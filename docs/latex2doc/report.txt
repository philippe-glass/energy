



\textsc{Université de Genève 
 Faculté des Sciences de la Société


	
 Coordination model and Digital Twins for managing energy consumption and production in a smart grid. \Doctoral thesis presented by:
Philippe Glass

supervised by:
Prof. Giovanna Di Marzo Serugendo



Jury members:
Prof. Jean-Henry Morin (Jury president): Université de Genève
Prof. Giovanna Di Marzo Serugendo (supervisor): Université de Genève
Prof. Jose Luis Fernandez-Marquez: Université de Genève
Prof. Davide Calvaresi: HES-SO Valais-Wallis
Prof. Emmanuel Fragnière: HES-SO Valais-Wallis


Geneva, 2025
Abstract
Smart grids play a key role for energy management directly supporting the socio-ecological transition of neighbourhoods. This research provides the design of a coordination model to enable the management and exchange of electrical energy between producers and consumers at a microgrid level. The coordination model proposed, which derives from the SAPERE coordination model, allows intelligent digital twins to interact and generate data on the fly to meet different needs in real time. We have designed prosumer digital twins, which autonomously generate supply contracts in the form of a transaction, and supervisor digital twins, which regulate energy overflow in real time and proactively using predictions generated by a learning model. The interactions of digital twins through the coordination model not only generate energy exchanges between prosumers but also enable peak shaving - to avoid energy overflows. We have also adapted and used the coordination model to integrate two decentralised approaches to distributed learning applied to a micro-network: the Gossip Federated Learning approach, which consists of exchanging homogeneous learning models between neighbouring nodes, and the Gossip Ensemble Learning approach, which consists of exchanging prediction results between neighbouring nodes, possibly obtained from heterogeneous learning models. The experimentations, based on real data, show that the combination of a coordination model and intelligent digital twins makes it possible to implement and operate these two purely decentralised learning approaches. The results obtained on the predictions confirm that these two implemented approaches can improve the efficiency of learning on the scale of a microgrid, while reducing the congestion caused by data exchanges.
Because a microgrid project involves major changes and efforts on the part of users, it has no chance of succeeding unless the aspirations and fears of potential users are thoroughly taken into account: these can be collected and then used to define social acceptance criteria to be taken into account when implementing the project.
A group from the same research project carried out a study to construct these criteria 'by design' and we then incorporated some of them into the digital twin's algorithms. The main features implemented consists in avoiding the tragedy of the commons, reducing free-riding behaviour through reward credits, integrating energy storage at the microgrid level and integrating certain salient attributes that can be handled by the digital layers of a microgrid.
We have implemented and tested the coordination model with different microgrid network topologies and with different types of data: simulation datasets, which are purely generated, and realistic datasets, based on household statistics, and real datasets, collected in the 'Les Vergers' living-lab near Geneva.
The results show that the combination of a coordination model and intelligent digital twins supports self-adaptive energy management, collaborative and decentralised learning framework, while taking account of issues linked to social acceptance. Such approaches are fundamental to developing smart grids that are resilient, reliable and respectful of environmental and social criteria.


Key words: Smart grid; coordination model; Coordination law; Digital twin; Tuple space; LSA; Node; dynamic adaptation; Node state; Kilowatt Hour; Gossip Federated Learning (GFDL); Gossip Ensemble Learning (GEL); Social acceptance by design.
Résumé

Les smart grids jouent un rôle clé dans la gestion de l'énergie en soutenant directement la transition socio-écologique des quartiers. Cette recherche propose la conception d'un modèle de coordination pour permettre la gestion et l'échange d'énergie électrique entre producteurs et consommateurs au niveau d'un microgrid. Le modèle de coordination proposé, qui dérive du modèle de coordination SAPERE, permet à des jumeaux numériques intelligents d'interagir et de générer des données à la volée pour répondre à différents besoins en temps réel. Nous avons conçu des jumeaux numériques prosommateurs, qui génèrent de manière autonome des contrats
d'approvisionnement sous la forme d'une transaction, et des jumeaux numériques superviseurs, qui régulent les débordements d'énergie en temps réel et de manière proactive en utilisant des prédictions générées par un modèle d'apprentissage. Les interactions des jumeaux numériques à travers le modèle de coordination génèrent non seulement des échanges d'énergie entre les prosommateurs, mais permettent également l'écrêtement des pointes - pour éviter les débordements d'énergie - et permettent aux modèles d'apprentissage d'être distribués entre les noeuds dans le contexte de l'apprentissage fédéré appliqué à un microgrid.
Parce qu'un projet de microgrid implique des changements et des efforts importants de la part des utilisateurs, il n'a aucune chance de réussir si les aspirations et les craintes des utilisateurs potentiels ne sont pas prises en compte de manière approfondie : celles-ci peuvent être collectées puis utilisées pour définir des critères d'acceptation sociale à prendre en compte lors de la mise en oeuvre du projet.
Un groupe du même projet de recherche a réalisé une étude pour construire ces critères et nous avons ensuite incorporé certains d'entre eux dans les algorithmes des jumeaux numériques. Les principales caractéristiques mises en oeuvre consistent à éviter la tragédie des biens communs, à réduire les comportements de resquillage grâce à des crédits de récompense, à intégrer le stockage de l'énergie au niveau du micro-réseau et à intégrer certains attributs saillants qui peuvent être traités par les couches numériques d'un micro-réseau.
Nous avons mis en oeuvre et testé le modèle de coordination avec différentes topologies de microgrids et différents types de données : des données de simulation purement générés, des données réalistes, basés sur les statistiques des ménages, et des données réelles, collectées dans le living-lab "Les Vergers" situé près de Genève.
Les résultats montrent que la combinaison d'un modèle de coordination et de jumeaux numériques intelligents permet une gestion auto-adaptative de l'énergie, un cadre d'apprentissage collaboratif et décentralisé, tout en tenant compte des questions liées à l'acceptation sociale. De telles approches sont fondamentales pour développer des réseaux intelligents résilient, fiables et respectueurx des critères environnementaux et sociaux.

Mots clés : Smart grid ; Modèle de coordination ; Loi de coordination ; Jumeau numérique ; Espace de tuple ; LSA ; Noeud ; Adaptation dynamique ; Etat du noeud ; kilowattheure ; Epprentissage fédéré; Aapprentissage ensembliste ; Acceptation sociale.
Acknowledgements


I would especially like to thank my thesis supervisor, Professor Giovanna Di Marzo Serugendo, who offered me the opportunity to carry out this thesis and for her guidance, insightful advice, support, and patience throughout this project. I would also like to thank her for giving me the opportunity to work as a teaching assistant at CUI during this period.

I am also grateful to the LASAGNE project's partners for giving me access to needed computing resources and for their advice and expertise especially in microgrids technical and social aspects, which also help me to progress in this research.

I would like to thank the members of the jury,
Prof. Jean-Henry,
Prof. Jose Luis Fernandez-Marquez,
Prof. Davide Calvaresi,
Prof. Emmanuel Fragnière,
for agreeing to assess my thesis and for taking the time to read it.

I also thank ERA-NET for funding this research, without which this thesis would not have been possible.

I wish to express my gratitude to my family and loved ones for their unwavering support, understanding and patience during the intense moments of thesis preparation and writing.

Acronyms
acronym
DTDigital Twin (see definition 0.1)
Eco-lawCoordination Law 0.2)
ELEnsemble Learning
FDLFederated Learning
GEDGrid Edge Device
GELGossip Ensemble Learning (see definition 0.3)
GFDLGossip Federated Learning (see definition 0.4)
kWhkilowatts-hour
LASAGNEdigitaL frAmework for SmArt Grid and reNewable Energie
LSALive semantic annotation (see definition 0.5)
LSTMLong Short-Term Memory
MASMulti-Agents System
MLMachine Learning
RESTREpresentational State Transfer
RLReinforcement learning
SAPERESelf-Aware PERvasive service Ecosystems
acronym


Publications

Conferences:

-  Fragniere, Emmanuel and Sandoz, Sarah and Abdenadher, Nabil and Moussa, Mohamad and Di Marzo Serugendo, Giovanna and Glass, Philippe: Improving the Social Acceptability of Microgrids (IEEE Renewable Energy and Sustainable E-Mobility Conference (RESEM), May2023).

https://ieeexplore.ieee.org/abstract/document/10236324

-  Fragniere, Emmanuel and Sandoz, Sarah and Abdenadher, Nabil and Moussa, Mohamad and Di Marzo Serugendo, Giovanna and Glass, Philippe: Fostering "Energy Communities": An Ethnographic-SECI Approach to User-Centered Residential Micro-Smart Grid Adoption (11th IEEE INTERNATIONAL CONFERENCE ON SMART GRID, June 2023).

https://ieeexplore.ieee.org/document/10171075

-  Moussa, Mohamad and Glass, Philippe and Abdennahder, Nabil and Di Marzo Serugendo, Giovanna and Couturier, Raphael: Towards a Decentralised Federated Learning Based Compute Continuum Framework" - European Conference on Service-Oriented and Cloud Computing, October 2023.

https://link.springer.com/chapter/10.1007/978-3-031-46235-1_14



{Papers:

  -  Glass, Philippe and Di Marzo Serugendo, Giovanna: "Coordination Model and Digital Twins for Managing Energy Consumption and Production in a Smart Grid." November 2023.
https://www.mdpi.com/1996-1073/16/22/7629

-  Glass, Philippe and Di Marzo Serugendo, Giovanna: "Gossip coordination mechanism for Decentralised Learning" April 2025.

https://www.mdpi.com/1996-1073/18/8/2116


{Posters:

  -  Di Marzo Serugendo, Giovanna and Glass, Philippe: "Lasagne - implementation of smart grid in the form of a coordination system of digital twins ", October 2022 - poster presented at the data-science day, September 15, 2022.
https://archive-ouverte.unige.ch/unige:164521

-  Di Marzo Serugendo, Giovanna and Glass, Philippe: "Coordination model and digital twins for managing energy consumption and production in a smart grid", October 2023. - poster presented at the PhD students' day, September 2023.

https://archive-ouverte.unige.ch/unige:172075


Chapter 1) Introduction:
Since the advent of renewable energies, the need for energy distribution systems between private individuals has been booming. For this reason, the need for energy management and distribution systems between private individuals has intensified.
Smart grids (see definition 1.1) play an essential role in the distribution and regulation of energy at a local level in a micro-grid structure that can be connected to the power grid.
Smart grids are electricity networks that use computer technology to adjust the flow of electricity between suppliers and consumers.
By collecting information on the state of the network, they contribute to a balance between production, distribution, storage, and consumption.
Smart grids (also called microgrids) are part of the new models of distributed, dense, and ubiquitous computing systems that provide services capable of continuously adapting to changing conditions.
The main objectives of smart grids are to:
-  Decentralize energy distribution (by connecting producers and consumers at a local level).
-  Promote the integration of renewable energies, which by their nature are intermittent and therefore less stable than carbon-based or nuclear energies.
-  Provide a more precise vision of future needs, by providing predictions of energy consumption/production in the next hours or days.
-  Prevent and avoid production/consumption peaks, shortages.
-  Optimise use, reduce costs.
-  Take into account various social acceptance by design criteria in energy exchanges.
1.1) The challenges we have to face:
Today, the computing units of microgrid nodes, also known as 'Grid Edge Devices', are not capable of exchanging energy in an autonomous and decentralised way. Indeed, these entities execute instructions that are issued from a centralized system, and they don't have the ability to interact with other peer entities in an autonomous and intelligent way.
In addition, the new requirements of energy regulation in microgrids have a particular impact on the need to find the most sustainable balance possible between electricity consumption and production in a microgrid system to ensure the stability of such a system [1]. As a result, machine learning algorithms need to be put in place to learn the electrical behaviour of systems incorporating renewable energy, which by its nature is highly volatile [2].
In addition, microgrids, as ubiquitous information systems [3], provide huge quantities of electricity data generated in different places and at different times: According to Zhang et al.'s review on data analysis in smart grids [4], in addition to lower-level data such as electrical status measurements collected by sensors, smart grid systems also generate higher-level data such as control instructions, fault information and analysis data that provide insight into previous information: all of which contribute to a significant increase in the total volume of data. In this context, a purely centralised learning framework could quickly find itself at a loss to manage such a volume of data, the sources of which may vary over time. This creates a bottleneck: firstly, in the central server IT unit, which must manage and coordinate all the units in the micro-network, and secondly in the data network, since all the information flows converge on the central server.
These limitations cover coordination, control, fault management and machine learning tasks on electrical behaviours.
Moreover, centralised control systems take much longer to adapt to a disruption to a distributed energy resource. More generally, they are much less scalable in relation to any changes that may occur to a distributed energy resource (addition, modification, or deletion of a Distributed Energy Resource) [5].
Furthermore, the data characterising users' electrical power is confidential and could be hacked by third parties during the transfer [6]: such data should not be sent as is to a centralised unit which coordinates all the tasks.
In addition, maintaining the stability of a microgrid at a local level and coordinating between the various prosumers requires the deployment of autonomous software entities that can represent each of its prosumers: digital twins can provide a solution along these lines.
Last but not least, current smart grids do not consider the social dimension, whereas the integration of social criteria would help to strengthen user confidence and involvement: in this way, passive consumers would become active prosumers.
The aim of this thesis is to address these gaps by proposing solutions based on interactions and self-adaptation at the local level, using coordination models and digital twins.
1.2) The research questions we identified:
We can break down the research work of this thesis into several research questions, which we define as follows:
-  (Q1) Can we design a coordination model and mechanisms that allows Grid Edge Devices to collectively achieve various objectives?
-  (Q2) How can we model the notion of Digital Twins to represent microgrid entities which exchange and regulate energy at a local level?
-  (Q3) How can we integrate a gossip mechanism into a coordination model that can be used for decentralised learning, with an aggregator that the client layer can define on the fly?
-  (Q4) To what extent can we integrate criteria of social acceptability into Digital Twins behaviours, in the decision-making process for electricity transaction and electricity regulation?
-  (Q5) Can we implement a light version of the coordination model that can run on a Grid Edge Device with a small amount of disk space and memory?
1.3) Expected contribution:
To meet these challenges, this thesis proposes a purely decentralised information system adapted to distributed structures such as microgrids, where each computing unit generates consumption and production data and can exchange information directly with other computing units.
We focus exclusively on the digital level: we propose to deal with the data flows exchanged between the different entities of a microgrid but not directly with the electricity flows. More specifically, we propose a digital solution to optimise the production, distribution and consumption of electricity at local level, while ensuring the stability of the microgrid. We propose to facilitate the integration of renewable energies that can be produced locally at the microgrid level.
Coordination models ([7]) could fill this gap as they allow the design of distributed systems capable of adapting to permanent changes and in which autonomous agents, which represent the smart grid entities, interact with each other. Such systems have been used, for example, to coordinate different medical and transport services during a humanitarian crisis ([8]).
The aim of this thesis is to design such a system capable of managing and distributing energy between individuals, using coordination systems as a platform for exchanging information between stakeholders.
This research aims to provide the following outputs:
-  A coordination model that ensures the distribution and regulation of energy at microgrid level and uses a Gossip mechanism for decentralised learning to distribute knowledge among neighbouring nodes (with the aim of reaching a consensus among the nodes).
-  A light version of the same coordination model that runs with limited memory and disk space.
-  Digital twins which model the behaviour of entities interacting in the microgrid, and which can exchange energy, manage peak shaving, take part in decentralised learning on the scale of the microgrid and which also take into account social dimension criteria to improve user involvement.
This thesis is also part of the LASAGNE research project, initiated by several consortia in Switzerland and Sweden, which aims at developing self-adaptive applications for smart grid energy management. These applications cover aspects such as energy negotiation or peak shaving. To address this goal, the LASAGNE project develops an edge-to-cloud and edge-to-edge infrastructures [9], relying on a digital platform providing specific services for these applications. This platform instantiates a coordination model, provides Digital Twins and supports distributed collaborative Machine Learning (ML) methods.
Chapter 2) Related works:
The development of smart grids has become an important issue in recent years, reinforced by the drastic rise in energy costs, the growing risk of energy shortages and the need to increase the share of renewable energies in energy supplies.
First, we call a smart grid an infrastructure for managing flows of electricity between connected electrical entities, using a combination of information, electricity, and network technologies. By optimising distribution, a smart grid strives to ensure a constant balance between production and consumption. Certain entities, called "nodes", contain calculation units, and generally interact with a set of directly connected electrical appliances, via sensors and actuators. It is worth noting that some higher-level nodes, which interact with lower-level nodes, may not interact directly with electrical devices.
Defining the smart grid concept
According to surveys that examine the use of the smart grid concept [10], there are a multitude of definitions which differ according to the user's point of view (technical or economic or commercial) or according to the region. However, certain concepts of the various definitions are recurrent: these include dynamic infrastructures (combining the circulation of information and electricity), the real-time interactivity, and the different power system stakeholders which cooperate within the same network.
In the context of this thesis, we define a smart grid in this way:

A smart grid (also called microgrid) is an electricity network that uses computer technologies to adjust the flow of electricity between suppliers and consumers. It is made up of several interconnected nodes containing computing units, which are generally connected to electrical devices that consume or produce electricity - except for the highest-level nodes. By collecting information on the state of the network, a smart grid contributes to the balance between production, distribution, and consumption [11].
Today, the development of such infrastructures is still at a "pioneering" stage and has not yet reached a sufficiently mature state: indeed, to date, smart grid designers have to contend with a number of definite issues, such as the lack of standardisation both in the design and development of smart grid infrastructures, and at the legal level, which further complicates their implementation, especially when stakeholders from different countries are involved. The fact that smart grids combine many scientific and technical fields also complicates their implementation.
However, according to Mozina [12], there are some attempts at standardisation, such as IEEE 1547, which defines the rules for interconnecting Distributed Generators on a smart grid. The standard cites obvious requirements for the interconnection of Distributed Generators but offers few methods, solutions, or options for meeting these requirements.
Choice of research areas
Smart grid entities need an infrastructure equipped with digital applications that enables them to interact locally and adapt to constant changes. To be more precise, entities interact by negotiating, exchanging, optimising, and reducing energy (to avoid peaks). At the same time, they need to forecast consumption and production to anticipate peaks in energy production or consumption.
We are therefore interested in paradigms based on decentralised architectures and the principle of dynamic adaptation, enabling local entities to interact with each other and generate new data on the fly. Among these paradigms, we find Multi-Agents systems and coordination models.
Given that participants in a power grid need to forecast consumption and production with massive amounts of load data that are volatile over time, we also need to focus on machine learning and decentralised learning framework adapted for a microgrid network. In summary, we will focus on the following three areas:
-  Coordination models, which make it possible to design a system in which agents interact dynamically: a coordination model provides coordination support and mechanisms that enables different agents to interact with each other in a dynamic, decentralised way.
-  Multi-Agents approaches to exchanging energy, an unavoidable research area, given that any smart grid infrastructure comprises various stakeholders seeking to negotiate, to buy or sell electricity locally and to manage peak shaving.
-  The Digital Twin approach, which enables physical entities such as electrical appliances or supervision devices to be represented by virtual "twin" entities.
-  Machine learning approaches applied to energy at the scale of a microgrid and applied in a decentralised manner. The objective is to predict electricity consumption and production at the level of a microgrid (the forecast obtained is then used to manage peak shaving).
2.1) Coordination models:
With the advent of connected objects whose data production is exploding, distributed applications could offer solutions that go beyond the limits of centralised systems. By using dynamic adaptation at a local level, distributed applications can adapt more easily to permanent changing conditions and to localised needs which depend on space topology [13]. These changes particularly concern smart grid applications since the integration of renewable energies [14]. The paradigm of coordination models fits perfectly into this digital transformation: it helps to decentralise processes by creating self-organisation based on interaction between entities.
2.1.1) Background of coordination models:
A coordination model can be defined as a set of software components and infrastructures enabling entities to interact with each other: it contains a coordination medium, for sharing data between coordinated entities, and coordination laws applying to shared data (transformation, propagation).
We can classify coordination models according to the coordination medium (which are tuple space and blackboard) and the type of coordination mechanism (gravitational, bio-inspired, chemical). The coordination model used in this research, which is derived from SAPERE, is based on tuple space and has a chemical and bio-inspired mechanism.
2.1.1.1) Coordination mediums:
We can define the two main categories of coordination medium as follows:
-  A blackboard is a shared data structure containing a communication buffer and a trigger mechanism, which is available to different data sources and serves as a community memory.
Corkill [15] considers it as the first attempt to integrate cooperating software modules.
-  A tuple space is a shared virtual space in which the various software entities deposit data in the form of tuples of values. LINDA [16] is the ancestor of tuple-based models.
2.1.1.2) Coordination mechanisms:
These are the mechanisms that apply to data shared on the coordination medium. The design of coordination mechanisms has drawn inspiration from various concepts of science:
-  The concept of stigmergy, introduced in zoology: the principle of stigmergy is that the trace left in the environment by the initial action of an agent stimulates a subsequent action, performed by a surrounding agent. In this way, successive actions tend to reinforce each other and thus lead to the spontaneous emergence of a coherent, apparently systematic activity. Research [17] has used this principle extensively to coordinate the movements of swarm robots.
-  The chemical reactions: they represent simple laws that regulate the evolution of complex phenomena, thus coordinating the behaviour of many components.
These coordination mechanisms rely on a coordination medium, which contains the data shared between the different entities. A tuple space is an example of a medium where shared data is defined as a tuple of properties.
Chemical reactions define combinations of logical fragments [18] applied on the fly to a set of tuples. As a result, the reaction modifies some tuples or produces new ones. In the Gamma coordination model, Banâtre et al. [19] use molecules to represent coordinated entities and chemical reactions to represent state transformations.
-  The Gravitational and electromagnetic fields: some models make the agents evolve from calculation rules analogous to the calculation of a resultant force vector in physics. For example, the Co-fields model [20] exploits composite computational fields to coordinate the movement of users and robots in an environment.
-  The concepts of distribution and topology: they have enriched the chemical tuple space, forming the biochemical tuple space [21]. Distribution and topology introduce new coordination concepts, such as environment compartmentalisation, diffusion (borrowed from physical coordination models), neighbourhood, which structures the topology of coordination, and local spaces for carrying out chemical reactions.
2.1.2) The tuple-based bio-inspired coordination model concept:
Coordination models ensure interaction between agents of heterogeneous natures, using a virtual environment for sharing data (called medium) and a biochemical-inspired transformation mechanism for disseminating and updating this shared data (called coordination laws) [22].
Each entity is represented by an agent that interacts through the coordination model: the agent then provides a set of services and submits data about itself, (properties and capabilities) under the form of a tuple (couple, triple or more of properties with a value attached). In this way, a set of agents can generate data built on the fly to respond spontaneously to a request.
Thanks to the use of distributed bio-inspired patterns, coordination models improve resilience, adaptive capacities, and the distribution of treatments between agents.
Zambonelli et al. [23] represent a coordination model architecture in 3 layers:
-  The agents: these are autonomous and pro-active software entities running at a hosting company.
-  The infrastructure: represents a layer composed of a set of connected hosts and infrastructure agents. A host entity provides computing and communication capabilities, sensors, and actuators while an infrastructure agent acts to implement environmental behaviours present in nature, such as diffusion, evaporation, and aggregation.
-  The environment: represents the real-world space where the infrastructure is located. The agent can detect an event using the sensors provided by the hosts.
The biological model, which is often compared to the computational model, consists solely of the "environment" and "organism" layers. These two layers are reconciled respectively with the "environment" and "agent" layers of the computational model (see figure 2.1).
The two entity models: biological and computer, according to Fernandez-Marquez et al. [24]:
2.1.3) Use of coordination models in the field of electricity:
In the literature, examples of applications in the field of electricity present the use of coordination models in the form of bio-inspired algorithms. These applications do not make use of the inspiration of chemistry, nor of any coordination support (such as a tuple space).
For example, Peres et al [25] propose a coordination mechanism that uses ant, bat and genetic algorithms to improve the electrical stability of rotor generators (by optimising the synchronisation torque and damping torque of electric generators).
Zhao et al. [26] present a coordination mechanism based on particle swarm optimisation to regulate the energy produced by wind power plants. Energy regulation uses a multi-scale model to transfer energy to a longer-term supply or, conversely, to a shorter-term supply, depending on energy production and consumption needs.
Bhattacharyya et al. [27] try to solve reactive power planning problems by using bio-inspired coordination models based on Particle Swarm Optimisation. They have also used this model to evaluate the system's total operating cost and optimisation gains.
Shan et al. [28] have also implemented the same type of bio-inspired models to minimise the operational cost of a microgrid, considering the electrical constraints of the various devices, in island mode or in a grid-connected mode.
Saber et al. [29] have implemented a coordination model to manage electricity transactions between the prosumers of a microgrid participating in an organised market. At each cycle, the model recalculates all supply and demand prices, considering the preferences of each prosumer as well as the energy available at each bus in the power grid.
It is worth noting that these implementations are limited to the use of bio-inspired algorithms and do not use support as such to share data between coordinated entities and apply coordination laws to update data or disseminate it to the set of entities.
Ben Mahfoudh [30] has used the SAPERE biochemical model to experiment with energy exchanges between agents (representing connected lamps), which trade energy taking into account pricing and network bandwidth.
We have also used this biochemical model [31] to simulate a microgrid (based on real data collected in the "Les Vergers" living lab near Geneva), in which prosumers exchange electrical energy according to demand and availability.
2.1.4) Synthesis:
In terms of research, coordination models have reached an advanced level of maturity. They have drawn inspiration from living systems, chemistry, and physics.
The SAPERE model [32] seems to be the only biochemical model that can support coordination using stigmergy, chemistry and topology at the same time. Table 2.2 summarises the evaluation of some coordination models based on different criteria.
Review of coordination models: 

Table 2.3 summarises the evaluation of some use of coordination models based on different criteria.
This table underlines the fact that, to date, the use of coordination models is still very marginal in the field of electricity. Among the various inspirations, biological inspiration remains predominant, while biochemical inspiration has not yet been tested, except at the University of Geneva. Furthermore, there are no applications using physics-based models.
Review of coordination model applications for electricity: 

2.2) Multi-Agents approach for energy exchanges:
Multi-Agents systems are the ideal solution for implementing distributed applications to solve complex problems, such as crowd management, robot automation, biomedical simulations or energy engineering. Jennings et al. [33] define a Multi-Agents System (MAS) as a system made up of a set of agents active in a certain environment and interacting according to certain rules. In a MAS, an agent is an autonomous physical or software entity that attempts to achieve its own goals: it is a pro-active, reactive, and social entity, taking part in an organised activity and interacting with other agents.
According to Daneshfar et al.'s review [34], agents have 3 main characteristics:
-  Reactivity: they can react quickly to changes in their environment.
-  Pro-activity: they are motivated by their own objectives.
-  Social capacity: they can negotiate, cooperate, or compete. They communicate with each other using a common language (defined in an ontology).
According to Roche et al.'s review [35], Multi-Agents System offer several advantages over centralised systems:
-  Agents only act locally: if the view and knowledge of agents is limited to the microgrid neighbourhood they belong to, the amount of data to be transmitted (and the corresponding costs) is dramatically reduced in comparison to other communication intensive methods.
-  Agents are flexible, plug & play, and fault tolerant. The structure of a Multi-Agents System or of its environment can change without any significant consequence for the functioning of the system itself.
-  Multi-Agents Systems are well-suited for solving difficult problems, where the computation can be distributed among several agents.
Mahela et al. [36] have published a comprehensive analysis of the use of Multi-Agents systems to control smart grids. This analysis shows that the Multi-Agents system is the most effective paradigm for integrating the different types of entities and processes involved at different levels of smart grid organisation. Indeed, each autonomous agent, with its own responsibilities, can represent an entity and focus on a specific issue independently - for example, energy pricing, energy transaction processing, energy flow monitoring, intrusion detection or fault handling. Depending on its hierarchical level within the organisation, its decisions have a greater or lesser impact on other agents.
Binyamin et al. [37] have identified different ways of using Multi-Agents systems for smart grid applications: the different issues to address, the classification of agents used to manage smart grid entities, and the techniques implemented.
In the field of data security, an example of a technique often used is the blockchain mechanism [38], which aims to monitor the updates of resources exchanged between agents in a smart grid.
2.2.1) Using Multi-Agents Framework:
The scientific and technical literature attests to the existence of a wide variety of frameworks for designing Multi-Agents systems.
The most used for this type of application is JADE [39], which facilitates the development of agent applications in line with the FIPA specifications for inter-operable intelligent Multi-Agents systems. FIPA protocols include the simple inquiry protocol, the contract-net negotiation protocol, and the English and Dutch auctions.
For example, Qasim et al. [40] have implemented a negotiation mechanism between agents in real time using a FIPA-based protocol enriched with time-stamped data to manage the temporal aspect of negotiations.
JADE [41] provides a distributed agent platform that can be distributed across several hosts. It also provides services and functionalities, such as a Directory Facilitator, a programming interface to simplify registration of agent services, a transport mechanism to exchange messages with other agents, a compliant IIOP protocol to connect different agent platforms, and a Graphical User Interface to manage agents and platforms.
Some other MAS framework exists, such as ZEUS, SkeletonAgent or MadKit.
In the field of electricity, Kuzin et al. [42] have proposed a method for controlling smart grids in case of failure detection of a main alternative current power source.
They used the JADE Multi-Agents framework to implement a flexible protection of critical loads against main grid failures and the MACsimJX interface to ensure communication between agents and the smart grid model. According to the simulation results, they achieved good response times and effective control of energy resources to ensure smart grid stability.
Mocci et al. [43] have used hierarchical Multi-Agents systems working with JADE to integrate smart charging of electric vehicles with active demand participation via an aggregator agent. The proposed Multi-Agents System operates with hierarchical and decentralised control and simulates a dynamic non-cooperative single-objective game, which converges to the Nash equilibrium.
Pinto et al. [44] have used a framework architecture that combines different Multi-Agents systems, each dealing with a particular aspect such as portfolio optimisation, market simulation, or strategy selection based on the current context. The whole system allows to maximise the profits of the microgrid stakeholders by using all the different markets in parallel, from the local market to the wholesale market.
2.2.2) Using Multi-Agents Architectures:
The architecture of the Multi-Agents system reflects the structure of the organisation we wish to set up between the different agents. It defines the possible roles of the different agents and may (or not) include different hierarchical levels.
2.2.2.1) 3-level hierarchical architecture:
According to Roche et al. [45], despite the multiplicity of systems to manage and the degrees of intelligence of agents, most articles in the literature show a basic structure, generally based on three hierarchical layers:
-  The top layer, corresponding to distribution network operators and higher-level networks. This layer coordinates several microgrids and optimises global energy market operations at a strategic level.
-  The intermediary layer, corresponding to the microgrid coordinator. This layer optimises microgrid operation by distributing energy between generators and loads.
-  The bottom layer, corresponding to generators, load, and storage agents. In this layer, each agent controls an intelligent device that enables it to react in real time.
In the field of electricity, Logenthiran et al. [46] and Dimeas et al. [47] have used a 3 layers architecture with the following agent roles:
-  The top layer, which contains two agents managing the entire network: the Distribution Network Operator and the Market Operator.
-  The intermediary layer, which contains the central Microgrid Controller.
-  The bottom layer, which contains the 2 following types of local controllers: the micro-source and the load controllers.
Dimeas et al. also propose to use auction algorithms to manage price negotiation between producers and consumers.
Rumley et al. [48] propose other types of architecture by defining feeder and load agents. Feeder agents use dynamic adaptation to reconfigure their links in case of shortage or excess of energy resources, or in case of significant loss due to energy transport.
James et al. [49] propose an architecture which includes the following agent types: buyer, seller, bulletin board, physical device, and others.
However, other research, as described below, has developed more sophisticated architectures that take greater account of the diversity of issues to address in a smart grid.
2.2.2.2) "Link" based architecture:
Ilo [50] proposes the "Link" paradigm to enable the grid market to flourish, by encouraging consumers to actively participate in grid operations and by making the operating structure in a smart grid more reliable. The proposed architecture contains three main components: the Grid-Link, the Producer-Link, and the Storage-Link, where a "link" element defines a generic element found throughout the power grid or in customer power plants. This architecture minimises the volume of exchanged data, and guarantees safe, reliable, and durable operation in both normal and emergency situations.
2.2.2.3) Using holonic structures:
The holonic architecture [51], which has also been used to represent smart grid infrastructures, is of particular interest.
Basically, the word "Holonic" comes from the Greek word "holon", a union formed from the words "holos", meaning whole and the word "on", meaning parts. In a hierarchical structure, Frey et al. consider a holon both as an entire element and as a part of a higher-level element.
They define a holonic MAS as a Multi-Agents system composed of a set of holonic entities, and they define a holon recursively, as an entity that is both a member of an organisation and an organisation itself: this latter organisation manages other holonic entities that are at a lower level. Figure 2.4 represents a holonic structure comprising smart grid entities. For example, a holon representing a household is a member of the microgrid organisation and manages a lower-level organisation containing its electrical appliances. This paradigm facilitates the integration of heterogeneous entities at different hierarchical levels.
In addition, this model helps to meet certain requirements such as the implementation of multiple authorities at different levels, the integration of heterogeneous systems, the need for permanent adaptation and the need to satisfy demands that can be contradictory. Some tests performed on a prototype implementation have proved that it is indeed possible to meet these requirements.
Generic Holonic architecture control, inspired from [52]. This schema represents a simplified microgrid with district-level, house-level, and appliance-level goals.:
Taleb et al. [53] have simulated a holonic smart grid under different conditions: connected mode, island mode and disturbed mode. The results show that holonic structures tend to increase the adaptive capacity of agents in the face of disturbances and power shortages.
Many holonic approaches have designed or used frameworks to implement such an organisation.
For example, Case et al. [54] have designed a framework that helps implement a holonic organisation, iteratively and integrating entities one after the other (defining for each entity, its goals, roles, and state transitions).
This framework starts with a simple implementation, and allows iterative enrichment based on a recommendation system to evolve the structure.
Cossentino et al. [55] have implemented the ASPECS agent-oriented framework (Agent-oriented Software Process for Engineering Complex Systems) to design a holonic organisational meta-model with a step-by-step guide from requirements to programming, enabling the modelling of a system at different levels of detail.
Wallis et al. [56] present a framework that integrates prosumers as independent holons within a dynamic microgrid structure. With the aim of maintaining a balance between generation and consumption, this approach uses a strategy selection mechanism based on the forecasting results of load consumption and photovoltaic power generation at different horizons.
2.3) Use of Intelligent Digital Twins:
Digital Twins were born in the context of the emergence of Industry 4.0, which seeks to automate industrial processes by transferring part of the physical equipment to the virtual world [57]. They result from the fusion of several disciplines, such as AI, the Internet of Things and virtualisation. In this context, the need has arisen to reproduce the dynamics of a physical system in the digital world, with computerised control of testing, analysis, and risk prevention.
Grieves [58] defines the Digital Twin model based on its 3 following components:
-  The physical space and products, which continue to exist and function in the real world.
-  Its digital representation (called virtual space), which contains its information and its abstract model.
-  The bidirectional connection between the physical space and the virtual space (often referred to as the "digital thread"), which enables the two spaces to interact with each other.
In a survey on Digital Twin, Barricelli et al. [59] define it as a computer-based model that is simulating, emulating, mirroring, or "twinning" the life of a physical entity, which can be an object, a process, a human, or a human-related feature. A Digital Twin benefits from the autonomy (sensing and acting) available to agents in Multi-Agents systems [60].
According to Marah et al. [61], autonomous agents have powerful capabilities that enable them to meet the requirements of integration into a Digital Twin. Therefore, Multi-Agents System (MAS) is the main model for programming agents in the cyber-physical systems layer as well as in the Digital Twin layer.
Depending on the industrial field and its applications, Digital Twins may possess cognitive abilities such as self-adaptation, communication, negotiation, reasoning, and learning [62]. As a result, they can be considered as "intelligent".
Tzanis et al. [63] present an approach based on cybernetic Digital Twins to anticipate future power failures in a smart grid within a very short time frame. In this approach, each twin combines a machine learning model and a discrete deterministic mathematical model. Experiments have shown promising results on low-latency networks.
Ebrahimi et al. [64] have designed a Digital Twin model of complex renewable energy generators such as wind or hydro power plants. They present a comprehensive modelling strategy that contains different modelling levels and applies uncertainty and smart algorithm tools.
2.3.1) Synthesis:
Table 2.5 summarises the evaluation of some Multi-Agents systems (MAS) applications in the field of electricity, based on different criteria: it shows that there are no electrical applications using both Multi-Agents systems and Digital Twins. On the other hand, Multi-Agents systems are widely used, particularly compared to more traditional Digital Twins. This may be explained by the relative novelty of the Digital Twin concept. In addition, some MAS applications seem complete as they use both a dedicated framework and a scalable architecture. This further underlines the maturity of Multi-Agents systems.
Review of Multi-Agents systems: 

2.4) Approaches for distributed learning:
In a microgrid structure, a node, also called an edge device, is a computational entity able to store and process data and software. Typically, the coordination platform and the Digital Twins [65] execute within a node (e.g., an edge device).
In this paragraph, we study machine learning methods to allow edge devices to predict the consumption and production at its own level (that is, locally) or at the microgrid level (that is, globally). As a result, we need to distinguish between the learning model itself, also known as classifier, which an edge device (e.g., a node) in the network runs at its level to predict electrical behaviours based on data observed locally, and the distribution framework used at the microgrid level to federate the learning done by the individual nodes. These two orthogonal elements constitute the learning techniques implemented throughout a microgrid.
In what follows, the first subsection focuses on distribution frameworks used to federate learning between different computational units, while the second subsection focuses on the different types of classifiers used by a computational unit in the domain of energy.
2.4.1) Distributed Machine Learning frameworks:
In terms of frameworks, we present here two main families of approaches, one called Federated Learning, which uses a centralised model, and the other called "Gossip Federated Learning", which uses a purely decentralised model.
2.4.1.1) Centralised Federated Learning: the general approach:
Centralised Federated Learning, more commonly known as Federated Learning (FDL) [66] is a paradigm in which multiple machines collaboratively train an artificial learning model while keeping their training data at the local level. The principle is that different devices distributed in different nodes located in the same network all participate in learning a variable whose behaviour is homogeneous across all the nodes. In this approach, each device participates in the learning of this common behaviour by training an instance of the learning model using its local data. A central server manages the distribution of the learning model to each node device (called 'client') in a cyclic manner. Periodically, each client is therefore allocated a version of the model, which it will re-train with its dataset and then return to the central server. The local data used to train the model is not sent to other nodes: in this way, it remains protected. As represented in figure 2.6, the data streams containing learning models all converge on the central server, forming a star graph topology.
Federated Learning approach, inspired from [67]. In this approach, a central server, represented in the middle of the diagram, manages the distribution and collection of model weights, which the subordinate nodes (also known as 'client' nodes) update.:
The central server aggregates the model weights received from the clients (for example, by applying an average) and assigns the new model version based on the aggregated model weights. The Federated Learning paradigm contrasts with purely centralised learning, in which all machines send their data to a central server, which is the only entity to execute the learning model.
In the energy domain, Savi et al. [68] have experimented the federated learning approach coupled with the LSTM model to predict the short-term effective load at different node locations in a smart grid. Ibrahem et al. [69] have proposed a Federated Learning approach that uses a privacy-preserving aggregation scheme for energy theft detection in smart grids. They have designed an aggregator server that receives only the encrypted form of model parameters from individual nodes. This protects the network from external intrusions and preserves the node's privacy.
2.4.1.2) Decentralised Federated Learning approach:
A variant of the Federated Learning approach, called "Decentralised Federated Learning" [70], involves the various devices to a greater extent, in that each node device itself manages the distribution of model weights to the surrounding node devices, unlike the traditional approach where a single server is responsible for distributing model weights to all the devices. We consider this approach to be totally decentralised in that the data flows are not all linked to a single central server as in a star graph topology but are distributed throughout the network. Similarly, the aggregation and communication processing are not concentrated on a single computing unit, but on a set of local units located in the various nodes.
The Decentralised Federated Learning approach uses the "gossip" mechanism (see definition 2.7), which is a composition of aggregation and spreading mechanisms.
A decentralised approach is based on the "gossip" mechanism, which is a composition of aggregation and spreading mechanisms.
Figure 2.8 represents the Decentralised Federated Learning which is an application of the gossip mechanism to a set of nodes that train a learning model. This mechanism, also called "Gossip Federated Learning" is a framework in which a local node performs all actions locally. More precisely, each node executes alternatively the computation phase (which consists of training the learning model with local data) and the inter-nodes communication phase (which consists of exchanging learning models with neighbours and merging local models with those of neighbouring nodes).
Table 2.9 summarises the two approaches presented, highlighting the points of convergence and divergence.
Comparison of Centralised and Decentralised Federated Learning.:
According to Liu et al. [71], this approach reduces the communication traffic among nodes and prevents disclosing sensitive local data to other nodes. During the inter-node communication phase, one node only sends the computed weights of its learning model (and not training data).
Decentralised Federated Learning approach, inspired from Liu et al. [72]:
An empirical study [73] provides a systematic comparison of Federated Learning and Gossip Federated Learning approaches, using experimental scenarios including a real unsubscribe trace collected on cell phones under different conditions: communication regularity (continuous or in bursts), bandwidth, network size, and compression techniques.
One might think that, because of the use of lighter computing units (located at node level and not in the cloud), gossip learning performance would be much poorer.
Surprisingly, the results showed that best gossip variants perform comparably to the best Federated Learning variants.
Another approach has experimented with Gossip Federated Learning on an ultra-dynamic configuration, such as a network of electric vehicles moving in an urban environment [74]. To predict the vehicles trajectories, this experiment has applied Gossip Federated learning to a fleet of moving cars, with each vehicle device locally executing the LSTM learning model. The results confirmed that in this type of highly dynamic configuration, Gossip Federated learning significantly improves the accuracy of poor-experienced vehicles, by taking advantage of the learning experience of better-trained models that move in the vicinity.
As the Gossip Federated Learning approach is new, there are still very few applications in the field of energy.
Giuseppi [75] has proposed a decentralised Federated Learning algorithm for non-intrusive load monitoring (NILM) applied to a network of energy communities. NILM is a process for analysing voltage and current variations that occur in a home: it aims to deduct the appliances used, as well as individual energy consumption. For different types of appliances, evaluations have confirmed that the decentralised version tends to perform better than the centralised version.
Moussa et al. [76] have experimented with a Decentralised Federated Learning framework on a microgrid network composed of Grid Edge Devices that use LSTM Learning model locally. In this approach, each node applies a variant of the gossip mechanism conditioned by the performance of its current predictions: if the latter are good, it sends its weights to neighbouring nodes (otherwise, it will ask neighbouring nodes for their weights to improve its performance).
2.4.1.3) Ensemble learning approach:
So far, we have presented approaches that allow several independent models to be combined, but which are structured in the same way. In the literature, there are also a multitude of approaches that allow models of different types to be combined, using many ways of combining them [77]. This is the very general 'Ensemble Learning' approach, which builds a new higher-level classifier from several classifiers.
The underlying idea of Ensemble learning is that the union of several basic models which are trained separately, and which may be of different types, can produce more reliable results than a single model. This draws inspiration from the human behaviour of seeking several opinions before making an important decision. Nicolas de Condorcet has formalised this in the Jury's theorem [78]: in a jury made up of members who take decisions independently and with a reliability rate greater than 1/2, majority jury decisions tend to increase reliability.
According to Sagi's review on Ensemble learning methods [79], different sub-approaches to Ensemble Learning use different ways of combining learning models, such as input manipulation (which gave rise to the AdaBoost and Bagging classifiers), output manipulation (which gave rise to Gradient boosting), ensemble hybridisation (which gave rise to Random Forest), manipulated learning (Rotation Forest) and partitioning.
In the same way, Ensemble Learning approaches are also used in the field of electricity.
Wang et al [80] have built an Ensemble Learning approach for load forecasting which combines LSTM models as first level models and Fully Connected Cascade (FCC) neural networks as second level models. The LSTM models are executed on different portions of data, which are separated using the HDBSCAN clustering algorithm [81].
In all the experiments carried out on real data per household and at regional level, the evaluated accuracies confirm that the proposed variants based on Ensemble Learning outperform the 'basic' LSTM approach.
Kumar et al. [82] have also experimented an Ensemble Learning approach to forecast consumption power. This approach uses a voting process to choose a prediction from among the predictions generated by 5 different base models. The choice consists of applying these models to the evaluation data and selecting the one that minimises the calculated error. Similarly, the experiments confirmed an improvement in the performance of the proposed Ensemble Learning approach compared with the elementary classifiers used.
With the aim of securing microgrid and gaining users' trust, Ali et al. [83] have proposed an Ensemble Learning model to filter prosumers willing to exchange energy in a microgrid, based on their predicted reliability in terms of packet loss rate, response time, responsiveness, integrity, and consistency. The proposed Ensemble Learning approach combines LSTM and LGBoost classifiers and applies data sampling manipulation algorithms using SMOTE and PCA.
It is important to note that the Ensemble Learning implementations we have just mentioned all combine different elementary models in a centralised manner, i.e. the mechanisms that combine the models are executed by a single process, although the models are driven by independent processes.
Other approaches have already explored decentralised mechanisms for combining models: for example, the approach of Yu et al. [84], which involves each agent in the process of combining data samples from neighbouring agents and the approach of Magureanu et al. [85], which defines a consensus probabilistic protocol (called Slush) based on peer-to-peer exchanges. This purely decentralised version offers advantages such as reduced overhead communication and robustness against intrusions. To date, such decentralised Ensemble Learning approaches have not yet been implemented on microgrid applications.
2.4.2) Machine learning models:
The increasingly massive deployment of sensors to monitor energy consumption has resulted in the production of an enormous amount of data.
In addition, the advent of renewable energies has led to high data volatility over time.
We must therefore choose appropriate learning methods to meet such a challenge: they must be able to understand data that is both large, dimensional, and volatile, while operating seamlessly from an embedded device with limited memory space.
2.4.2.1) The Markov Chains model:
The Markov Chains model uses discrete-time Markov random processes, for which stochastic matrices give the probabilities of all possible state transitions [86].
For these random processes, the probability of a future state depends only on the present state and not on past states: this characterises the "absence of memory".
This stochastic model allows continuous learning with newly collected data (both the weight vectors and the chains). The University of Mashhad has experimented with this model to predict the energy produced by photo-voltaic cells [87]. The results obtained confirmed the performance of Markov Chains for energy production, after sufficient training of the model. This model also has the advantage of being able to slide in time by applying a learning window. This allows the model to adapt more easily when observed behaviours change significantly over time.
2.4.2.2) Gradient Boosting (XGBoost):
XGBoost [88], which stands for Extreme Gradient Boosting, is a supervised machine learning method for classification and regression used by the AutoML training tool. This method is based on decision trees and improves on other methods such as Random Forest and gradient optimisation. It is effective with large, complex datasets, using a variety of optimisation methods. Data scientists widely use XGBoost and XGBoost provides state-of-the-art results on many problems.
In the field of energy, Gupta et al. [89] have experimented with the XGBoost model for solar power prediction. According to the result, the XGBoost model outperforms the Facebook prophet model which is also suitable for a large dataset with significant seasonality.
2.4.2.3) LSTM:
In the field of energy, the LSTM model (Long Short-Term Memory) [90], which is an advanced and more flexible Recurrent Neural Network architecture, has become one of the most popular models for predicting time series with large fluctuations over time. LSTM is a recurrent neural network: the principle is that the current state also depends on previous states, which is not the case with the Markov model or conventional neural networks. A LSTM cell uses gates to regulate the various signals it receives from input variables or from the preceding cell. As a result, this model helps to memorise past behaviours and to regulate their importance: it is a natural candidate model to adopt in the context of short-term load forecasting. One of the first evaluations of LSTM in this field [91] reveals that LSTM outperforms classical Artificial Neural Networks: in particular, LSTM performs much better in learning long-term temporal correlations. This research has tested the LSTM model on a publicly available residential smart meter dataset, whose performance is compared to various references, including the state of the art in load forecasting.
2.4.2.4) Multi-Agents reinforcement learning:
Reinforcement learning (RL) [92] is an area of machine learning concerned with how intelligent agents learn to make decisions in an environment to maximise the notion of cumulative reward. As a result, RL differs from supervised learning in that it does not require the presentation of labelled input/output pairs, nor the explicit correction of sub-optimal actions. It's worth noting that the RL problem is mathematically known as a Markov Decision Process (MDP), where, at each time unit, an agent in a state $s$ performs an action $a$, receives a scalar reward $r$, and moves to the next state $s'$ according to the environment dynamics.
In the field of electricity, Roesch et al. [93] have used reinforcement learning to minimise the global cost at the scale of a complex microgrid system composed of generation resources, a storage battery, and a short-term market trading platform. In the modelling, the total cost includes electricity and production costs, as well as real-time fluctuations in market electricity prices. The reward function, meanwhile, considers the different types of costs as well as the different types of interacting agents (resource, battery, and market agents). Experiments have shown that this approach outperforms more conventional optimisation approaches such as reactive rule-based benchmark-scenario, both in terms of cost optimisation and calculation time.
Chakraborty et al. [94] have also proposed the use of reinforcement learning in a microgrid application. In their proposal, the aim of reinforcement learning is to select a prosumer peer with whom negotiation of an electricity contract is most likely to succeed. A negotiation between two agents A and B is only successful if they find a contract that satisfies both A's and B's requirements. The results confirmed a significant increase in the success rate of negotiations thanks to reinforcement learning.
2.4.3) Synthesis:
Table 2.10 summarises the evaluation of some applications in the field of electricity, based on different criteria: it shows that machine learning models are widely used locally, at the device level. However, few applications use distribution frameworks to manage the exchange of learning weights between nodes, and in particular, the decentralised "Gossip" approach remains largely unexplored to date.
Review of collaborative ML frameworks: \Social acceptance by design:
{
[GDM1] In the previous sections, we explored existing work in the 3 main technical areas of interest to us. However, the success of a microgrid project does not depend solely on the technological aspects being taken into account. The social dimension is an orthogonal aspect that also needs to be taken into account from the outset of the design phase: taking it properly into account is vital if we are to gain the trust of potential users and a good level of member involvement once the microgrid is up and running.

As part of an early work on literature review of social acceptance in smart grids, Wolsink [95] argues for a socially constructed institutional approach and introduces the idea of common resource management, stressing the need for self-governance, flexible regulation and community cooperation in microgrids.
More recentely, Senyapar et al. [96] provided a comprehensive review of the smart grid literature, highlighting the fact that economic benefits are often more influential than environmental concerns in social acceptance. It also highlights the importance of user roles, security and AI integration, and calls for more attention to the social dimensions of smart grid adoption.
Valkering et al. [97] investigate the enablers and barriers to the social acceptance of smart energy systems. In addition to enablers such as financial incentives, we find barriers related to loss of control over the smart energy system, privacy and security concerns, and free-rider behaviour.
The series of surveys carried out by Burgio et al. [98], which focus on energy storage technologies and communities, highlight the lack of knowledge about shared storage systems and communities as one of the main barriers to their adoption by citizens.

To date, there is no implementation that applies real-time algorithms based on social acceptance criteria as such to exchange or regulate electricity. This type of algorithms, which manages exchanges and regulation, is generally based on cost, grid safety or user comfort criteria. There are, however, microgrid analysis tools based on social acceptance criteria that involve future decisions not in real time but in the longer term.
Valencia et al. [99] have implemented an integrated framework for assessing the long-term sustainability of microgrid interventions, taking into account: i) the notion of socio-technical transition, ii) sustainability through the concept of socio-ecological resilience, whether expressive or predictive, iii) the motivating factors for involving the community and the community's particular characteristics. The framework was tested as a decision-making tool on a real microgrid operating in "island" mode in Huatacondo (Chile) with the aim of improving its level of autonomy.
Santos et al. [100] have also proposed an analysis framework that aims to optimise the use of different types of located distributed energy resources, taking into account socio-economic and technical criteria. The framework was tested on a "rural" microgrid located on the island of Rottnest (Australia), which makes extensive use of renewable energy resources such as wind and solar. The framework, which was tested in combination with the Homer optimizer, yielded significant gains on societal and environmental criteria.
}
2.6) General synthesis:
To provide an overall summary of the various related work carried out, table 2.11 summarises the evaluation of the different references, taking into account the main features we are studying in this thesis: the use of coordination models, Digital Twins, Multi-Agents systems, machine learning algorithms, and the use of a decentralised distribution framework (Gossip Learning type).
Looking at this table, it's interesting to note that no research work has yet combined all the areas we're studying. Multi-Agents systems and machine learning techniques are the most widely explored in the context of smart grids, but, for example, they do not also make use of coordination models and Digital Twins.
General review 

In this section, we have reviewed some research areas that we consider essential for designing digital smart grids applications, such as energy exchange and negotiation, energy forecasting (consumption or production), and peak shaving. We therefore focused on the 4 following main areas: coordination models, Multi-Agents systems, Digital Twins, and machine learning applied to energy. Coordination models have reached an advanced level of maturity in terms of research and use interesting concepts borrowed from biology, chemistry, and physics. To date, although some power grid applications use bio-inspired coordination models, no biochemical model has yet been used in smart grid infrastructure.
Multi-Agents systems have reached a much more advanced level of maturity, since MAS applications have developed considerably in the field of electricity since the 2000s: there is a wide variety of architectures, and some applications use frameworks such as JADE to facilitate agent integration. Few applications use the much more recent concept of Digital Twin.
As far as automatic learning techniques are concerned, several algorithms have been explored for predicting electrical behaviours. Depending on the specific use, the most popular models seem to vary, but they are all well suited to highly volatile time series.
Many approaches use a distribution framework to federate model learning across nodes but most of them use the conventional Federated Learning approach, based on an aggregation server. The decentralised gossip approach is still marginal in the field of smart grids, although some applications of gossip learning are emerging for electric vehicle management.

This state-of-the-art section suggests that the different areas of research we are exploring correspond to contrasting levels of maturity in the implementation of smart grids. Multi-Agents systems as well as Machine Learning techniques are used almost systematically, while coordination models as well as collaborative and decentralised ML frameworks are still in their infancy in the fields of smart grids, although they are used for other areas.

According to the general overview of selected smart grid implementations, no approach has yet combined coordination models, Multi-Agents systems, Digital Twins, machine learning techniques and machine learning distribution frameworks. Therefore, it would be interesting to experiment with a smart grid implementation combining these different domains. Each of these research areas could bring a potential gain.
Chapter 3) Design of a coordination model and Digital Twins for smart grids:
In chapter 3.1, we have reviewed the different types of coordination models and oriented our choice towards biochemical models based on tuples to constitute an interaction environment. We have also highlighted the relatively new (but now widely developed) concept of Digital Twin: it allows to represent the real entities of the micro-grid with higher-level virtual representations endowed with autonomy, decision-making and communication capabilities. In this section, we explain how we adapt the coordination model and digital twins to represent the entities of the microgrid and make them interact.
This interaction will make it possible to exchange energy and to regulate it, for example, to avoid production and consumption peaks. These first two interaction objectives are developed in chapter 3.2 and are the subject of the first thesis contribution. In chapters 3.3, we present the use of interactions to improve the knowledge acquired by the nodes of a microgrid (the subject of the second contribution) and in chapter 3.4, the use of interactions to integrate social acceptance criteria into the behaviour of different entities (the subject of the third contribution).
We first propose to look at the adaptation of the tuple-based bio-inspired coordination model (see definition 3.5), which constitutes the main building block of this research.
A tuple-based bio-inspired coordination model (assimilated to coordination model in this thesis) provides a coordination medium, for sharing data among the coordinated entities; and coordination laws applying on the shared data (transformation, spreading) [101]. We consider coordination laws as self-organising mechanisms inspired by bio-inspired systems. The coordination model uses the stigmergy principle [102], which enables the exchange of asynchronous information between the coordinated entities using the coordination medium. Such a service has its own logic, controlled by an autonomous software agent (also called intelligent Digital Twins).
3.1) Adaptation of SAPERE coordination model:
The tuple-based bio-inspired coordination model used derives from the SAPERE coordination model and SAPERE middleware [103].
[JLF2] We decided to use the SAPERE model for the following reasons: Firstly, this model has already been implemented and used for various applications and is robust enough to cope with a large number of nodes (as was the case in its experimentation at the Vienna Marathon). In addition, the tuple-based environment provides more flexibility in the way entities interact, and the middleware library that contains the coordination law implementations not only reduces the development effort required in the Digital Twins software layer but is relatively easy to maintain and modify since we can update some existing coordination laws and add new ones if necessary (which was the case for the Gossip mechanism implementation).
Ben Mahfoudh [104] provided the most recent extension of SAPERE.
Figure 3.6 represents the SAPERE coordination model in the form currently used, which draws inspiration from biochemistry. It contains a shared virtual environment, called tuple space (see definition 3.7), in which Digital Twins can share data by submitting or retrieving data properties.
Digital Twins can thus submit and retrieve LSAs (see definition 3.8). LSAs contain tuples of properties provided from other Digital Twins or generated by the coordination law [105] (see definition 3.9) at any time.

A tuple space is a shared virtual space containing all tuples of a node. There is a shared space for each coordination platform (see definition 3.10).

A Live semantic annotation (LSA) is the tuple of data containing the Digital Twin properties that travel and evolve in the tuple space. Digital Twins can thus submit and retrieve LSAs (tuples of properties) provided from other Digital Twins or generated by the coordination laws at any time.

A Coordination law is a Mechanism that applies to entities in the environment. Coordination laws are modelled with bio-inspired design patterns [106] and classified into three hierarchical levels, as shown in figure 3.11:
-  The bottom layer (called "Basic Patterns") which contains the atomic mechanisms.
-  The middle layer (called "Composed Patterns") which contains the mechanisms using those of the lower layer.
-  The upper layer (called "High Level Patterns"), which contains the mechanisms using those of the two lower levels.
Description and composition of bio-inspired design patterns according to Fernandez-Marquez et al. [107].:
A coordination model distinguishes itself from a publish/subscribe model as the Digital Twins interacting in the system, do so using the tuple space (a blackboard) to share information in an indirect stigmergy-like manner (submitting LSAs, and retrieving LSAs that match specific criteria they are looking for). A coordination platform (which instantiates the model, see 3.12) runs in a computational node (see definition 3.13).

A Coordination platform is a system that implements and runs the coordination model. The coordination platform executes within a Grid Edge Device and communicates through the network with other coordination platforms in other Grid Edge Devices (thanks to the Spreading Coordination eco-law, a specific type of broadcasting communication described below).
The software agents generate new data on the fly by coordinating their activities through the coordination platform: they submit and retrieve data from the platform. The data submitted corresponds to:
-  data generated by an actual physical object linked to the environment (e.g., consumption or production level)
-  data exchanged among Digital Twins for managing energy (e.g., requests or offers of energy, peak shaving schedules)
-  or data provided by other services (possibly processed or transformed dynamically by self-organisation mechanisms)

A node is a local computing entity of the environment. It is associated with a network address and a set of direct neighbour nodes. In the context of the thesis, a node is associated with a building and is also called a GED (Grid Edge Device).
Coordination model:
3.1.1) Coordination laws:
Coordination laws (also called "eco-laws"(Footnote: as they derive from the SAPERE coordination model [108])), act like chemical reactions, and cause the content of LSAs, in the tuple space, to evolve over time. They transform LSAs and propagate the data between the different nodes of the system. LSAs contain data and are submitted to coordination laws, they are not themselves coordination laws. The coordination laws currently defined are the following:
-  "Bonding", which binds (provides the matching of) a Digital Twin to data provided by another Digital Twin (see definition 3.14).
-  "Decay" (evaporation), which periodically decreases the relevance of data and removes data that has become obsolete.
-  "Spreading", which disseminates information within a network across different nodes.
-  "Aggregation", which aggregates certain data retrieved from different nodes. We define the aggregation function in the Digital Twins and give it as a parameter in this coordination law. In this way, the Aggregation coordination law remains generic and independent of the aggregation function implementation.
A Digital Twin (see definition 3.15), which we also call "agent" in this thesis(Footnote: a Digital Twin is essentially a software agent [109]), is generally a detailed virtual replica of a physical object or system, also called the physical twin. A Digital Twin may also incorporate real-time changes in the physical world based on direct observations and data transmitted by the object itself, most often through sensors or IoT devices. Within the coordination model, Digital Twins go beyond real-time replicas, since they are equipped with advanced functionalities (e.g., sensing, acting, learning, negotiating, etc.) [110]. They are actual software agents working on behalf of actual devices or users. They coordinate their activities by submitting and retrieving LSAs into and from the LSA tuple space.

In the context of this thesis, a Digital Twin is an intelligent software agent that interacts on the one hand with end-user applications (or with consumption/production edge devices), and on the other hand, coordinates its actions with other Digital Twins through the coordination platform. To do so, it submits LSAs into the tuple space or retrieves LSAs from the tuple space. Digital Twins serve various purposes:
-  Interaction with the coordination platform.
-  Coordination of tasks among Digital Twins.
-  Real-time representation of their physical twin counterparts (e.g., edge consumption device data).
It is worth noting that, in general, a digital twin cannot always be equated with an autonomous software agent. Digital twins are conceived in several forms and can, on the one hand, correspond to several distinct agents and, on the other hand, correspond to agents whose behaviour does not have all the autonomy and self-adaptation faculties of an autonomous agent. Di Marzo Serugendo et al. [111] have categorised four types of digital twins: Static twin (containing only static properties), Functional twin, also called a mirror (static twin enriched with dynamic behaviour capabilities), Self-adaptive twin (functional twin enriched with capacity to acquire real-time data and update the model), and Intelligent digital twin (self-adaptive digital twin enriched with autonomy, learning, reasoning, knowledge, acting capabilities, and communication capabilities with other twins). For example, Chambers et al. [112] have used self-adaptive digital twins (with one twin corresponding to several agents) to simulate and analyse a whole range of complex phenomena linked to sustainability in urban systems. In this thesis, we use intelligent digital twins representing microgrid entities that we also assimilate to autonomous software agents, and for which a twin corresponds to a single agent in the implementation.
3.1.2) Generation of data on the fly:
The model uses the principle of stigmergy (indirect communication through the environment, in our case the coordination platform): it allows the asynchronous transformation and spreading of information provided by the Digital Twin. The coordination laws ensure the different data transformation operations in the environment. One Digital Twin can submit a data item and another Digital twin in the same node (or a remote node) can retrieve this same data item, in that form or transformed by the coordination laws. We can consider this data as the output of one Digital Twin, serving as input to another twin. As a result, this model allows Digital Twins to perform coordinated actions, as well as de facto generating data on the fly [113]. New data arise from the actions of the physical twins in the physical environment.
3.1.3) Coordination platform, nodes, and devices:
The coordination platform is the implementation of the coordination model and typically executes in a computational node or (computational) edge device (e.g., computer, raspberry, etc.).
We distinguish computational devices from energy devices, which are electrical devices that consume or produce energy (e.g., solar panel, boiler, etc.).
3.2) Modelling of Intelligent Digital Twins for energy exchanges:
We have defined different types of Digital Twins to model the behaviour of the actors who interact in a microgrid organisation at the scale of a few houses or buildings. We have thus adapted the coordination model for the needs of electricity exchanges and energy regulation. The modelling of actors (see figure 3.16) includes:
-  2 types of energy Digital Twins: the consumers and the producers. In modelling and implementation, producer and consumer twins are also prosumer twins, who can both consume and supply.
-  2 types of supervisory Digital Twins: the learning twin, which tries to predict consumption and production at the node level and the regulator twin, which manages crisis situations at the node level.
Energy Digital Twins participate in negotiations regarding energy exchanges. Negotiations involve energy demands submitted by consumers and energy offers submitted by producers. Section 3.17 provides an explanation of the specific algorithms detailing the establishment of contracts for fulfilling requests based on the received offers. Within a node, there are as many instances of energy Digital Twins as there are producers and consumers. Supervisory Digital Twins have only a single instance at the node level and are instantiated when we start the node coordination platform service. In the following, we define the role of each type of Digital Twin.
The Digital Twins that interact with each other: the consumers, the producers, the learning, and the regulator twins. The latter two are unique within a node, while the consumers and producers are multiple, depending on the number of devices connected to the node.:
For the sake of clarity, we consider the smart grid of Figure 3.18. The CLEMAP devices are our GED (or nodes, see Definition 3.19). These devices receive information about data consumed and produced. Namely, we provide one Digital Twin for each consumer or producer linked to a node, and one learning and one regulator twin per node, as shown in Figure 3.20.
We consider Digital Twins as autonomous pro-active agents that go beyond simulated models of physical devices equipped with real-time information. This corresponds to the notion of intelligent Digital Twin as defined by Di Marzo Serugendo et al. [114].
At the present time, the Digital Twins actually run in a separate device as shown in Figure 3.21. In the final version, the CLEMAP device will host a coordination platform and all the corresponding twins.
3.2.1) Prosumer Digital Twin:
A prosumer Digital Twin (also known as a "prosumer twin") represents a generic entity that both produces and consumes electrical energy. It may represent an entire household equipped with batteries or photovoltaic panels. At a given moment, a prosumer may need electricity, and at another moment, it may offer electricity to other entities.
A prosumer twin performs all the following actions already carried out by the consumer and prosumer twins.
In the current implementation, the prosumer twin covers both producer and consumer twins: it makes it easy to switch from producer to consumer and vice versa. It will soon make it possible to consume and produce at the same time. Indeed, a prosumer twin switches from one to another according to the current need and current production of energy. Concretely, this means that the two roles are managed by the generic "prosumer twin" (and the prosumer agent's class in the implementation). A prosumer twin can either represent to a 'lower level' electrical device that constantly produces or consumes energy (in which case it will always have a fixed role) or a higher-level entity that can either request energy or supply energy (in which case the prosumer twin will switch from one role to the other depending on whether it is trying to supply or demand energy).
For simplicity of notation, (and even if the implementation has merged the 2 twins into the prosumer twin) in the following of the document, we call:
-  a producer twin, a prosumer twin which is producing energy at the moment.
-  a consumer twin, a prosumer twin which needs electricity at the moment.
In the following two sections, we focus on each of these two roles, producer, and consumer.
3.2.2) Producer Digital Twin:
A producer Digital Twin (also called "producer twin") represents a device producing electrical energy at current time. It performs the following actions:
-  It reports any event concerning its activity (start, deactivation, stop).
-  It generates offers to meet the energy requests submitted by consumers.
-  After retrieving a new energy supply contract (see 3.22), it sends a confirmation to give its approval. It repeats this action, until the contract is validated or rejected.
-  After retrieving an interrupt command from the Regulator twin, it pauses its activity.
When we shut down the node, the twin de-activates itself and the coordination laws remove the twin's LSA from the tuple space. This LSA cleansing reduces the volume of data exchanged and the number of coordination law executions at each cycle.
3.2.3) Consumer Digital Twin:
A consumer Digital Twin (also called "consumer twin") represents a device that consumes electrical energy at current time. It performs the following actions:
-  It reports any event concerning its activity (start, deactivation, stop).
-  As long as it has not retrieved enough offers to meet its needs, the consumer twin verifies if its request resulted in the emission of a new energy offer. If applicable, it checks if all the retrieved offers can meet its needs. After retrieving satisfactory offers, it generates a new contract and has it validated by the producers concerned.
-  After retrieving confirmation from a producer, it updates the contract status. It stops and removes it immediately in case of disapproval.
-  After having the contract validated, it updates its satisfaction indicator to "True".
-  As long as the contract is still valid, the consumer twin has it reconfirmed periodically by the producers concerned.
-  After retrieving an interrupt command from the regulator twin, it stops the contract and pauses its activity.
Similarly, when we shut down the device, the Digital Twin de-activates itself and the coordination laws remove the Digital Twin's LSA from the tuple space.
3.2.4) Learning twin:
The learning Digital Twin (also called "learning twin") capitalises on the various events occurring at the node and generates prediction data about the state of the node.
-  After retrieving an event from an energy twin, it updates the global state of the node, including requested, produced, supplied, consumed, missing and available powers. The learning twin stores this data for later use, either by the web application to display the history of the node, or by the regulator, to detect possible over-consumption or over-production in the last recorded node state (see the node state definition in 3.23).
-  At each refresh cycle, it updates the global state of the node as well as the node's training data. The learning twin executes the learning model to regenerate a new prediction of the node's state at 5-, 10-, 30-, and 60-minute horizons. The electric devices we use do not provide predictions, they only provide actual consumption and production data every minute (full data: power and voltage), and every 10 sec (only power). The Learning twin has 5-, 10-, 30-, and 60-minute horizons, to provide predictions useful for higher-level services and for the Regulator twin.
A node (also called GED), as expressed in Definition 3.24 is a computational device.
In this thesis report, we call node state the set of 6 power variables that characterise the global current electric state of the node, i.e. the 6 following variables summed over all the electrical devices connected to the node's computing devices:
-  Wattage requested (power of demands)
-  Wattage produced (generated power) %: sum of the power produced by the various electrical devices linked to the node.
-  Wattage consumed (power of satisfied demands). As some devices demanding energy may not be supplied, we obtain the following inequality:
-  Wattage supplied (generated power used for supplies). As some producer devices may not use all the energy produced for supply, we get the following inequality:
-  Wattage missing (power of not satisfied demands).
-  Wattage available (generated power not used for supplies).
NB: In the case where there are no energy exchanges with the neighbourhood, all producers exclusively supply consumers attached to the same node and all consumers use exclusively wattage produced locally. The wattages supplied and consumed are therefore equal.
3.2.5) Regulator twin:
The regulator Digital Twin (also called "regulator twin") supervises the node to ensure stability of the grid, i.e., to perform peak shaving (avoiding excess of production or consumption). It performs the following actions:
-  At each refresh cycle, it retrieves a complete picture of the node and the twins so as to detect possible production (or consumption) overruns, or various problems that may occur.
-  After detecting a production excess or a consumption excess, it sends a deactivation order to certain prosumer twins asking them to return below the threshold.
-  Once it has detected an out-of-place Digital Twin (which no longer exists in the coordination model), it sends an alert so that all the twins delete any references linking this twin (contracts, offers, requests, etc.).
-  After retrieving a prediction that warns of over-consumption or over-production within the hour, it submits in the coordination platform a LSA that corresponds to an order to postpone certain activities to proactively avoid exceeding the threshold. This LSA is retrieved by the Digital Twin corresponding to the electrical device that should stop consuming or producing energy.
Assessing the behaviour of prosumers:
This assessment is carried out on an ongoing basis, and only if the reward allocation option is activated in the coordination platform.
At each refresh cycle, the regulator twin also evaluates the involvement of the various prosumers in the energy exchanges, with the aim of giving them rewards or penalties depending on the level of altruism and fairness in the distribution. For more details, please refer to section 3.25 on the evaluation of prosumer behaviour as part of the integration of social acceptance criteria. This assessment is carried out step by step, using the same picture of consumption and production data per prosumer that are retrieved by the regulator. Rewards are also distributed through the LSA property of the regulator, on a regular basis, when it has accumulated sufficient new results over the last production and consumption periods. These results are converted into scores which can be directly interpreted as rewards or penalties depending on their sign (positive or negative).
Chapter 4) Exchange and regulation of energy among Digital Twins:
In this section, we present the different algorithms that the Digital Twins apply collectively to meet different needs in a dynamic way: As autonomous agents, they adapt continuously to the evolution of the situation. The algorithms we describe in this section are therefore executed by the different Digital Twins and are based on the principle of self-adaptation: each twin makes decisions at its own level and interacts with the other Digital Twins through the coordination model using the blackboard principle. A result then emerges from these different actions to meet the instant need. Given that these logarithms are carried out jointly by different Digital Twins, we will describe what each twin is doing in relation to its role at the present time. For example, for two prosumers that need to exchange energy, we will describe the algorithm performed by the consumer (the prosumer that requires energy) and the one performed by the producer (the prosumer that can supply energy).
4.1) Algorithm for generating contracts:
Many situations lead Digital Twins to regenerate contracts after a sudden stop of electricity supply. By using dynamic adaptation (see definition 4.1) and figure 4.2), Digital Twins can generate a new contract: this allows them to fill a new energy gap in a relatively short time.

In the context of a distributed application, we define dynamic adaptation, as a mechanism that responds to a specific need on the fly without prior intention and without the initiative of a supervising entity. The dynamic adaptation uses the following mechanisms:
-  a semantics-based mechanism that determines the most appropriate match using data retrieved from other agents (Digital Twins).
-  a scalable and distributed technique for dynamically selecting the most appropriate way to compose the most appropriate solution at the current moment.
Figure 4.3 represents the contract life cycle in the form of an UML state-chart and Figure 4.4 focuses on the sequential aspects: it represents an example of interaction between one consumer needing 50 Watts and two producers with capacities of 13 and 60 Watts. In this scenario, the second producer has a lower environmental impact and is therefore chosen first when comparing offers. Table 4.5 displays examples of combinations of producer capacities with the resulting supplies.
Combinations of producer capacities and resulting supplies, using 2 or 3 producers to meet a demand of 50 watts. The first row corresponds to the case represented in figure 4.6 in which the second producer alone supplies the 50 watts. The last line shows a case with 3 producers.:
Dynamic representation of a contract status with UML state-chart:
Contract generation in the form of a sequence diagram. The different steps described above appear on the left.:
4.1.1) Steps followed to draw up a contract:
The following lists and describes the different stages of interaction that lead to a new contract between producers and consumers:
-  [Step 1: sending of the request by the consumer:]
The consumer twin submits its request through its LSA to report its need for energy supply.
-  [Step 2: sending of offers by producers:]
The producers retrieve the new consumer requests from their LSA. Once the requests have been retrieved, each producer then generates new elementary offers to meet the different requests. A producer applies a prioritisation policy to choose the requests to handle first. For example, a policy can classify the requests by decreasing the level of urgency, then by increasing power. The producer generates offers within the limit of its available wattage. As long as its remaining wattage is positive, it generates a new offer, even if it cannot cover all the requested wattage.
-  [Step 3: issuance of a new contract by the consumer:]
The consumer retrieves the offers that have been issued by the producers. Periodically, it checks whether all its retrieved offers meet the need. Similarly, it applies a policy that determines the offers to choose as a priority. For example, a policy can favour geothermal energies over other types of energy.
The consumer then goes through the different offers in an iterative way, following the chosen policy: as soon as the offer aggregated (from the elementary offers) meets the need, the consumer issues a new contract based on the selected offers.
-  [Step 4: confirmation of a contract by the producers concerned:]
To have the contract confirmed by the producers, the consumer twin submits it in its LSA.
Then, each producer involved retrieves the contract and checks whether it agrees or not with the terms and then submits its confirmation or refusal in its LSA: in this way, the consumer will retrieve the producer confirmation or refusal and will update the status of the contract validation.
-  [Step 5: validation of a contract by the consumer twin:]
Each time the consumer twin retrieves one confirmation, it updates the contract status to include the producer's approval (or disapproval), and then, submits the new contract content to its LSA so that all stakeholders involved have the updated version.
The consumer validates the contract only when all the producers involved have responded positively. If so, all stakeholders involved retrieve a validated contract: the contract then takes effect, and the producers can start supplying energy.
If any of the stakeholders disapprove the contract, the consumer cancels it, and a new bidding cycle begins immediately.
4.1.2) Treatment carried out by the prosumer twins:
The 2 following algorithms 4.7 and 4.8 represent the actions performed respectively by the consumer and producer Digital Twins.
NB:
-  We also consider a prosumer that currently produces energy as a producer.
-  We also consider a prosumer that currently needs energy as a consumer.
Contract generation: treatment of the consumer Digital Twin:
Comment of algorithm: Initial state: not satisfied and no contract.
Comment of algorithm: To send the consumer's request to the tuple space.
$ contract == NULL $ No contract
Comment of algorithm: Retrieve new offers from LSA.
($sumWattage(receivedOffers()) >= request.wattage $) Check if the offers can meet the demand.
Comment of algorithm: New contract
Comment of algorithm: Submit the new contract in tuple space.
Comment of algorithm: receiveProducerConfirmation() Retrieves producer confirmations.
Comment of algorithm: Confirmations issued by producers.
$ contract.hasDisagreement() $ Check for any disagreements in the contract.
Comment of algorithm: At least one disapproval: cancel the contract.
Comment of algorithm: All stakeholders have approved the contract.
Comment of algorithm: Submit the updated contract in tuple space.
Contract generation: treatment of the producer Digital Twin:
Comment of algorithm: Consumers processing table: it contains requests, offers, and contracts.
Comment of algorithm: Remove obsolete requests, offers and contracts.
request in retrieveRequestsFromLSA() Iterates on requests retrieved from LSA.
Comment of algorithm: Inserts new requests into the consumer processing table.
contract in retrieveContractsFromLSA() Iteration on contracts retrieved from LSA.
$ isConcerned(contract) $ Check if the producer is concerned by this contract (nothing to do if it is not the case).
Comment of algorithm: check if the producer can supply this contract.
Comment of algorithm: Insert this contract in the consumer processing table if not already in.
Comment of algorithm: value.
Comment of algorithm: submit the confirmation in the LSA.
Comment of algorithm: recovery of requests for which the producer has not yet issued an offer.
Comment of algorithm: Prioritization of requests for processing, according to the producer's offer management policy.
Comment of algorithm: calculation of the remaining balance in watt.
Comment of algorithm: the producer responds to the following offers as long as there is a positive remaining balance.
Comment of algorithm: Creation of a new offer by not exceeding the remaining balance in watt.
Comment of algorithm: submit the new offer in the LSA.
Comment of algorithm: refresh of the remaining balance in watts.
Principle of dynamic adaptation:
Algorithms for handling urgent requests
It may be the case that some energy device consumers should have priority over other energy consumers. For instance, we absolutely need to charge an electric vehicle, and this takes priority before a washing machine. To accommodate such cases, we defined the notion of a priority request.
In such a context, a consumer submits an energy request with a priority flag set to true. After retrieving a priority energy request, a producer ensures that current supplies do not prevent it from having sufficient availability to meet this request. If necessary, it interrupts the non-priority supplies (by stopping the contracts). It reiterates this action until the availability becomes sufficient. After having stopped the possible supplies, the producer generates and submits an offer to meet the priority demand. Different simulations have shown that new urgent requests with high wattage have a very significant impact on priority management and can even stop all existing supplies according to the demanded power value.
NB: even if the producer's capacity is not sufficient to meet the demand on its own, it contributes to meeting it and, in this way, it will have acted to respond collectively to the emergency.
4.2) Adaptation to meet a growing demand for electricity:
We have introduced a 5 % margin on the power demand in an electricity contract, so
that the consumer can adjust its consumption by plus or minus 5 % without having to modify the contract.
The advantage of this flexibility is that most of the contracts avoid stopping when the demand for electricity is constantly fluctuating. However, it has the disadvantage of reducing the producer's availability (the equivalent of the contract margin), as it cannot supply this 5 % margin.
Finally, the choice of 5 % seems a reasonable compromise to allow contracts to continue without having to solicit a large reserve from the producer. Indeed 1 % is not enough to prevent contract's breaking, while 10 % would cause an excessive energy reserve. The Digital Twins handle the supply margin as follows:
-  In case the demand decreases by more than 5 %, the contract automatically updates its power range to match the new demand. This on-the-fly adjustment does not require any verification of energy availability, as it is a decrease in supply demand.
-  In case the demand increases by more than 5 %, the consumer automatically issues a new demand for electricity to make up the difference: in this way, the consumer does not have to stop its current contract. The consumer will send a secondary demand to cover the increase, and a new "temporary" contract will respond to that demand. As a result, the secondary supply will complement the current supply. As soon as the temporary contract is validated, the consumer has two supply contracts, though, after a few seconds, it merges them automatically into one contract. The automatic merge avoids proliferation of contracts, as a consumer cannot have more than 2 contracts at the same time.
Figure 4.9 represents the generation of a temporary contract to meet an increase in demand of $300W$ on an initial contract of $1000W$; the merged contract has then a power of $1300W$.
Adaptation to meet a growing demand for electricity (+ 300 Watts): contract merging:
4.3) Prediction of local electrical state:
Learning the state of the electricity network is one of the key functions of a microgrid: in order to be able to anticipate problematic situations that may arise, it is essential to be able to predict the electrical behaviour of the microgrid in the near future. For example, in the context of peak-shaving, it is important to be able to predict when electricity production or consumption is likely to exceed a maximal threshold. The alert feedback can thus enable the regulator Digital Twin to take the necessary action to avoid the threshold being exceeded before it occurs. In this contribution, we propose that each node tries to predict each of the 6 variable intervals at the local node level using 2 different classifiers: Markov Chains and LSTM. We also define the prediction perimeter (otherwise known as the scope), which corresponds to either the node or the cluster. This amounts to replicating each prediction model for each perimeter.
In this section, we restrict ourselves to local learning and to the node perimeter, e.g. learning of the 6 variables at node level, carried out exclusively by the local node and without involving knowledge acquired by neighbouring nodes. Knowledge exchange between nodes will be discussed in Chapter 4.10, which deals with decentralized learning. This distributed approach consists of using coordination mechanisms (inspired by the gossip pattern) to share the knowledge acquired by the different nodes.
4.3.1) classification of electrical states:
In this study, we propose to apply classification algorithms to try to identify the 6 power variables that constitute the complete electrical state of the node: total power requested, produced, supplied, consumed, available and missing. For each variable, we associate a simplified state corresponding to a range of values that the variable can take. The set of states is defined in the same way for all 6 power variables of the node. The set of states represents the level of granularity of the prediction. The greater the number of states, the more accurate the prediction, but the greater the demand on resources. It should be noted that this definition of state classes is common to the various classifiers we will be experimenting with (Markov Chains and LSTM).
To keep the data volume and computation time reasonable, we limit ourselves to 7 states, each state representing an interval of values that the component of the node to be predicted can take (see table 4.11). This compromise gives a correct order of magnitude for the electrical power without overusing the calculation units. Furthermore, the division of classes into regular intervals does not necessarily reflect the actual distribution of values for each power variable. This would require further improvements which, on the one hand, would require a more in-depth study of the actual distribution and, on the other hand, a breakdown of the classes specific to each variable, which is not the case in this version, given that this contribution focuses more on the learning distribution mechanisms than on the classifier implementations themselves.
Definition of Markov states for the node prediction model. This division into states includes 5 steps of 20 % from 0 to the maximum power threshold, noted MAX_POWER. We also define 2 additional states: one for value 0 Watts and one for values beyond the threshold. For example, it can be set to 10,000 Watts for one scenario and 50,000 Watts for another scenario. This threshold variable is included in the configuration parameters of the coordination platform: its value can be adapted according to the maximum capacity of the microgrid to support the flow of electricity generated or consumed at a node.:
4.3.2) Prediction using the Markov Chains model:
The learning twin uses Markov Chains model to predict the trend of each power variable at the node level. This learning model is a stochastic model, which uses transition matrices to define the transition probabilities of all possible states.
This model has the advantage of being able to predict time series fluctuating over time, thanks to the use of a sliding window: the latter allows the model to be re-trained by focusing on the data of the last N days. Furthermore, this learning model is relatively easy and quick to implement, which facilitated its integration into the coordination platform.
4.3.2.1) Memorising observations number for each transition:
In the prediction model, we set the step size of the time variable to one minute: this corresponds to the time interval between two observations of the node state. An iteration is defined as the time interval during which observations are attached to the same transition matrix. To differentiate periods of the day while keeping data of reasonable size, each day is broken down into 19 time slots, each corresponding to a one-hour period except for [0h-6h]. We therefore have the following 19 time slots [0-6h], [6h-7h], [7h-8h], ... [11pm-0am]. If some variables vary a lot within the same range during peak hours, it might be wise to re-cut some of the time slots. An iteration corresponds to a given day and time slot. On each subsequent day, we therefore have 19 new iterations for each of the 6 components.
NB: the implementation does not yet integrate meteorological variables (temperature, pressure, humidity). We therefore limit ourselves to one transition matrix per time slot and per component (6 x 19 = 114 matrices for a given scenario and node).
Every minute, the learning agent refreshes the state of the node, calculating the total wattage requested, produced, supplied, consumed, missing and available. Each watt value corresponds to one (and only one) Markov state. For each of the 6 components, the learning agent updates the state transition corresponding to the pair [previous Markov state (which has been memorised), current Markov state]. The number of observations associated with the current iteration and the transition [previous Markov state, current Markov state] is then incremented by 1.
4.3.2.2) Feeding transition matrices:
For each component and time slot, the transition matrix results from the number of observations collected over the last "N" iterations: N corresponds to the learning window associated with the Markov Chains. This means that we restrict ourselves to the iterations of the last "N" days. In our implementations, the default learning window is 100.
The transition matrix is calculated in two steps:
-  Sum of the number of observations for each transition (previous state, next state) within the learning window.
-  Normalise the values obtained to obtain transition probabilities: number of observations state $i$ to $j$ / Sum (number of observations in line $i$)
Figure 4.12 shows an example of a normalized transition matrix obtained. Each row number $i$ contains all the probabilities of transition from a state $i$ to a state $j$ (contained in the cell $i$, $j$)
Example of transition matrix for the requested variable taken in the time range between 6 and 7 am.:
4.3.2.3) Prediction calculation:
For each power variable, the learning twin computes a prediction at a target time horizon, using the transition matrices. At each iteration step, the model multiplies the probability vector by the relevant transition matrix. The result of the prediction is a 7-component vector containing the probabilities of reaching each Markov state starting from the initial state (there is one component per Markov state).
After each prediction, it stores the result in the database. Since it stores the actual state of the node at each refresh, it can reconcile a posteriori the prediction generated at time $t_1$ with the actual perceived state at $t_2$. For each prediction, it thus obtains the assumed Markov state and the actual Markov state at prediction horizon $t_2$. The learning twin also stores the actual state to facilitate the evaluation of the predictions.
State transition matrices are constructed from the experiments collected, noting the transition [$Previous state$, $New state$].
4.3.2.4) Initialising transition data:
For the model to be usable across all time slots and components, the transition matrix generated must be complete, i.e. without any "empty" rows (an empty row contains only 0s). This means that for all 19 time slots and 6 components, each state must appear as a starting state in at least one transition containing at least one observation.
We generate the initial number of observations at the test simulator level, which has access to the historical production and consumption database of the different electrical devices.
The initialisation function proceeds as follows:
-  on the history of production/consumption data for electrical appliances for the previous N days, we calculate the values of 6 variables every minute on the history (using a calculation that simulates probable electrical exchanges between producers/consumers)
-  calculate the cumulative number of observations for each transition, at each time slot, for these 6 variables
-  complete the values on the remaining empty lines by adding an "artificial" observation to the most explored state around the line
4.3.3) Predictions using LSTM model:
We use the LSTM learning model as an alternative to Markov Chains to predict the power variables of the node state. Indeed, LSTM is known to provide excellent performance for time series learning and to be less sensitive to high variations in time intervals.
Given that these two models are implemented, the learning twin can use either Markov Chains or LSTMs, depending on the settings chosen in the configuration of the coordination platform.
4.3.3.1) The general principle of recurrent neural networks:
LSTM (Long Short-Term Memory) is a sub-category of recurrent neural networks (RNN). The general principle of a recurrent neural network is that the current state at time $t$ depends on the previous (which is not the case for classical neural networks or Markov Chains). As shown in figure 4.13, at each computing cycle, the cell receives not only the input data, represented by X but also the state memorization from the previous cycle, represented by $h(t-1)$.
Recurrent Neural Network:
4.3.3.2) Longer-term memory by LSTM networks (Long Short-Term Memory):
Recurrent networks face the problem of under-representation of older states in the model weights (a problem known as "vanishing gradient"). The LSTM sub-category attempts to overcome this problem by storing memory information over an extended period. On the one hand, an LSTM network adds a backup of the long-term state (called c) in addition to the short-term state $h$ already present in Recurrent Neural Networks, and on the other hand, an LSTM cell enables more precise control of the flows coming from the inputs and the stored state, by introducing filters on 4 independent gates. Forget gate: decide what information to discard from a previous state. As shown in Figure 4.14, the stored state of an LSTM cell is then composed of the short-term state (h) and the longer-term state (c), and the flows are processed from the following 4 gates:
-  Forget gate: decide what information to discard from a previous state.
-  Input gate: decide which pieces of new information to store in the current state.
-  Candidate gate: decide what data to write to the cell-state.
-  Output gate: decide which pieces of information in the current state to output.
These portals produce vectors which are then combined to produce output signals and stored states (which is composed in "h" and "c" signals).
LSTM cell composed with 4 different gates that consider input signals, recent memory and non-recent memory of the cell state.:
4.3.3.3) Adaptation of LSTM networks for node state prediction:
In the same way as for Markov Chains, each of the 6 power variables is predicted independently. An instance of the LSTM model is dedicated to each variable and each model instance consists of two layers, each containing 50 LSTM cells. We should note that the number of layers and cells per layer can be easily modified in the initialization of the LTSM model.
Each instance learns from the pre-compiled historical data of the variable concerned.
In terms of implementation, the LSTM model uses the Keras library developed in python and runs on a separate service. The learning twin interacts with the various LSTM models via a REST server. In this way, the Digital Twin can ask the "prediction" REST server at any time to:
-  initialise an LSTM model based on the history of a variable (e.g. consumption at node level).
-  train the model.
-  update model weights from parameter values.
-  retrieve updated model weights.
-  calculate predictions for given horizons.
Although the calculations are performed from another server, the learning twin manages the model data and the resulting predictions in the same way as for Markov Chains.
Predictions of the cluster node state
In section 4.15, we presented the general mechanism for learning state variables at the node level. However, the learning twin also manages the learning and prediction of these same state variables at the cluster level. We define the cluster as the set of all nodes that are directly or indirectly linked to the local node.
As we will illustrate in figure 4.16, the learning twin manages two instances of learning models, one for totals at the local node level and one for totals at the cluster level. Each learning model instance is independent of the other: in fact, each model instance has its own dataset and manages its own training and predictions. It should be noted that cluster prediction is only performed if prediction is enabled in the coordination platform settings. The choice of learning model (currently Markov Chains or LSTM model) is also indicated in the platform configuration: depending on these parameters, the learning twin instantiates an LSTM model or a Markov Chains model. In both cases, the learning twin applies the same general procedure as for local node predictions (with a few minor specificities in certain treatments linked to the cluster model).
4.3.4) Initialisation processing:
In the same way as for learning the state of the local node, the learning twin feeds the learning model linked to the cluster for the 6 power variables to be predicted: these same variables (power produced, demanded, supplied, consumed, missing and available) are summed over the complete cluster. On initialisation, the simulator retrieves the power history supplied by the various devices, then calculates the values of these 6 variables for each device. To obtain these values at cluster level, it sums all these variables without filtering on a specific node, as is the case for calculating the history of the local node. When each coordination platform starts up, the learning twin retrieves the cluster history, which is then injected into the learning model associated with the cluster. The model is then trained a first time, in a similar way to the model used to predict the state of the local node.
4.3.5) Periodic treatments:
At regular intervals, the learning twin feeds the model dataset with the next total values obtained from these 6 power variables (every minute, at each refresh cycle). However, these totals are not obtained in the same way as for the state of the local node: instead of calculating these variables for all the prosumer events received from the whole cluster and then applying a sum to all the calculated values, the learning twin simply retrieves the cluster total which is already calculated by the aggregation coordination law. To be more precise, each learning twin attached to a node calculates the total corresponding to its local node only and the aggregation coordination law aggregates the totals submitted by the different learning twins (one instance of learning twin per node).
Figure 4.17 shows an overview of how the cluster total is calculated. In this example, the cluster contains 4 nodes (from $N1$ to $N4$), each learning twin from $N1$ to $N4$ submits its local total and then the aggregation coordination law aggregates all the totals received from $N1$ to $N4$, applying a sum on each power variable. As we will explain in section 4.18, the aggregation mechanism allows any aggregation operator to be applied to any class: in this case, a sum is applied to all the variables contained in the $NodeTotal$ class, which models the state of the node containing its 6 power variables.
The following actions are similar to those used to train the local node state. To be more precise, at each refresh cycle, the learning twin:
-  Retrieves the cluster total from the aggregation result.
-  Updates the model data set.
-  Invokes new predictions of the 6 state variables, at different horizons. All these predictions are also stored in the database with the scope value "CLUSTER" instead of "NODE".
-  Applies a reconciliation operation to past predictions, comparing the assumed state with the actual state.
At start-up and at a frequency that depends on the model type, it invokes the model training.
Calculation of the total at cluster level by aggregating the totals obtained for each node. This figure shows only the two power variables "produced" and "consumed" out of the 6 power variables.:
Algorithms for Peak shaving
Peak shaving aims at providing stable conditions for the grid. Decisions are taken either based on actual grid conditions or based on predictions.
4.3.6) Management of production and consumption peak overruns:
We should note that regulation is carried out entirely by the regulator twin (and not by an external or manual system). This Digital Twin acts locally and its impact is limited to the other Digital Twins connected to the same node.
At regular intervals, the regulator twin retrieves the node global state that the learning twin recently stored in the database. From the different totals, the regulator twin detects the production and consumption flows that exceed the alert threshold.
If the total produced or the total consumed electricity exceeds the threshold, the regulator twin applies a policy to determine the Digital Twin to stop first so that the node can get back under the alert threshold. The regulator twin thus obtains an ordered list of Digital Twins to stop. For example, the regulator twin can stop by order of priority the producers with the highest power.
The regulator twin stops one by one the Digital Twins contained in this list, as long as the updated total remains above the alert threshold (see algorithm 4.19).
Choice of producers to deactivate (run by the regulator):
Comment of algorithm: Designate producers to stop first.
$ wProduced - sumWattage(listProducersToStop) > THRESHOLD$ Check if the expected power after the producer shutdown still exceeds the threshold.
Comment of algorithm: Add the producer to the list of producers to stop.
4.3.7) Avoidance of over-production or over-consumption based on predictions:
The regulator twin periodically retrieves the result of the last prediction made by the learning twin (see figure 4.20).
When the learning twin predicts a peak within the hour, the regulator determines the list of Digital Twins to reschedule to reduce the node production (or consumption) with the aim of returning to 20 % below the maximum threshold. The regulator therefore chooses a policy to prioritise the Digital Twins to reschedule, for example, by ranking them by increasing wattage.
After completing the rescheduling table, the regulator submits it through its LSA and then all Digital Twins retrieve it. The Digital Twins concerned by the rescheduling then advance their end of activity date so that they stop 10 minutes before the scheduled peak time. By default, they will be able to resume their respective activities only after the end of the shutdown period. For example, in case of overproduction, the postponement of production directly concerns certain producer twins. Consequently, it also impacts the consumers supplied by the producers in question, since their production is halted.
Mechanism of peak shaving with the replanning of activities.:
From a sequential point of view, the peak avoidance mechanism works as follows:
-  [Step 1:] the learning twin calculates the probabilities of threshold crossing risk and submits them in its LSA.
-  [Step 2:] the regulator retrieves the predictions previously submitted by the learning twin and detects the high probability of overshot.
-  [Step 3:] the regulator determines the rescheduling table of the energy supplies to postpone. The regulator then submits a rescheduling table in its LSA.
-  [Step 4:] the concerned Digital Twins retrieve the re-scheduling directives sent by the regulator: they then defer their consumption or production activity.
4.4) Preparing for model evaluation:
4.4.1) Definition of evaluation metrics:
The first objective of the contribution is to be able to satisfy a maximum number of consumers in a relatively short period of time, while avoiding threshold overruns in terms of production or consumption. To do this, we evaluate the 2 following metrics:
- [Max response time:] the maximum time during which a request is not satisfied while the total power available at the node can still meet this request (see 4.21 and 4.22 formulas).
- [Failure rate:] quantifies all unfulfilled requests over the event history since the beginning of the scenario. It considers the energy not supplied during the test period. It is the ratio of the demands not supplied (in kWh) even though there is sufficient energy, divided by the total requested in kWh over the total duration of the test (see formula 4.23). Note that this ratio does not consider unsatisfiable requests, e.g., unsatisfied requests whose power exceeds the remaining availability of the node.
The maximum response time is the maximum of the maximum response rates obtained on all requests for electricity (computed in4.24).
4.4.2) Maximal response time for a given request:
For each request, the $requestResponseTime$ function evaluates the maximum response time for a given request: it corresponds to the time elapsed at the first moment when the request started to be satisfied.
4.4.3) Failure rate:
The failure rate is the total energy requested and not provided divided by the total energy requested. To compute the total energy, we decompose the total period into elementary time slots in which we retrieve all corresponding requests statuses (see $historyEvent$ element called $hReq$ in the formula). On each elementary request, the energy requested is equal to the power requested multiplied by the elementary duration.
4.4.4) Definition of different producer's policies:
For a producer twin, the offer policy defines the priority order of the requests to process. During the tests, we applied different policies of request prioritisation to compare their performances:
-  The "Random" policy, for which the producer sorts the requests randomly for the same priority level.
-  The "Prioritisation" policy, for which the producer sorts the requests by consumer node distance, decreasing urgency level, decreasing alert duration, and increasing power. The alert duration is the time (in seconds) during which the demand remains unsatisfied while the power produced is sufficient.
-  The "Hybrid" policy, which uses by default the random policy. It automatically switches to the prioritisation policy when an unmet request reaches the 8-second alert threshold.
4.4.5) Definition of test scenarios:
We have defined and implemented different scenarios to test the coordination model under different conditions. These scenarios identify the challenges that the Digital Twins may face in meeting power requirements or in regulating the state of the nodes. Some scenarios focus on specific problems while others attempt to replicate realistic conditions. We define the different types of scenarios as described in the following subsections.
4.4.5.1) Scenarios for technical tests:
They are ad hoc scenarios that validate the reliability of a particular algorithm, by running Digital Twins with very specific conditions, on a short duration: for example, a technical test evaluates the capacity of all Digital Twins to satisfy simultaneous energy requests. It can also evaluate the ability of Digital Twins to manage a threshold overrun or to manage a new urgent request that implies stopping certain ongoing supplies. The technical tests also include simulations of over-production, over-consumption, and the tragedy of the commons. During the evaluation, we repeat these tests dozens of times to obtain more meaningful results.
4.4.5.2) Realistic scenario:
This scenario seeks to replicate actual consumption and production based on household production and consumption statistics [115]. The statistical data includes the average power consumed or produced at each hour of the day and for each category of appliance in a home.
The simulator performs periodic processing for each device category:
-  Random assignment of a total consumption (or production) target power that is close to statistical averages.
-  Adjustments of device powers to reach the total target (by modifying, starting, and stopping some devices).
We should note that, in the "realistic" scenario, we have pushed the granularity to the maximum by using one Digital Twin per device. This does not necessarily correspond to the configurations commonly used today. However, the model allows for the representation of aggregations of devices by defining a new higher-level category in the reference data.
4.4.5.3) Realistic scenario in degraded mode:
The "degraded mode" is a variant of the "realistic" scenario: this scenario contributes to generating shortages by constantly reducing producers' wattage by half compared to the values of the realistic scenario. In this way, it tests the resilience of Digital Twins in more difficult situations.
4.4.5.4) "living-lab" Scenario:
Since May 2022, we have been collecting measurement data from the living laboratory "Les Vergers", located in Meyrin near Geneva. Seven Clemap smart meters installed in 4 different buildings measure the power data of different electrical appliances (see figure 4.25).
Collection of consumer power history
Each smart meter collects power measurements every 10 seconds and sends more complete measurements every minute (including voltage and amperage). This power measurement data is first sent to a cloud server (Exoscale) in the form of history as binary files (one per smart meter and per day and hour).
Collection of producer power history
SIG provides power measurements for its own power supply and that of the solar panels, in the form of a text file containing power averages corresponding to 15-minute intervals. These files are manually copied to the same cloud server.
Copy to database
To facilitate the use of the measurement data, we have set up a script that copies and stores the measurement history in the database accessible from the coordination platform (the section 4.26 describes this database). In this way, we can replay any real scenario that has taken place in the living lab since May 2022. For example, we can run the scenario starting on September 1, 2022, at 1:00 PM: the producer and consumer Digital Twins will retrieve the corresponding demands and productions (in Watts) that we have registered in the database for the corresponding moment.
Architecture of the living-lab of "Les Vergers":
4.4.6) Defining the microgrid topology:
The coordination model used ensures interaction between Digital Twins located at different nodes. The general topology of a network is defined as shown in figure 4.27: an instance of the coordination platform runs on each node, which is directly linked to several neighbouring nodes. All nodes can communicate with each other either directly or indirectly. We can define any mesh topology between the nodes, the only requirement being to run an instance of the coordination platform on each node (which may or may not be physically on different hosts). At each execution cycle, the spreading coordination law propagates the LSA data located at the current node to all direct neighbour nodes (and thus to the entire network after a certain number of cycles). We should note that each node receives LSAs from neighbouring nodes on a TCP-IP socket server, in the form of serialised objects. Furthermore, a node defines its neighbours in emission only. Consequently, neighbours can be different in transmission and reception: it propagates LSAs to nodes in its own neighbour list, but it can itself receive LSAs from other nodes not included in its neighbour list.
General diagram of a topology with instances of the coordination platform communicating with each other.:
4.4.6.1) Configuring nodes:
In a test simulator, we have made it possible to configure the list of nodes and assign a node to each device according to its location. This configuration is written as a mapping table in a configuration file as shown in Figure 4.28. In this configuration file, a node is associated with each location: as each device has a location defined in the test dataset, it can be assigned a node via this mapping table, which means that the Digital Twin representing this device will be created in the instance of the node's coordination platform. For this example, any device located in the gymnasium will be represented by a Digital Twin of node N3.
The $maNodes$ table in the same file contains the address of the REST server for each node. For example, the REST server for the N3 coordination platform is supposed to be running on localhost, port 9393.
Note that to run the scenario, we need to launch as many instances of the coordination platform as there are nodes used (one for each node) and then, a single instance of the test simulator. In the example shown in figure 4.29, we therefore need to launch 4 instances of the platform (from N1 to N4). Since the simulator sends REST requests to each platform instance, these must all be launched before the simulator is started. At launch, the simulator retrieves the list of devices to be integrated into each node and requests the server of each coordination platform to initialise these devices. Digital Twins are then created for each node's coordination platform, and energy exchanges are carried out across the set of nodes.
Nodes configuration by location:
As shown in Figure 4.30, the configuration of each node includes the addresses of its direct neighbours. This can be modified when the server is running. In this way, it is possible to define and update the topology of the various nodes. The network graph can be made "full" by attaching all the other nodes as direct neighbours to each node.
Using scenarios from the Les-Vergers living lab, we have experimented with distributing the devices in a set of 4 nodes, with one node for each geographical location: the primary school, the gymnastic room, the after-school room, and the under-ground. We have also experimented with 2 extreme network topologies:
-  The minimal topology (see figure 4.31), which is of chain type, for which a node has 2 neighbours, or a single neighbour at the end of the chain.
-  The maximum topology (see figure 4.32), which is of 'full' type, for which all the nodes are completely interconnected.
The experiments confirmed that the chain topology has the advantage of reducing the number of data transfers between nodes but, on the other hand, increases the number of cycles required to exchange energy between Digital Twins, particularly when the consumer and producer are at the two extremes of the chain.
Conversely, the "complete" topology increases network traffic drastically but reduces the number of cycles required to exchange energy.
Chained graph topology: each node has two direct neighbours (with the exception of nodes at the end of the chain, which have only one neighbour).:
Full graph topology: each node has all other nodes as direct neighbours.:
4.5) Results:
In this section, we present the evaluation of different functionalities provided by the interaction of Digital Twins through the coordination model:
-  energy exchanges
-  energy regulation
-  prediction of energy production or consumption
4.5.1) Assessment of energy exchanges:
Since the primary objective of the contribution is to be able to satisfy as many energy needs as possible within the limits of available resources, we have tested the coordination platform by simulating different types of scenarios (defined in section 4.33). Each scenario focuses on a particular aspect to be assessed and uses specific data sets (purely fictional, real, or realistic).
4.5.1.1) Results of technical scenarios:
These tests are based on purely fictitious random scenarios designed to create a situation with specific difficulties to overcome. Table 4.34 shows the results obtained with one of these scenarios, which periodically generates large numbers of Digital Twins at random. It favours requested wattage over produced wattage, which also causes energy scarcity at the node and thus makes contract generation more difficult. The difficulty of fulfilling requests also increases with the number of requests arising at the same time.
Best, worst, and average results obtained on 10 technical tests performed for 10 minutes. The prioritisation policy used consists of sorting energy requests as follows: distance from the consumer node (in ascending order, to favour local requests), urgency level (in descending order), warning duration (in descending order) and power requested (in ascending order). For example, for two requests from the same node and with the same urgency level, the one that has been in warning for longer will be given priority.:
The prioritisation policy provides the lowest maximal response time and the lowest failure rate. The use of randomness results in very long alert times (average at 141 seconds, maximum at 181 seconds).
Given the high volume of requests, it is more difficult to provide offers that meet the demand with the highest level of alert. Indeed, it usually takes several offers for the same request (often more than ten) to fulfil the requested amount of energy. In the case of a random policy, the concerned consumer therefore has a lower probability of obtaining sufficient offers when compared to the prioritisation policy.
The prioritisation policy by alert level focuses on the requests to process first. This is the safest strategy, although it sometimes entails longer response times, since the Digital Twins all focus on one consumer, the most "on alert" at the current moment.
On simpler scenarios, the hybrid policy achieves better results because it tries to keep response times very low by partially using randomness, while removing the risk of getting very long times by dynamically switching to the prioritisation policy after a certain alert threshold.
This table shows that the hybrid policy also obtains very degraded performance when the number of Digital Twins and the difficulty increase.
4.5.1.2) Tests on the 3 main scenarios: realistic, degraded, living-lab:
Table 4.35 compares the results of maximum response time and failure rates obtained on the 3 main scenarios described in section 4.36: "realistic, "degraded", and "living lab". The "prioritisation" and "hybrid" policies seem to obtain comparable response times while the random policy still obtains worse response times, although they are acceptable compared to the very poor response times obtained in the "random" scenario.
In the various tests of the "realistic" scenario, it turns out that shortages are less frequent than in the "random" scenario. Indeed, based on values close to the statistics provided, the quantities produced generally meet the needs. As a result, shortages are less frequent, and the random strategy is less penalised by the difficulty of obtaining a contract when there are multiple demands to satisfy at the same time.
The results we obtained on the "degraded mode" confirmed a very clear deterioration in the performance of the random policy when shortages are frequent or systematic. This deterioration in performance also concerns the hybrid policy, but to a lesser extent.
Our results on the "living lab" scenario also confirm a significant deterioration for the random and hybrid policies, but more moderate than the deterioration observed in the degraded mode.
The tests carried out from a real situation allow us to confirm once again that we have obtained the best performance with the prioritisation policy.
For the different scenarios, we note that the failure rates follow the same trend as the response times.
Results obtained with the following 3 scenarios: "realistic", "degraded mode" and "living-lab", tested for 60 minutes. We ran each scenario with the 3 producer policies: Prioritisation, Random, and Hybrid policies.:
4.5.1.3) Interpreting the results:
The different results show that the choice of the supply management policy has a significant impact. A "pure" random policy can lead to very poor performance, especially when conditions become more difficult to generate a contract. We should therefore avoid it. A hybrid policy sometimes achieves better results when Digital Twins are not subject to scarcity constraints. By choosing the most appropriate policy for the situation, it is possible to achieve good response times with failure rates on a kWh basis below 1 %. The maximum response times are generally higher than 10 seconds. This is due to the execution time of the self-composition mechanism:
-  There is a delay in the propagation of information between Digital Twins. Indeed, the coordination law engine waits one second after the start of the previous cycle before executing the next cycle.
-  There are a high number of steps required to validate the contract.
4.5.2) Assessment of energy regulation:
4.5.2.1) Regulation in the present moment:
Simulations of fictitious scenarios have confirmed that the model is capable of dynamically managing overproduction and overconsumption. After a producer is deactivated, the other prosumers generate new contracts to satisfy the interrupted supplies. For example, a scenario tests overproduction by starting from an initial state below the threshold (see figure 4.37). The regulator twin chooses the policy which stops the maximum wattage agents first. In this scenario, a new 1000 Watts producer (nÃ‚Â°4) is added to the node, which triggers a threshold violation: the regulator twin then stops producer 1, which has the highest wattage. As a result, the contracts of consumer_1, 2 and 3 are stopped, but Prod_4 has sufficient wattage to recover the supplies (see figure 4.38). New supply contracts are then dynamically regenerated in the next 4 seconds (see figures 4.39
).
Overproduction scenario: initial state:
Overproduction scenario: final state. The line with the blue background indicates a deactivated prosumer (Prod_1).:
overproduction scenario: history of events:
comment
4.5.2.2) Proactive regulation:
Tests carried out on several scenarios have confirmed that the regulator twin is capable of postponing certain activities when the learning agent predicts that the threshold will be exceeded within the hour (overproduction or overconsumption). In the evaluation, we check that the replanning does indeed provide for the current activity to be stopped at $t2$ - 10 minutes ($t2$ being the time at which the threshold is expected to be exceeded) and that the re-planned activity covers at least 20 % of the maximum threshold (i.e. 600W).
Figure 4.40) shows a scenario starting at 21:51 with 4 producers: the first producing for a long period while the next 3 will stop producing at 23:51. The learning agent then predicts that the threshold will be exceeded at 22:52. The regulator twin then reschedules the activity of some producers (prod_2, prod_3 and prod_4) to remove at least the equivalent of 600 W from the total produced. In this example, it decides to defer the lowest power producer first (i.e. Prod_2). Following the regulator's derogation, producer Prod_2 has brought forward its production shutdown time from 23:51 to 22:42, i.e. the predicted time - 10 minutes. (see figure 4.41 and 4.42). Consumer 2's contract is also affected, as it was initially scheduled to stop after 22:42.
NB: Consumer_4, which is also supplied by prod_2, is not impacted as its contract was initially due to end before the shutdown time.
Overproduction forecast (initial state):
Overproduction forecast (final state):
Overproduction forecast (events history):
4.5.3) Assessment of local predictions:
The success of proactive control depends on the reliability of the predictions of consumption and production, which is why it is also relevant to evaluate the predictions of each of the variables making up the state of the node (including production and total consumption). To assess the quality of the prediction, we run the coordination model with the realistic scenario which corresponds to actual household production and consumption. The principle of this evaluation is to compare the predicted state at $t1$ with the actual state of the node at the prediction target time ($t2$ = $t1$ + prediction horizon).
All predictions are calculated by the learning twin and stored in the database. Each prediction record also includes the actual state at the horizon, which is filled in a posteriori by the learning agent at the time of the prediction horizon ($t1$ + prediction horizon). In this way, we can assess the average accuracy of predictions for each variable, each period and each horizon.
4.5.3.1) Accuracy obtained with the realistic scenario:
Table 4.43 provides the average success rates of predictions by horizon and using a sliding window of 100 days.
Accuracy obtained for the realistic scenario (based on statistics) using the Markov Chains model with a sliding window of 100 days.:
Accuracy obtained for the realistic scenario:
In general terms, the results show that the accuracy obtained is not very high. This is due to the difficulty of predicting a relatively complex scenario involving a hundred or so agents that are generated randomly.
Furthermore, we can see that the missing and available wattage have lower reliability rates. This can be explained by the fact that the available or missing total is subject to more uncertainties, due to supply disruptions which have an immediate impact on its value, which is not the case, for example, for the total produced or demanded. These two variables are therefore more difficult to predict.
4.5.3.2) Accuracy obtained with the living lab scenario:
Accuracy of hundreds of predictions per horizon, obtained for the realistic scenario (based on statistics) using the Markov Chains model with a sliding window of 100 days.:
Accuracy obtained for the "living-lab" scenario:
We can observe a certain difficulty in predicting energy production, even over very short time horizons. This can be explained by the very high volatility of photovoltaic production in the living-lab of "Les Vergers", particularly during the middle of the day. We could improve this performance by integrating solar radiation into the characteristics of the prediction model. The same applies to available power, which is closely related to the power produced (available power is equal to the difference between the power produced and the power supplied).
Chapter 5) Software architecture and implementation:
In this chapter, we describe in detail the architecture of the various software components and how they are implemented. In fact, the coordination model operates on a distributed architecture, spread over several nodes, and on each node a single instance of the coordination platform operates with several software components that interoperate with each other.
In the implemented model, the coordination platform is the process that runs the coordination model at the node level, e.g., at a single household: it initialises the Digital Twins that then evolve autonomously in the environment. We call a client process a process that sends requests to a node coordination platform to update the state of digital twins: this can involve creating, updating or deleting a digital twin, or invoking or stopping one of their current processes or modifying specific information about them. A client process can be a test simulator or a web application that monitors the smart grid at the node level (see figure 5.1).
A node coordination platform service uses the SAPERE core as a coordination model.
The architecture of the model operating at node level can therefore be broken down into three layers:
-  The "derived" SAPERE core: this is the library that manages the tuple space and the coordination laws.
-  The service layer: this is the process that executes the model at the level of the nodes (the Digital Twins and their environment). It uses the SAPERE kernel.
-  The client layer: these are the processes that send requests to create, modify and delete Digital Twins.
Software architecture, in a complete development environment.:
5.1) The derived SAPERE Middleware:
The middleware derived from SAPERE manages the tuple space, which is the coordination medium where the data submitted by the various twins (also called agents) evolves, and the various coordination mechanisms that transform and propagate the data in this environment. In terms of execution, the derived SAPERE Middleware is a library implemented in Java and not an executable in its own right. This library is invoked by the coordination platform service at each node level. The middleware library therefore defines the following core functionalities:
-  The node coordination medium (the tuple space), which is the environment in which the coordination laws are applied.
-  The node configuration (its own location and the location of each of its neighbours)
-  The LSA structure of a twin object and its properties.
-  The different coordination laws and their mechanisms.
-  The LSA server, which receives LSA objects from neighbouring nodes. (We should note that this is not the same server as the REST server). The contents of LSA objects are serialised and sent via TCP-IP to the neighbour node according to the node configuration.
It is important to note that this layer (unlike the higher-level layers) defines mechanisms that are totally independent of the domain of use (the latter is energy in the case of this thesis but could be different in another usage).
5.1.1) LSA structure:
An LSA comprises all the data that an agent (also known as a Digital Twin) exchanges with other agents across the tuple space.
5.1.1.1) Agent authentication:
Thanks to the Bonding and spreading coordination laws, an LSA submitted by an agent is likely to be received and taken into account in the processing of a host agent located in the same node or in a neighbouring node.
It is then important that the agent at the origin of this LSA can be correctly identified by the host agent, whether it is its profile (agent type) or its location (attached node). To meet this need, the LSA then includes this identification object which includes the following attributes:
-  agent name (word)
-  agent type (word): Corresponds to the classification of the Digital Twin: prosumer, learning twin, regulatory twin.
-  this encrypted key is only used if the agent authentication by key option is activated on the coordination platform.
-  node location (of class $NodeLcation$, which contains the node name, the host IP address, the port of the REST server as well as the port used by the server receiving LSAs from neighbouring nodes).
This structure is present in all LSAs and can therefore be used to authenticate the agents responsible for any data circulating through the coordination model.
5.1.1.2) Synthetic properties:
The synthetic properties of an LSA include the "key" information characterising the complete state of the LSA in the tuple space. This information is updated by the various middleware coordination mechanisms according to the initial state of the LSA and the evolution of the LSA's situation during the various transformations it undergoes. These generic properties are modified exclusively by the middleware layer and not by the higher layers that manage the digital twins and the coordination platform service. Figure 5.2 lists the various synthetic properties of LSA in tabular form. The last column shows the coordination law(s) that make use of this synthetic property.
Synthetic properties of an LSA that are currently used by the 4 coordination laws and the LSA reception server.:
The 3 lines in dark grey correspond to the synthetic properties added as part of this thesis:
-  PATH: stores the network addresses reached by an LSA (to extend a broadcast to nodes that have not yet received an LSA)
-  AGGREGATION and AGGRATION_DATE: used to implement the aggregation mechanism (specifying the properties to be aggregated and recording the last aggregation time).
5.1.1.3) Object properties:
This is the list of properties submitted by the agent, which will then be propagated and transformed by the coordination laws in tuple space. Each property (belonging to the $Property$ class) contains the following attributes:
-  $name$: This label identifies the property in the Bonding eco-law treatments as well as in the treatments carried out by the agents receiving these properties.
-  $value$: the corresponding value: must belong to any serializable class.
-  $ip$: the network address where this property is submitted
-  $query$: a specific request identifier (in case a receiver agent wants to apply a finer filter on bonded LSA). We should note that an LSA can contain several properties with the same name, in which case the "query" attribute can differentiate between them.
-  $aggregatedValue$: contains the result of the last aggregation, if an aggregation has been applied to this property. This value is set to null by default.
It should be emphasised that the value is an object of any class, which allows to ensure maximum flexibility in data exchanges between different Digital Twins. The only constraint on the class used is that it must implement the Serializable interface in order to be able to send and receive the contents of an object across the TCP-IP network. However, if the many objects submitted have a huge size, a limiting factor may arise at the bandwidth level in data exchanges between agents (Digital Twins).
Distinction between object properties and synthetic properties
It's very important to distinguish synthetic properties from object properties, which we describe immediately above. Synthetic properties, which are identified by constant keys, correspond to information managed exclusively by the middleware, while object properties, which ware are describing here, correspond to the various data submitted by the Digital Twins in the tuple space: these data properties are managed by the Digital Twins themselves in the upper-level layer. Synthetic properties can be considered as system properties at the level of Digital Twins.
5.1.1.4) Names of bonded properties:
This list identifies the names of properties an agent wishes to receive from other agents. It enables the Bonding law to complete all the LSAs the agent wishes to scan (the LSAs for which at least one of the properties whose name is present in this list of names). For example, an energy consumer is interested in receiving electricity offers, identified by the "OFFER" property label in an electricity producer's LSA. The consumer agent will thus include the name "OFFER" in this list, to receive LSAs containing offers of energy.
5.1.2) Generic agent modelling:
As shown in the class diagram 5.3, this middleware library defines the general classes of the different agents (or Digital Twins) that interact via the coordination model. The general definition of the agent uses 3 different classes that inherit from each other: this avoids concentrating the implementation of all the problems to be managed in a single class. The abstract class $SapereAgent$ is extended in the upper layer, which contains all the classes of digital twins, and these classes define the properties, information exchanged, and behaviours specific to each type of digital twin.
Generic classes of agents (or digital twins) that interact through the coordination model:
5.1.2.1) Agent class:
The $Agent$ abstract class models common properties and behaviours of all agents that interact through the coordination model. It groups together the following information common to all agents:
-  $agentName$ (of class $java.lang.String$): Agent name, unique to each agent.
-  $lsa$ (of class $LSA$): An object of $LSA$ class, described previously in section 5.4, contains a tuple of properties that evolve in the tuple space. The LSA instance also contains the agent's authentication object, which identifies the agent's taxonomy and its origin node.
-  $waitingProperties$ (list of properties): contains the list of properties awaiting submission, in the event that the LSA capacity does not allow to receive all the properties to submit at the same time. To limit the volume of data exchanged each cycle, the maximum number of LSA properties is set to 10. In this case, the "pending" properties are temporarily stored in this list and will be submitted a posteriori as soon as the size of the LSA properties list falls below the maximum allowed size. Pending properties are processed in "first in first out" order.
5.1.2.2) LsaAgent class:
The $LsaAgent$ abstract class which directly inherits from the $Agent$ class also manages:
-  Access to the tuple space.
-  Operations to be performed on the LSA in the tuple space (addition, modification, deletion). This management is done using an attribute of class $OperationManager$, which contains the queue of operations to be performed.
-  The notifications of events generated by the coordination laws: each event is associated with an LSA and a category (event type) that identifies the coordination law that emitted this event. (Bond, Decay, Spreading, Aggregation: update of an LSA that can be used following an aggregation).
This class follow the $ISapereAgent$ interface, which requires the implementation of the methods for processing different types of events:
-  $onNotification$: handles a "Bonding" type event.
-  $onDecayedNotification$: handles a "Decay" type event.
-  $onSpreadingEvent$: handles a "Spreading" type event.
-  $onAggregationEvent$: handles an "Aggregation" type event.
Each type of event is generated by the coordination law having the same name.
All implementations of Digital Twins using the coordination platform inherit indirectly from this class. Therefore, they must implement these reception processes. In case an event type has no impact on the Digital Twin behaviour, the corresponding processing method may not contain any instructions.
5.1.2.3) SapereAgent class:
This class, which inherits from the $LsaAgent$ class, offers the option of storing all the LSAs targeted by the Bonding law, by request identifier. (This storage is carried out in the $bondedLsaList$ attribute, which is a mapping table between the request identifier and the list of LSAs).
This option is not activated for the Digital Twins used in microgrids. Indeed, this table consumes much memory and is not useful for microgrid agents.
5.1.3) The different coordination laws and mechanisms:
Coordination laws (called eco-laws) are defined as class singletons which are instantiated by the eco-law's engine, and are executed one after the other every cycle, at one-second intervals. Each eco-law corresponds to an elementary bio-inspired pattern and performs a specific transformation on all the LSAs present in the tuple space. The UML diagram 5.5 shows the elementary eco-law classes currently implemented.
Classes that model coordination laws:
5.1.3.1) Decay:
The Decay coordination law allows to clean the tuple space by deleting obsolete LSAs. At each execution cycle, the Decay coordination law applies its processing to all LSAs present in the tuple space. This mechanism is very simple: it decrements the LSA relevance indicator (stored in the "DECAY" synthetic property) and deletes the LSA when the indicator becomes negative. In the context of this contribution, this law allows for example to deactivate prosumers that are no longer active, because their energy demand or their production has expired.
5.1.3.2) Spreading:
The Spreading coordination law disseminates all present LSAs at the current node tuple space to all neighbouring nodes and repeats this operation at each execution cycle. Since all the nodes repeat the same operation every cycle, we can easily deduce that every LSA will eventually be routed to all the nodes in the cluster, in a direct or indirect way. For each LSA present in the tuple space, the process for spreading LSAs involves the following two steps:
-  It identifies the addresses to target: these are the addresses of the connected node where the LSA has not yet been present.
-  For each address targeted, it duplicates the LSA and sends the copy to the target address (via TCP-IP).
Sending process
Figure 5.6 illustrates an LSA spreading cycle performed by a node. The spreading eco-law sends the LSA to its direct neighbours (except for the originating node, which doesn't need to receive its own send). Each time an LSA is sent, the eco-law stores the various destination addresses in the synthetic LSA property "SENDING". In this way, when the LSA is received another time by the same node, it will not be sent again to the same destinations, and the broadcasting process of this LSA will be stopped in this node. The process of physically sending serializes the content of a LSA object and transmits it via the TCP/IP protocol. Then, when the LSA is received at a destination node, its content is deserialized by the LSA server of the destination node.
LSA spreading to direct neighbour nodes.:
Reception process
For spreading to work across a network of different nodes, each node must also manage the reception of different LSAs. A "LSA server" runs in parallel as a TCP-IP reception server: it deserializes each received message to rebuild the LSA object sent by the remote node. When each LSA is received, the "PATH" reception synthetic property is updated to store all the destinations reached by the LSA. In the same way, it prevents the further dissemination of a LSA that has already reached the node, even though theoretically this shouldn't happen, as the sends are already filtered so as not to resend an LSA to its origin or a destination already registered by the LSA. Once received, each LSA is then injected into the tuple space, to be integrated at node level.
Iterative updates of distances from neighbouring nodes
Furthermore, in the reception process, the server re-evaluates the distance of neighbouring nodes thanks to the synthetic properties recorded in the LSA: in fact, its origin is known (specified in the synthetic property "SOURCE") as well as its complete path travelled (specified in the property "PATH") which is a list of addresses. Its distance travelled (expressed as the number of network links) is simply the number of addresses in this list, or its size. As shown in figure 5.7, given that the distance with respect to a neighbouring node corresponds to the "minimal" path travelled from this same node, the distance is updated each time an LSA is received from a node with a travelled distance less than the distance already recorded for this node.
We should note that this mechanism for calculating the 'minimum' distance from the routes covered by the LSAs was initially present in the Gradient mechanism. It is therefore used systematically at each LSA reception (even if the gradient mechanism is not solicited), in order to assess the distances between the various neighbours.
Update the estimated distance from a neighbouring node (N0).:
5.1.3.3) Bonding:
The Bonding eco-law allows the exchange of property objects among different agents (otherwise known as Digital Twins). Its mechanism consists of linking a list of targeted LSAs to a client LSA, where each targeted LSA contains certain properties of interest to the client LSA. For example, it allows a producer twin to target an energy request (labelled as "REQUEST" in the LSA's properties) submitted by a consumer twin in need of energy.
To do so, the bonding eco-law iterates through each LSA present in the tuple space. For each "client" LSA named $lsa1$, it identifies the list of target LSAs (named $lsa2$ that may be of interest to $lsa1$ (which contain a property element targeted by $lsa1$'s owner agent). It checks whether $lsa2$ is not $lsa1$ and if $lsa2$ owns a property whose label matches one of the property names searched by $lsa1$ (this is the list of names of bonded properties described in section 5.8).
For example, in figure 5.9, the owner of mathlsa_1math searches for LSAs with properties named "AAA" or "BBB": as a result, the bonding eco-law selects the 2 LSAs mathlsa2_1math and mathlsa2_4math.
Processing the bonding eco-law on one LSA: search for LSAs whose properties match those targeted by lsa1. It will select beginmathlsa2_1endmath and beginmathlsa2_4endmath.:
After identifying the LSA to be targeted, the binding eco-law generates a new binding event for each targeted LSA and then invokes the $onBondNotification$ method of the relevant "client" agent (lsa1 owner), passing the newly generated event as an argument.
Each Bonding event includes the targeted LSA: in this way, the client agent can extract and process the property (or properties) of interest from the $onBondNotification$ method.
5.1.3.4) Aggregation:
This coordination law manages the aggregation of certain properties contained in LSAs. Its handling is relatively complex compared to other coordination laws, given that it offers a certain level of flexibility: it can now aggregate any type of object, in a personalized way, with the possibility of independently aggregating several different properties on the same LSA.
Unlike the earlier version of SAPERE, the current version of aggregation does not apply to the LSA itself, but to one or more LSA properties. Each property is aggregated independently of the others. This new aggregation mode, which applies to LSA properties, is explained by the need to keep each LSA alive in the tuple space, given that each LSA represents a microgrid prosumer that must remain active as long as it produces electricity, or it needs to consume electricity.
Description of the AGGREGATION synthetic property
In the current version of the middleware, we apply an aggregation not to an entire LSA but only to one of its properties, which is identified by its name (used as a search key to retrieve this property from the list of properties).
The principle is to specify an aggregator for each of the properties to be aggregated. They will be aggregated with properties of the same name contained in other LSAs. In this way, aggregation will not destroy the LSA itself (as was the case in previous versions), and aggregation can be applied to each property independently.
The "AGGREGATION" synthetic property is used to specify the various aggregations to be applied, in the form of a property name - aggregator specification mapping table. Each property name can therefore specify only one aggregator at a time, which will be applied exclusively to this property name in the various LSAs.
Figure 5.10 shows an example of aggregation definition on 4 different property names that appear in the LSA. In this way, 4 aggregations will be executed independently for the properties "LAST_UPDATE", "NODE_TOTAL", "MODEL_1", "MODEL_2".
Here is the detailed structure of each aggregator specification that applies to each property name (this structure is also described in figure 5.11):
-  $propertyName$: this is the LSA property name on which the aggregation is applied. It is important to specify that this is a property (managed by the agent) and not a synthetic property (managed by the Middleware layer). As a reminder, the properties objects are submitted by the owner agent and are then transformed and propagated in the tuple space.
-  $operator$: this is the aggregation operator, knowing that several possible aggregation operators can be defined in the class of the object to aggregate (for example, arithmetic or geometric mean, min or max).
-  $type$: the aggregator type: standard or custom. Standard aggregators are defined "in hard" in the middleware library code (those that were previously defined and applied to elementary types), while the custom aggregator must be defined in the class of the object to be aggregated: the class in question must then implement the $IAggregateable$ interface and in particular, the method that performs the aggregation. This last method also takes the operator 's name, which gives the possibility of defining several variants of an aggregator applied to a class. In this way, we can define any aggregator outside the coordination middleware library: the aggregation eco-law is limited to applying the aggregation method on all the properties to be aggregated.
-  $activateGossip$ (boolean): option that extends the aggregation to all external nodes before, (including indirect neighbours). This will enable local data to be aggregated with data from neighbouring nodes, as is the case, for example, with Gossip Federated Learning. If this option is disabled, only local data will be aggregated. We note that only connected nodes are concerned: if a node is not yet or no longer accessible, even indirectly, it will not be required for this check.
Aggregation synthetic property, in the form of a mapping table that specifies the aggregation to be applied for each property name (listed as a key in this table).:
Description of a generic structure of objects to aggregate
In what follows, we define an "aggregatable" object as one that can be aggregated by implementing the "aggregatable" interface: the latter defines an aggregation behaviour that consists of generating a single object of the same class with the aggregated data, from a set of objects of the same class, following the aggregation method specified in the operator also supplied as a parameter.
This section describes the generic template that contains the common properties and methods of all "aggregatable" object (object that can be aggregated):
The following properties are described in an abstract class that any object that can be aggregated, will extends:
-  $mapSourceObjects$: mapping table of source agent name and source object. This tracks which object comes from which agent in the previous aggregation. Note that an object received in the aggregator input may have already been aggregated once, in which case it will already contain several source agent names and objects in this property. In this case, all the source objects of this object will be added one by one to the $aggregatedNodes$ property of the new aggregated object. This corresponds to "recursive" aggregation, which is carried out several times.
-  $mapNodes$: Mapping table of source agent name and source agent node. This correspondence table makes it easy to find the source node of an object contained in $mapSourceObject$.
-  $lastUpdate$: (Date) Instant of last update. Enables the aggregation coordination law to avoid repeating an aggregation if there are no recent updates (i.e. if no last update date for the objects to be aggregated is later than the last aggregation).
-  $aggregationCompleted$: This boolean flag confirms whether the aggregation is truly complete (e.g. if it includes objects from all active nodes). This boolean is relevant only if the gossip option is activated.
-  $aggregationDate$: Time of completion. This allows a Digital Twin to know when the last aggregation took place, and, if necessary, to force a pause before the next aggregation (by simply clearing the LSA property whose name corresponds to the value of $propertyName$ parameter).
Implementation of aggregation in each "aggregatable" class
All object classes to be aggregated implement the "IAggregatable" interface and inherit from the $Aggregatable$ abstract class. As a result, each "aggregatable" class will inherit the "getter" methods that return its properties defined in the $Aggregatable$ abstract class and
will have to implement the aggregate method to comply with the $IAggregatable$ interface. This method must be defined with the following arguments:
-  the aggregation operator (identify which operator to apply if several aggregation calculation variants exist). Consequently, the aggregation method must deal with the different ways of aggregating objects. A specific block or sub-function is used to implement each operator.
-  the mapping table of source agent name and corresponding source object received.
-  the Digital Twin authentication (may be useful in cases where the Digital Twin that locally owns the LSA has reduced visibility on the objects to be aggregated).
Selection of LSAs with properties to be aggregated
The aggregation eco-law iterates over each local LSA present in the tuple space which contains a synthetic property labelled 'AGGREGATION'. For each of these LSAs (called $lsa1$), the eco-law searches the list of LSAs on which the aggregation can be applied. These are all the LSAs (which we call $lsa2$) that meet the following conditions:
-  distinct from $lsa1$
-  belonging to the same node (unless the Gossip option is enabled, in which case this condition is not required)
-  with a non-empty aggregation list defined in the "AGGREGATION" synthetic property described above.
-  whose aggregation list includes at least one aggregation applying to the same property as $lsa1$'s aggregation list. For example, if $lsa1$ has one aggregation that applies to the "TOTAL" property and another to "MODEL", $lsa2$ must have at least one aggregation that applies to either "TOTAL" or "MODEL" property name.
Executing the aggregation mechanism on one LSA
At this point, the main iteration loop has selected an LSA (called $lsa1$) for which there are other LSAs on which we can aggregate this LSA with the other LSAs found.
The eco-law iteratively goes through each item of class $AggregatorProperty$ contained in this "AGGREGATION" synthetic of $lsa1$. For each item (which we call $nextAggregation$), the eco-law performs the following processing:
-  it retrieves the objects to be aggregated from LSA properties: these are the values of the LSA property specified in $nextAggregation.propertyName$ parameter. On the set of objects obtained, it excludes:
-  only in case when the option $nextAggregation.activateGossip$ is not set: all objects from external nodes (direct and indirect neighbours).
-  objects for which the aggregation has already been completed with the objects from all agents contained in the cluster or in the local node (depending on whether the $nextAggregation.activateGossip$ option is enabled or not).
-  then, it invokes the aggregator method, on the object belonging to the local LSA, and sends as arguments:
-  the agent authentication of the local LSA.
-  the aggregation operator specified in $nextAggregation.operaor$.
-  all the objects to be aggregated (including the object from local LSA and all the objects selected in the previous step).
-  finally, it retrieves the object resulting from the aggregation and put it in the $aggregatedValue$ attribute of the LSA property named $nextAggregation.propertyName$: this ensures that the initial object, which is stored in the $value$ attribute is not overwritten by the aggregated value. The date of aggregation is recorded in the result object, so that future next aggregations can be delayed if necessary.
Figure 5.12 shows a simplified view of the aggregation mechanism described here. This processing follows the following 3 steps: (step 1): it retrieves the objects to be aggregated from LSAs received as input and from the local LSA (value of $propName$ property in each LSA)
, (step 2): it executes the $obj_1.aggregate$ method defined in the class of $obj_1$ , and (step 3): it stores its content in the "aggregatedValue" attribute of this property.
Application of a single aggregation specification (contained in the synthetic property "AGGREGATION" of the local LSA: LSA_1). :
5.2) The coordination platform service:
The coordination platform service is implemented in Java as a separate executable jar. Its runs both:
-  the "LSA server" used to receive serialised LSA (see section 5.13).
-  the linked REST server, which receives requests to create or update Digital Twins, from the web application and the simulator programs.
This software layer defines:
-  The taxonomy, the structure and behaviour of all Digital Twins which interact through the coordination platform.
-  The taxonomy and the structure of data exchanged between the Digital Twins: these are energy request, supply, offer, contract, events, message of regulation order.
-  The learning model structure and mechanism (in the case of Markov Chains).
-  The structure of data exchanged with the web application and the test simulators (received forms and structures of data returned to the client process, which are then displayed on web pages if it is the 'front' server).
5.2.1) Implementing the Digital Twins:
All Digital Twin classes inherit from the generic $SapereAgent$ class defined in the middleware library: this class manages interaction with tuple space via LSA, whose property data evolves with each coordination law execution cycle.
Classes that model the various Digital Twins dealing with energy exchanges or energy regulation:
5.2.1.1) "Microgrid" twin:
The $MicroGridAgent$ class models all the types of Digital Twin that can be involved in a microgrid. These are supervisor twins and prosumer twins: the latter exchange energy with the former. The $MicroGridAgent$ class, which inherits directly from the $SapereAgent$ class defined in the middleware.
The $MicroGridAgent$ class defines the common property that all microgrid agents must have: the node context information (of $NodeContext$ class), which includes the general configuration parameters of the coordination platform instance.
5.2.1.2) Prosumer twin:
The $ProsumerAgent$ class models prosumer Digital Twins: prosumers have a dual behaviour, since they have both that of the consumer and that of the producer, but not necessarily at the same time.
Indeed, a prosumer may need electricity at time $t1$ (and thus be a consumer) and can provide electricity at time $t2$ (and thus be a producer). As a result, a prosumer manages the relationships it might have with other prosumers, both as a producer and as a consumer.
The previous version modelled producers and consumers in two separate classes: this did not allow the same Digital Twin to switch from one to the other as needs evolved. This new class is relatively late in coming, as the first scenarios, based on actual appliance consumption, do not involve switching from consumer to producer and vice versa. However, this current implementation does not yet allow a prosumer to supply a prosumer and receive energy from another prosumer at the same time (as this would require additional adjustments). As shown in Figure 5.14, the class handles both roles independently and has attributes that are specific to each of these two roles.
Those specific to the role of producer are as follows:
-  $globalProduction$ (of class $ProsumerEnergySupply$): global production at the present time.
-  $producerPolicy$ (which implements the interface $IProducerPolicy$): defines specific preferences and behaviours as a supplier (e.g. defines its criteria for considering or ignoring energy requests that are received).
-  $offersProcessingManager$ (of class $OffersProcessingManager$): processing class that manages the links with the various active consumers (who are also prosumers) at different stages (request received, offer already sent, contract in the process of being validated or validated).
Those specific to the role of consumer are as follows:
-  $globalNeed$ (of class $ProsumerEnergyRequest$): global need at the present time
-  $consumerPolicy$ (which implements $IConsumerPolicy$): defines specific preferences and behaviours as a consumer (e.g. defines its criteria for considering or ignoring energy offers that are received)
-  $offersProcessingManager$ (of class $OffersProcessingManager$): processing class that manages the received offers from suppliers.
-  $consumersProcessingManager$ (of class $ContractProcessingManager$): processing class that manages the energy contract for main supply and complementary supply. The management of a complementary supply has been put in place to cover an increase in electricity requirements that exceeds the upper limit set out in the contract, as explained in paragraph 5.15. As a result, the prosumer may have to manage a temporary 'complementary' contract, which is then merged with the main contract.
Treatments carried out by a prosumer twin: global view:
Management as a supplier
Figure 5.16 shows a zoom on the processing of relations with the various consumers, managed by the $ConsumersProcessingMangager$ class. This class both manages main supplies and temporary second supplies: it thus includes a processing table for main contracts and one for temporary secondary contracts. These two processing tables are independent and structured in the same way. When a consumer has an increase in demand that requires a new supply, the main table always stores its current contract while the second table manages the new offer and then the new complementary contract that will absorb the new energy gap. After the complementary contract has been merged with the main contract, the consumer is removed from the second table: it will then appear only in the 'main' table.
For each consumer, the processing table associates the "energy object" that corresponds to the current state of the consumer's treatment:
-  Either the request has been received and has not yet been processed, in which case the stored value is the request to be processed for the consumer (object of class $EnergyRequest$).
-  Either the producer has responded to this request with an offer and this offer has not yet led to a contract, in which case the stored value is the offer sent to the consumer (object of class $SingleOffer$).
-  Either the processing of the request has resulted in a contract (already validated or in the process of being validated), in which case the stored value is the contract that has been issued by the consumer (object of class $Contract$).
The processing of a consumer can only be in one of these 3 situations, which is why we associate a unique object (a request or offer or contract) per consumer identified by its agent name in this table.
Treatments carried out by a prosumer as an agent who supplies other prosumers.:
Management as a consumer
Due to the complexity of processing, supplier relationship management is split into two classes, each focusing on a different part of processing:
-  $OffersProcessingManager$, which processes offers received from suppliers.
-  the other, $ContractProcessingManager$, which manages the main contract and (if necessary) the second contract with the suppliers concerned.
Figure 5.17 describes how offers are processed in the $OffersProcessingManager$ class: the consumer accumulates the different offers received and tries to build up an aggregated offer by selecting as a priority the offers that correspond to its own preference criteria. The new aggregated offer is stored in the $globalOffer$ attribute: if it meets the consumer's electricity needs, the consumer issues a new contract which will be validated by the suppliers concerned. This process will be taken over by the $ContratProcessingManager$ class, which manages the entire life cycle of a contract.
We can see from figure 5.18 that the processing table is not duplicated to process a complementary supply (as is the case for other types of processing): this is because there is no point in processing offers for both main and complementary supplies at the same time, as this situation cannot arise. Indeed, when a consumer looks for a complimentary offer, this assumes that the main supply is already operational with a validated contract, and therefore that there is no need to process an offer for the main supply. Conversely, when the consumer is looking for offers for a main supply, there is no question of looking for a complementary supply at this moment.
Treatments or received offers.:
Figure 5.19 describes how supply contracts are handled in the $ContractProcessingManager$ class: this class supervises the entire life cycle of the main contract and any additional contracts (if applicable). A contract is formed from the global offer previously generated by the $OfferProcessManager$ class. At this stage, the contract must be confirmed by the suppliers. To do this, the $ContractProcessingManager$ instance manages contract validation, by retrieving confirmations from the producers concerned (as explained in the section 5.20). It should be noted that this management is also done through the $ContractProcessingData$ class, an instance of which is associated with each contract, the primary and the secondary.
Management of each supply contract by the auxiliary class
The $ContractProcessingData$ class manages the data for one supply contract (the main supply or the additional supply). In this way, the $ContractProcessingManage$ instance of the prosumer contains two instances of $ContractProcessingData$: one for the main contract and one for the additional contract, and each of these two instances is linked to one contract object and thus manages its life cycle. A contract can be null depending on the prosumer's current situation (if it doesn't need any energy, or if it doesn't have any supplies in progress, or any contracts to validate). The $ContractProcessingData$ class includes the following attributes:
-  $currentContract$: The contract itself.
-  $isComplementary$ (boolean): True if it manages a complementary supply.
-  $mapLastEvents$: The latest events concerning the contract (creation, modification of conditions, termination of the contract).
-  $receivedConfirmations$: The last supplier confirmations (Allows to confirm at any time whether all suppliers involved in the contract are still in phase with the current contract).
Management of contracts for primary and complementary supply.:
UML view of the classes used by the prosumer twin
The UML diagram 5.21 summarises the classes used in prosumer processing.
As seen above, the highest-level classes $ConsumersProcessingMangager$, $ContractProcessingManager$, $OffersProcessingManager$ respectively manage:
-  contracts with consumers (when the prosumer produces energy).
-  contracts with suppliers (when the prosumer needs energy).
-  new offers received from producers (when the prosumer needs energy).
Each of these classes uses lower-level classes with the same name suffixed with 'Table': they are used to manage the data linked to each prosumer, whether they are a supplier or potential supplier, or a customer or potential customer.
Class diagram of the processing carried out by the prosumer Digital Twin.:
5.2.1.3) Learning twin:
As explained in section 5.22, the learning Digital Twin calculates the node's state variables and trains the learning model that predicts these variables, both at the local node level and at the cluster level (if enabled). As a reminder, these variables are the power produced, requested, supplied, consumed, missing and available: the total of these variables at node level and at cluster level have the same structure (the $NodeTotal$ class is used for both).
Each learning model belongs to the generic class $AbstractlearningModel$ and can be an instance of $LstmLearningModel$ or $MarkovChainsModel$ depending on the type of model requested in the node configuration.
Processing at initialisation
It is important to specify that the Digital Twin initialises the dataset for its two learning models from the history of measurements data contained in the test scenario database. As explained in paragraph 5.23, a pre-simulation of energies exchanges is calculated over the period preceding the start-up of the coordination platform: this computed data includes the history of the 6 power variables at the individual device level. They are then aggregated at both local node and cluster level, and they are finally injected into the local node learning models and the cluster learning model, in order to train them a first time before they become operational.
Periodic processing
Each time the learning twins received an event via the Bonding coordination law, it then recalculates the node total, stores it in the database and updates the history of the node's learning model.
The cluster total is only calculated if cluster total prediction is enabled: in the latter case, the cluster total is calculated by the aggregation coordination law, which receives as input the node totals from the individual nodes. (In each node instance, the learning Digital Twin submits the node total to its LSA with the label 'TOTAL').
The learning twin regularly invokes the training of each model at regular intervals, but with a frequency that differs according to the type of model:
-  For Markov Chains model, as the computing cost is low, the model is trained every minute.
-  For LSTM model, as the computing cost is high, is trained every 20 or 30 minutes
The learning twin regularly invokes model predictions on each model. The prediction results are then stored in the database and submitted in the LSA, in order to be retrieved by the regulator twin which monitors the risk of overconsumption and overproduction. The prediction results are then compared with the actual states at the horizon, in order to estimate the accuracy of the predictions.
Treatment on request
At any time, the learning twin can be asked to provide information on the current state of its learning models or to calculate specific predictions (either unitary or serial), or to calculate statistics on all its predictions in order to provide a good overview of performance in terms of accuracy per time slot and per variable. The learning twin is also able to provide prediction statistics on demand. These requests are initiated by the web application: the learning twin is then solicited indirectly by the REST server and the results returned by the learning twin are then displayed by the web application. For more details on web pages, please refer to section 5.24.
Processing performed by the learning Digital Twin.:
5.2.1.4) Regulator twin:
As explained in section 5.25, the regulator twin monitors the stability of the node while managing agent modification requests and assigns rewards to the agents by evaluating their involvement in energy supplies and their ability not to over-consume.
Figure 5.26 gives an overview of the various processes carried out by the regulator twin, as well as the different data it needs to manage in order to carry out these processes.
Concerning alert management, the regulator sends different types of warning messages to the prosumer twins. Some are created at the regulator's initiative, while others are initiated by the client applications.
Detections made by the regulator twin
The following types of warnings are detected by the regulator and are therefore created at the regulator's initiative. At each cycle of the 'DECAY' eco-law (every second), the regulator twin performs the checks described in section 5.27 and in algorithm 5.28. In the event of an overflow, it retrieves the current consumptions (or productions) of all prosumers, recorded in the events which are currently active. These events are retrieved from the database using the $EnergyDbHelper.retrieveCurrentSessionEvents$ method. Once the prosumers to be stopped have been selected, the regulator submits the deactivation orders addressed to the prosumers in the 'WARNING' properties (there is one 'WARNING' property for each prosumer concerned).
The regulator twin also performs checks based on the production/consumption predictions described in section 5.29. The prediction, which is calculated by the learning twin, is extracted from the LSA property 'PRED'. When consumption/production needs to decrease rapidly, the regulator twin then submits the calculated table containing the reprogramming commands for each prosumer concerned, in its 'RESCHEDULE' LSA property.
Here is the list of warning types submitted by the regulator following its detections:
-  Overproduction: production threshold exceeded: this warning deactivates one or several prosumers to return below the threshold.
-  Overconsumption: consumption threshold exceeded: idem.
-  Forecast of overproduction: This warning asks one or more prosumers to defer their production to remove the probable risk of exceeding the threshold.
-  Forecast of overconsumption: the effects are similar to those of the warning type 'Forecast of overproduction'.
-  Not in space: detection of agents (Digital Twin) whose LSA no longer exists in tuple space. This technical problem leads to data inconsistencies: Indeed, these Digital Twins can no longer interact with the other twins. As a result, their references must be deleted from properties that belong to the other agents and the "out of space" agent will have to be completely restarted. This warning then allows all the other prosumers to delete the data linked to the 'out of space' agent. For example, all contracts linked to an 'out-of-space' prosumer must be terminated (whether as a producer or consumer) and the 'out-of-space' prosumer must be removed from all processing tables.
[JLF1] It should be noted that these warning properties have a fixed lifetime (e.g. 30 seconds for overproduction or overconsumption), and are then deleted by the DECAY coordination law in order to regularly clean up obsolete data. This relatively long time lapse allows warning properties to propagate through the tuple space and the various nodes so that they can be retrieved by all the prosumer twins concerned, which may be more or less close in network distance.
Handling external requests
The following types of alerts are created at the initiative of external requests from a client application (the web application or a test simulator). The regulator agent receives these instructions from the main controller which processes the REST requests: the regulator then sends these instructions to the Digital Twins concerned by submitting them in its LSA.
-  General interruption: order to stop all agents (including supervisors)
-  User interruption: order to stop one or several prosumers.
-  Change request: request to modify a prosumer production or demand (depending on if it wished to receive or to provide energy).
Management of alerts already sent
It is important to note that each alert has an expiry time of a few seconds, depending on the warning type (for example, 30 seconds for overproduction). This enables the regulator to know at any time which warnings have already been submitted, so that the same warning is not resubmitted during the next verification cycles. Indeed, it takes Digital Twins at least a few seconds to resolve a detected problem, and it would have no sense for a prosumer to receive the same warning several times at one-second intervals. The regulator twin also regularly cleans up expired alerts.
Calculation of rewards
Every second, the regulator twin calculates the evaluation criteria for each prosumer, which are then used to generate the new awards per prosumer. All this data is stored in an instance of the $AwardsComputingData$ class. At regular intervals, the regulator twin generates new awards using this instance of $AwardsComputingData$. The principle is to calculate the new awards by adding and combining the latest calculated values for the various criteria. For more details on the calculation algorithms, please refer to section 5.30.
Processing performed by the regulator Digital Twin.:
5.2.2) Modelling information exchanged between Digital Twins:
The UML diagram 5.31 represents the classes that model the different types of energy data exchanged between the Digital Twins, whether they be supplies, offers, events or contracts, etc....
For the sake of simplicity, this subsection does not describe the class directly submitted in the LSA, since the latter also manages data security. For this reason, the class names shown do not include the "Protected" prefix that characterises a data protection class (see section 5.32).
In the UML diagram, we can see that the various classes inherit from the generic $EnergyFlow$ class, which models an energy flow emitted by a prosumer (we define a flow as wattage data emitted by a prosumer, and which applies to a time slot). This class contains the following common information:
-  $issuerProperties$ (of class $ProsumerProperties$): characteristics of the prosumer (agent name, location, distance, and technical characteristics of the prosumer appliance).
-  $beginDate$ (of class $java.util.Date$): start-up time of the energy flow.
-  $endDate$ (of class $java.util.Date$): time at which the flow expires.
-  $isComplementary$ (boolean): indicates whether the flow is in conjunction with a 'complementary' request to increase the coverage of an existing supply.
-  $powerSlot$ (of class $PowerSlot$): current wattage, with the minimum and maximal wattages applicable to the flow during the period concerned.
This information is therefore common to requests, supplies, offers and contracts, and is also used by a change order sent to a prosumer.
All dates are in $java.util.Date$ format and include the time with a precision of a thousandth of a second, and tables are in $java.util.Map$ format (key-value correspondence table).
Classes that model the various objects involved in energy exchanges.:
5.2.2.1) Event issued by a prosumer (of class EnergyEvent):
This is an event submitted by a prosumer to notify the learning agent of a change that affects its energy demand, production, or its energy contract (only in the case of a consumer that is currently provided). This event object is submitted by prosumers in the "EVENT" property and is then retrieved by the learning twin. The $EnergyEvent$ class inherits from the $EnergyFlow$ class and contains the following additional attributes:
-  $type$ (of enumeration class $EventType$): Full event type, including the type of flow concerned (request or production or contract) and the main event category (start or expiry or stop or update). Refer to table 5.33 for a full description of the different event types.
-  $originStartEvent$ (of class $EnergyEvent$): Event creating the original flow (demand or production or contract). This attribute only concerns update or delete events, as they cannot exist without the creation event which initiated the energy flow (its value is 'null' for creation events).
-  $powerUpdateSlot$ (of class $PowerSlot$): difference for each of the 3 power components (current/min/max) compared with the 3 power components of the original event.
-  $warningType$ (of class $WarningType$): Regulation order which have caused the event (e.g. a shutdown due to overproduction which was ordered by the regulator twin). Its value is 'null' if this change is not initiated by a regulation order.
-  comment ($java.lang.String$ class): A more detailed commentary that explains the exact reason why this event was created.
-  $id$ (long): Event database identifier.
5.2.2.2) Request issued by a consumer (of class: EnergyRequest):
This is an energy request made by a prosumer which needs energy at the moment. The consumer submits this object in the "REQ" property (which will be then retrieved by all the producers).
The $EnergyRequest$ class inherits from the $EnergyFlow$ class and contains the following additional attributes:
-  $priorityLevel$ (of enumeration class $PriorityLevel$): Request urgency level (low, medium or high).
-  $delayToleranceMinutes$ (double): Response time tolerance in minutes. Prosumers no longer respond to the request if this deadline has expired.
-  $warningDate$ (Date) Instant from which the request is considered to be "on alert". (Not satisfied while there is enough energy available to supply it).
-  $awardsCredit$ (double): reward credit or penalty used in the request according to the number sign of the number (corresponds to either a bonus or a penalty applied to the price per KWH in the supply).
5.2.2.3) Offer issued by a producer and intended for a consumer (of class: SingleOffer):
This object is submitted by a producer in the "OFFER" property and is then retrieved by consumers.
This is an energy offer issued by a single producer and intended for a prosumer that has issued an energy request. This offer responds directly to this demand and can meet all or part of it in terms of power, depending on the availability of the producer. This class includes the following attributes: the name of the producer, the consumer request, the offer creation date, the offer expiry date (set at the creation date value + 10 seconds), the offer reception date (set by the consumer) and the acceptance date (set by the consumer).
5.2.2.4) Producer confirmation (class ConfirmationTable):
This object is submitted by a producer in the "PROD_CONFIRM" property and then retrieved by the consumer that have issued the contract to be validated.
This class includes the following attributes: the name of the agent issuing the confirmation and the table of confirmations by contract issuer. For example, a producer may have 3 different contracts to confirm, in which case the table contains 3 confirmations, one associated with each contract issuer (consumer to be supplied). A confirmation is modelled by the $ConfirmationItem$ class, which includes the approval indicator (OK/KO), the confirmation date and the confirmation expiry date.
5.2.2.5) Energy contract between a consumer and suppliers (class Contract):
This object is submitted by a consumer in the "CONTRACT1" or "CONTRACT2" property (depending if is a main or complementary supply) and is then retrieved by the producers that are involved in this contract as supplier.
This class inherits from $CompositeOffer$ class, which models an electricity offer provided by several suppliers.
Description of $CompositeOffer$ super-class
The $CompositeOffer$ class, which generalises the $Contract$ class, includes the following attributes:
-  the consumer's request.
-  the contract start and end dates.
-  the contributions table, which contains one instance of $SingleContribution$ per supplier agent name.
Each instance of $SingleContribution$ class contains:
-  the range of power supplied (of class $PowerSlot$).
-  the supplier node location (of class $NodeLocaiton$).
-  the supplier's pricing table by time slot (of class $PricingTable$).
-  the list of identifiers for the offers issued by the supplier.
It should be noted that the $CompositeOffer$ class is used by the consumer to aggregate the different offers it selects: the $CompositeOffer$ instance containing the aggregated offer may (or may not) lead to the creation of a new contract, depending on whether it is sufficient (or not) to satisfy the consumer's energy needs.
Description of $Contract$ class
The contract class includes the following additional attributes: the expiry date beyond which the contract can no longer be validated, the names of producers who have approved the contract, the names of producers who have disapproved the contract, the global pricing table per schedule and the identifier of the corresponding event in database.
5.2.2.6) Regulation warnings (class: RegulationWarning):
This class models a regulation order whose purpose is to modify or pause the activity of a prosumer for various reasons, whether it's a stop or update requested by the regulator or by an external user, from the web application.
An instance of this class is submitted by the regulator twin in the "WARNING" property and is then retrieved by the prosumer twins and the learning twin.
This class is also used in the 'DISABLED' property, which is submitted by a prosumer twin when it becomes disabled and then retrieved by the other digital twins. This class includes:
-  the order purpose, which corresponds to one of the following elements: overproduction, overconsumption, interruption request, modification request, or LSA not present in tuple space ('out of space').
-  the names of the agents affected by this order.
-  the order date-time.
-  the order expiry date (after this date, the order is removed).
-  the energy request or supply (only entered in the case of an order to update a request or supply of a prosumer twin.
5.2.2.7) Reschedule data (class: RescheduleTable):
Unlike the $RegulationWarning$ class, this class is used specifically for rescheduling the activity of prosumer as part of peak shaving, which is also managed by the regulator twin. This object is submitted by the regulator twin in the "RESCHEDULE" property and is then retrieved by prosumers.
This class consists of a key-value table where each key corresponds to the agent's name, and the value corresponds to the associated reschedule. A reschedule is modelled by the $RescheduleItem$ class and includes the wattage and the stop range (start and stop date/time).
Classes used for rescheduling:
5.2.2.8) Awards Table (class AwardsTable):
This class is used to model the allocation of the various rewards (or penalties) assigned to each prosumer by the regulator.
An instance of this class is submitted by the regulator twin in the "AWARDS" property and is then retrieved by prosumers. It contains a mapping table that assigns an award item (of class $AwardItem$) for each prosumer concerned. The $AwardItem$ class contains the score assigned to a prosumer for the 3 following criteria: supplies provided to the other prosumers, equity in energy distribution, and efforts to limit energy consumption. The decimal score of each criterion is positive or negative depending on whether it corresponds to an award or a penalty. The $AwardItem$ class also stores the list of different credit usages, which is empty at the computation time.
The global score of an award is evaluated by simply summing the 3 award scores that correspond to the 3 evaluated criteria, and its credit balance is evaluated by subtracting the different credit usages from the global score.
Classes used for awards distribution:
5.2.2.9) Prediction data (class PredictionData):
This class models the prediction of the future state of the node in terms of electrical power, which is predicted for different horizons. It appears in diagram 5.34). An instance of $PredictionData$ is submitted by the learning twin in the "PRED" and "PRED_CLUSTER" properties (depending on the prediction perimeter, i.e. whether the prediction is at node level or for the entire node cluster) and is then retrieved by the regulator twin.
This class contains:
-  the date at which the prediction is requested.
-  the horizon.
-  the target date (requested date + horizon).
-  the list of time steps used to calculate the prediction
-  the values of the node's initial state.
-  the variable states corresponding to the node's initial state.
-  the result obtained, i.e. the list of prediction vectors of the target state.
A node state comprises the following 6 components: power requested, produced, supplied, consumed, missing and available.
Classes that model prediction data.:

Figure 5.35 summarises all the LSA properties exchanged in tuple space through the Bonding eco-law. Each data type in this table is encapsulated in a LSA property whose name appears in the "Label" column. The first column displays the types of Digital Twins that submit the property, and the 4th column displays the types of Digital Twins that retrieve the property.
List of LSA properties exchanged between Digital Twins through the tuple space, thanks to the bonding coordination law.:
5.2.3) Implementing Learning Models:
As shown in figure 5.36, the lower-level implementation differs depending on the machine learning model used. For the Markov Chains model, training and prediction are implemented in the coordination platform, whereas for the LSTM model, training and prediction are implemented in an external service that interacts with the coordination platform using the REST protocol (as shown in figure 5.37). The Machine Learning external server uses functions already implemented in the Keras python library to initialise and train complex models, with the possibility of applying predictions at any time.
LSTM implementation - versus - Markov Chains implementation:
The UML diagram 5.38 shows the classes used in the two learning model implementations (LSTM and Markov Chains). The $AbstractLearning$ class corresponds to the general structure of a learning model and the $ILearningModel$ interface defines the various 'services' that it must implement.
Classes of learning model implementation.:
5.2.3.1) Markov Chains model:
As the Markov Chains model is relatively simple to implement, we have chosen to integrate it entirely into the coordination platform service.
Description of $CompleteMarkovModel$ class
-  $CompleteMarkovModel$: class that manages all Markov predictions for the 6 variables attached to the prediction parameter (node or cluster). There are therefore two instances of this class: one for predictions at node level and the other for predictions at cluster level. The $mapModels$ attribute contains a mapping table of $VariableMarkovModel$ instances (one for each of the power variables to be predicted).
-  $VariableMarkovModel$: Markov Model attached to a specific variable and prediction perimeter. Its attribute $mapMatrices$ is a mapping table that contains all the transition matrices (one per possible value of the $FeaturesKey$ class).
-  $FeaturesKey$: class which represents the division of the space of possible values taken by the characteristic variables into different ranges. This division contains as many dimensions as there are characteristic variables and as many elements as there are possible tuples resulting from the Cartesian product of these different ranges of variables (and therefore possible instances of $FeaturesKey$). Currently, only time ranges are used, but we could integrate solar radiation or precipitation levels. Consequently, for a given variable to predict, there is at most one transition matrix per instance of $FeaturesKey$, which is why this class is used to identify a transition matrix that matches the variable to be predicted. The complete key of a matrix also includes the power variable to be predicted, as these matrices are duplicated for each of the 6 variables.
-  $TransitionMatrix$: Contains a complete transition matrix attached to a variable and a range of characteristics (a $FeaturesKey$ instance). It contains the 3 following attributes, which are transition matrices whose cells have different formats: number of observations per iteration ($IterationObsNb$), total number of observations (double) and normalised number of observations (double between 0 and 1). In each of these matrices, the cells represent the transition from the current state, identified by the row index, to the next state, identified by the column index.
-  The attribute $completeObsMatrix$ contains the complete transition data. For each transition, the numbers of observations are distributed over each iteration of the Markov model, with one iteration per observation day. For example, there are 3 iterations if there were observations only on Monday, Wednesday, and Thursday of the previous week. Its content, however, cannot be directly used in prediction calculations, since it does not directly contain normalized numbers that correspond to probabilities.
-  The attribute $allObsMatrix$, of class $DoubleMatrix$, contains the matrix calculated from $completeObsMatrix$ by selecting the desired iterations.
-  The attribute $normalizedMatrix$, of class $DoubleMatrix$, contains the normalized values of $completeObsMatrix$. This matrix of decimal numbers can be directly used in prediction calculations carried out on the Markov Chains model.
We should note that $allObsMatrix$ and $normalizedMatrix$ are calculated from the $completeObsMatrix$ value and the sliding window. These last two transition matrices are used to avoid systematically recalculating the normalised matrix.
-  $IterationMatrix$: Contains a matrix whose cells are elements of class $IterationObsNb$. This allows all the weights to be recalculated according to the iterations selected, at any time. The result is a matrix of decimal numbers (of class $Double$).
-  $IterationObsNb$: Stores the number of observations for each iteration. The advantage of this class is that it can calculate the total number of observations from the selected iterations. For example, the Markov model applies a sliding window of 100 days, so this class makes it easy to return the total number of observations recorded over the last 100 days.
-  $DoubleMatrix$: Stores a matrix of decimals and manages matrix operations.
Calculation of predictions
The prediction calculation is performed for each variable separately, by the method $CompleteMarkovModel.computeVariablePrediction$, which takes as parameters the initial state transition (contains the state and value at the time of prediction), the $PredictionData$ instance and the name of the variable to be predicted.
The calculation principle consists of dividing the period between the prediction time and the horizon into 1-minute steps (each step corresponding to the observation frequency). Each step is stored in an instance of the $PredictionStep$ class. For each step, the linked transition matrix is determined based on the range of characteristics linked to that step (a $FeaturesKey$ instance), which currently corresponds to the time slot (but which could also include the predicted value of a weather parameter used at the corresponding time, if a weather characteristic such as solar radiation is implemented). The $ComppleteMarkovModel.getTransitionMatrix$ method, which takes the characteristic ranges and the variable name as parameters, returns the corresponding transition matrix.
The result of the prediction is a probability vector containing a scalar value for each possible state (from 0 to the last range above the maximum power threshold). This vector is initialized to 1.0 at the initial state index, at the time of prediction (this state corresponds to the last state observed by the learning twin). We then apply all the Markov transitions step by step by simply multiplying the result vector itself by the transition matrix linked to the next $PredictionStep$ instance. After the last multiplication step, we obtain a prediction vector that corresponds to the horizon instant.
5.2.3.2) LSTM model:
As the calculations performed by the LSTM model are much more complex to implement, we have chosen to use the Keras library written in Python: this library has proved its worth and can easily initialise and train an LSTM-type model.
Implementing the LSTM model in an external service
As shown in figure 5.39, LSTM models are managed using an independent process developed in Python that includes a front REST server. A class (named $Flask$) manages the REST controller which receives requests in HTTP format. This class, which uses the Flask library, manages the various services that process the REST requests sent by the coordination platform: initialising an LSTM model using historical data extracted from the database, adding new data to the LSTM model, updating model weights, calculating predictions. This controller calls the LSTM model processing modules which use the Keras library to execute the following services: initialisation of an LSTM model with given values of hyper-parameters and a given the set of layer characteristic, dataset update, model training, update of model weights, prediction, retrieval of model weights.
Another class (named $DataStore$) stores all active LSTM models in a mapping table in which each model is identified by its key: the name of the node owning the model, the predicted power variable and the prediction perimeter (node or cluster). For example, this table might contain a model belonging to node N2 that predicts power consumption at the node level only. In this way, each model is managed independently but the content of this class can be very bulky depending on the number of nodes and the presence (or not) of the cluster and node perimeters of prediction on each node.
Use of LSTM service from the coordination platform
The structure of the model is also implemented on the coordination platform side (of class $CompleteLSTMModel$), but the latter only retrieves the contents of the model initialised by the LSTM service so that it can be used locally and aggregated (if necessary) with that of other nodes.
This latter class, which is instantiated by the learning twin, interacts with the LSTM service to perform the various operations on the model: this enables the model to be initialized, trained, updated and predictions to be applied. Unlike Markov Chains, the LSTM model class acts as an intermediary, delegating the execution of all these operations to the external LSTM service.
It should be noted that the data structure contained in the $VariableLstmModel$ class is hierarchical according to
-  at the upper level, the RNN layers, each of which may contain (or not) matrices for the 3 types of parameters $w$, $u$, and $b$.
-  at the lower level, the matrices of each of the 3 parameter types:
-  $w$: weight matrix applied to input signals.
-  $u$: weight matrix applied to signals from the previous hidden layer.
-  $b$: bias vector.
The number of layers as well as the sizes of the different matrices are entirely defined by the LSTM service: no restrictions are applied on the $VariableLstmModel$ side, which allows the hyper-parameters to be modified on the LSTM service side without having to modify the $VariableLstmModel$ class (or one of its subclasses).
Interaction between the coordination platform and the LSTM service:
5.2.3.3) Integration of a new model:
At present, only the two learning models of Markov Chains models and LSTM are implemented, but the architecture used by LSTM makes it quite easy to integrate a new model, as the Keras python API contains many different models and the REST service that interacts with the coordination platform has already been set up. Figure 5.40 shows an overview of the integration of a new machine learning model that we call 'XXX'. Integrating a new model means, on the one hand, creating the class which represents the learning model at the level of the learning twin and, on the other hand, adapting the prediction external services already in place to integrate the new type of model in the ML external service.
-  Implement the new model which extends the $AbstractLearningModel$ class (represented by the $CompleteXXXModel$ class in figure 5.41)): this class encompasses the prediction models for the different variables to be predicted (for each variable: an instance of the model class which predicts a single variable). The implementation must include this class's aggregation method, which is invoked by the aggregation coordination law (As is done for the $CompleteLstmModel$ class).
-  Implement the corresponding model class that corresponds to a single variable (represented by the $VariableXXXModel$ class in figure 5.42)).
Depending on the structure of the layer, this class can use existing classes that model neural network layers.
-  Adapt the external prediction service to integrate the new model (represented by the ML external Service in figure 5.43)). This service can be implemented using the same method of receiving REST requests as that used for the LSTM service: it requires the processing to be adapted to take account of the structure of the new model to be integrated and the Keras APIs to be invoked to initialise the new model.
-  implement the initialisation method in $DataStore$ class (as done for init_model_LSTM).
-  integrate the new model in app.py, in methods train_model, update_model_weights, get_model_info, as done for the LSTM model).
-  Update the model class that predicts a variable so as to write all the calls to the prediction service previously updated.
Integration of a new machine learning model 'XXX' (represented in blue):
5.2.4) Implementing the coordination platform REST controllers:
The REST server manages the processing of requests from client applications (web or test simulator) that solicit the coordination platform, for example to instantiate, modify or delete Digital Twins, display the status of various processes, or modify the configuration. The implementation of this server initially used spring boot 2.3.2 API and currently uses a lower-level library ($com.sun.net.httpserver$) to reduce memory consumption.
The single instance of the $LightHTTPServer$ class manages the REST server that receives HTTP requests. Requests follow REST protocol and request parameters are written in JSON format. Each time a REST request is received, the $LightHTTPServer$ class performs the following processing:
-  it identifies the handler module (of class $AbstractHandler$) which will process the request. The handler key corresponds to the first part of the request URI.
-  it transfers the request to be processed to the corresponding handler.
-  it retrieves the resulting object from the handler processing and converts it to JSON format.
-  it embeds the JSON object in an HTTP response and writes its contents to the response buffer of the client socket.
This class contains a mapping table of handlers whose key corresponds to the URI prefix of the REST request. As represented on the UML diagram 5.44, the commonly used handlers are:
-  $EnergyHandler$: processing requests for Digital Twins of microgrids, energy exchanges and energy-related predictions.
-  $ConfigHandler$: processing requests for node configuration (update and display).
-  $SapereHandler$: processing requests for LSAs present in tuple space (update and display).
Class diagram of the coordination platform's REST server:
5.3) Use of relational databases:
5.3.1) Coordination platform database:
Each instance of the coordination platform running on a node uses its own instance of this database. Consequently, there are as many SQLite database instances as there are nodes running the coordination platform. In the current version, the coordination platform service creates a new local SQLite database at start-up, with all the data structures and views required for it to function. The initialization scripts can be found in the resources of the executable jar:
-  init_script.sql: script for initialising common structures.
-  init_script_markov.sql: script to initialise the structures used to save predictions (not used if the prediction calculation option is not activated in the node configuration).
An SQLite relational database is used to store certain data generated by the coordination platform service, in particular by the digital twins. In a previous version, this database was based on MariaDB: it was then migrated to SQLite so that it could run on a Raspberry Pi. This database is used to store 3 main types of data:
-  network configuration data, including the network address of the local node and those of neighbouring nodes.
-  all events and states that have occurred on the node (and neighbouring nodes). These events are recorded by the prosumer twins.
-  prediction results recorded by the learning twin.
It should be noted that this database is not used in any coordination mechanism but exclusively by the coordination platform service to configure the node and display the history of the prosumer twins, and by the learning model to record predictions and transition matrices.
This data contains consumer events (production/request/energy contract), offers generated by prosumers, node status (power demanded, produced, consumed, etc.), predictions, Markov chain training data, and the taxonomy of electrical appliances and energy sources.
Self-incrementing primary keys are used to identify each data tuple, and foreign key constraints are used as referential constraints.
5.3.1.1) table cluster dedicated to energy exchanges:
This table cluster concerns mainly the history of energy events and also includes node configuration data. As figure 5.45 shows, all tables have links to other tables (which are the reference constraints, represented by foreign keys). The energy events table ($event$) plays a central role, as it is referenced by many other tables. The following tables are used for energy exchanges.
-  $node_history$: Records the power state of the node as a whole: it includes the value of the 6 power variables (corresponding to a total for all the prosumers attached to the node) and the maximum waiting time for requests (with the name of the consumer concerned). The learning twin re-calculates and registers in this table the node's global state each time an event occurs (the event(s) concerned are linked to this "node_history" tuple). The node's total is also calculated cyclically (every minute), regardless of the events that occur: in this case, its registration in question is not linked to any event and the total is considered as a simple refresh. These refresh records are used to track consumer requests that are in warning. The learning twin also re-calculates and records the global state at the instant just before (by one second) the start of a supply of a request that was previously on alert: this logs the maximum request waiting time.
-  $agent$: Records the characteristics specific to each prosumer (node, location, device name and category, environmental impact). This is the only non-time-stamped table since this data does not change during the course of the scenario.
-  $event$: Records all events occurring on the prosumer twins. They allow to track what happened for each prosumer. Each event has a start and expiration date, as well as a cancellation date (if the event is replaced by another event such as the modification of an energy production) as well as an interruption date (if the Digital Twin or the contract is stopped, for a particular reason). By default, the cancellation and interruption dates are not filled in and will always be empty if the event in question will go until its expiration date. Section 5.46 describes the event taxonomy in detail.
-  $link_event_agent$: This link table records the prosumers attached to a contract as stakeholders: each stakeholder is identified by its agent name and characterised by its role: consumer or producer, depending on whether the stakeholder is a supplier or a consumer in this contract. At present, several producers can be linked to this contract, while a single consumer can be linked to the same contract. This generic table structure will one day (if need be) make it possible to link also several consumers to the same contract. Depending on the role of the agent associated with the contract, the powers indicated correspond to those supplied by a producer or those received by a consumer, according to the terms of the contract. The min and max powers represent the possible margin of variation, without having to break the contract, as explained in section 5.47.
-  $link_history_active_event$: This link table registers the identifiers of all events active at any given moment in the node's status history: this table helps to recalculate the complete state of the node at a point in time in the past, and to identify all active energy demands, productions and supplies at any given moment. It also records the waiting time for unsatisfied requests with the aim of highlighting unsuccessful requests. Each record in this table is therefore linked to a node history record (node_history table) and an event (event table): consequently, the pair of these two identifiers must be unique. This table also contains a link to the previous and next instance of the same table, for the same event but at the previous and next instant in the node's history. This makes it possible to follow a specific event over time, from its creation to its expiry (or its interruption, depending on what happened). This table is mainly used to display the history of all events that occurred on the nodes and can also be used for investigations.
-  $single_offer$: Records all offers made by producers to consumers, whether (or not) they were successful. In addition to the wattage and price offered, it indicates whether the offer was received, accepted by the consumer, whether it resulted in a contract (with the contract event identifier). Each of these indicators is accompanied by the time-stamped moment of allocation.
The following tables are more general than energy management but contain links to the previous tables (they are referenced by the previous tables):
-  session: identifies the coordination platform's current execution session. This table allows each session to be differentiated, so that data from the previous session is not overwritten by the current session.
-  $node_location$: Records all node configurations (name, host, REST server port, LSA server port), whether for the local node or for direct or indirect neighbour nodes.
-  $node_context$: Records the platform's execution context on a given node and for a given scenario. This ensures that attribute context data is not overwritten by that of another scenario. Contains, for example, the time difference between the fictitious scenario time and the actual execution time (in milliseconds).
-  $context_neighbour$: Records the identifiers of direct neighbour nodes attached to a node context (this update occurs when a user adds or removes neighbours in the node context, from the web application).
TEST TO DELETE:
comment
Figures 5.48 represent the Entity-Relationship diagram concerning energy exchanges:
Entity-relationship diagram representing the tables used for energy exchange.:
5.3.1.2) Tables cluster dedicated to prediction data:
As depicted in figure 5.49, this table cluster is used to store the predictions themselves as well as the transition matrices used in the Markov chain learning model. The predictions are recorded regardless of the learning model used, whereas the transition matrices are recorded exclusively by the Markov chain model. The tables specific to Markov-Chains model are named with the prefix "_mc".
The more general tables:
-  $model_context$: includes prediction model parameters: prediction scope (local node only or whole nodes cluster), model type (LSTM or Markov Chain), aggregation operator used (or left blank if learning remains local). The learning twin can activate both node-level and cluster-level learning, in which case it will have 2 tuples from this table attached to the same node context. It can use (or not) aggregation for each of the two perimeters independently.
-  $state_history$: the learning twin records the states of the 6 power variables as they occur in this table at current time. Each state corresponds to a power range, and the state identifiers are exactly the different classes that make up the output data of the prediction model. The learning twin uses this table to compare the predicted state with the actual state observed at the horizon.
-  $time_window$: division of the day into time slots, which represents the time frame in prediction models. A prediction result on horizon or a transition matrix is linked to a single time slot.
-  prediction: prediction of one of the 6 power variables, made at a given time t and over a certain horizon. It includes the initial state (which corresponds to the time of the prediction), the predicted state at the horizon and the actual state observed at the horizon.
-  $prediction_item$: probability associated with one of the possible states in the prediction result. Takes the value 1 for the predicted state if the prediction is deterministic.
Tables specific to Markov models: this sub-cluster is structured around the transition matrix table (header of a Markov Chains transition matrix). These tables are not used in the calculations performed by a learning model, but only for backup purposes. This allows the coordination platform to be started from an existing backup of Markov transition matrices.
-  $mc_model_iteration$: Represents an iteration of the Markov model on a given day. This data makes it possible to filter the number of observations according to the linked iteration (for example, by taking only the last 100 iterations), so that the model slides over time. An iteration of the Markov model is incremented each day.
-  $mc_transition_matrix$: header of the transition matrix associated with a model, and one of the 6 power variables, and one of the time slots defined in $time_window$ table.
-  $mc_transition_matrix_cell_iteration$: number of observations registered by the Learning Twin for a given transition (from a previous state $I$ to a following state $F$) and for a given transition matrix (instance of $mc_transition_matrix$) and at a certain iteration. This data is used to calculate the contents of the cell ($i$, $j$) of the transition matrix, $i$ and $j$ being respectively the indexes of states $I$ and $F$. The link to the iteration table makes it easy to filter the number of observations to apply the Markov model learning window (also called sliding window).
Entity-Relationship Diagram of tables used for predictions and transition matrices.:
5.3.2) Data for test simulators:
This database contains all the data used to feed the various test simulators. It is particularly used for the "living-lab" scenario, as it contains the history of power measurements collected in "Les Vergers" (see section 5.50 and figure 5.51). There is a single instance of this database, which is used to feed data to an instance of a test simulator, which then injects data into all the nodes concerned. Each node instance then receives filtered data specific to its own node. Figure 5.52 shows the organization of the tables used to feed simulator data.
-  $device$: Registers all the characteristics of the electrical devices that can be used for the different scenarios. Each device is linked to a specific node ("node" field, which can be updated by the test simulator according to the desired assignment of nodes to each electrical device).
-  $sensor$: Registers the characteristics and location of each smart meter sensor, identified by its serial number. In the configuration of the 'Les Vergers' living lab, this is the CLEMAP smart meter.
-  $sensor_input$: Registers each sensor input identified by its sensor identifier and one of the 3 current phases ('l1' or 'l2' or 'l3'). It is important to note that each device can be single-phase or three-phase: in the first case, a single sensor input is linked to the device (with one of the 3 phases 'l1', 'l2' or 'l3'), whereas in the second case, 3 sensor inputs are linked to the same device (on phases 'l1', 'l2' and 'l3').
-  $measure_record$: Registers each sensor measurement at a given date. The frequency of the measurement is indicated in the code $feature_type$.
-  $phase_measure_record$: contained the measurement values of a corresponding phase (3 instances of this table are linked to a corresponding measure_record). The apparent, active, and reactive powers are registered in the attributes $power_s$, $power_p$, and $power_q$. The voltage and intensity are indicated only in low frequency measures (registered every minute).
-  $device_measure$: Records the "global" active power calculated for each device measurement. This data can therefore be used directly by the test simulator, as it directly provides the active power corresponding to a given device at a given time. This active power (power_p) is calculated from the active powers contained in the linked instances of phase_measure_record (corresponding to the same time and sensor). The device's active power corresponds to:
-  for a single-phase device: the active power absolute value contained in the single tuple of $phase_measure_record corresponding$ table that corresponds to the device phase.
-  for a three-phase device: the sum of the active power absolute values of the 3 related $phase_measure_record$ tuples (corresponding to the 3 phases 'l1', 'l2', 'l3', for the same device and at the same time).
-  $simulated_node_history$: This calculation table, which has no direct link with the previous tables, is used by the test simulator to temporarily store a pre-calculated history of the total power obtained for the 6 variables of each node (total produced, requested, supplied, consumed, available and missing). At start-up, each coordination platform retrieves this pre-calculated history (which corresponds to its node identifier) and then uses it as a dataset to train its learning model for the first time.
Entity-Relationship Diagram for data used by test simulators.:
5.3.3) Taxonomy of energy events:
Events precisely trace everything that has happened for each prosumer, whether producer or consumer. For example, they can be used to easily calculate electricity supplies or shortages, at any time since the coordination platform was launched.
Event types are characterised both by their category (indicating, for example, a start or a stop) and by the type of object to which they refer (request or production or contract).
The different types of event objects are as follows:
-  PRODUCTION: concerns a production of electricity by a producer.
-  REQUEST: concerns a demand for electricity issued by a consumer.
-  CONTRACT: concerns a supply contract of a consumer by one or several producers. We consider a supply to be directly linked to a contract, which is why we use the term "contract". This does not apply to a self-supplying prosumer as a contract requires at least two stakeholders.
The different event categories are the following:
-  Start: indicates the beginning of new production, request, or supply contract.
-  Update: indicates a change of an existing production, request, or supply contract.
-  Expiry: indicates the expiration of existing production, request, or supply contract.
-  Stop: indicates the interruption of an existing production, request, or supply contract.
-  Switch: Indicates the switchover from production to electricity demand or vice versa. This happens to a prosumer when, for example, its internal production drops so low that it can no longer meet its own needs.
Table 5.53 shows the possible event categories for each event purpose. We can see that only the "switch" event does not exist for contract purposes, as it only concerns production or consumption and does not directly concern a supply contract.
Use of event categories by object type (production, request, contract).:
5.4) The simulator programs:
The simulator programs run the various types of scenarios that supply the coordination platform with consumption and production data, which are either stored in the database or generated on the fly. The general principle is to load the data containing the prosumers and their respective consumptions and productions, and then, to initialise the coordination platform and the prosumers to be created. The simulator program then interacts cyclically with the coordination platform to create and update the prosumers (for example their consumptions or productions). In this way, the program runs for the entire duration of the scenario: an iterative loop runs at a set frequency to update the prosumer twins, until the scenario expires.
As shown in figure 5.54, these simulation programs are executable classes that inherit from the $TestSimulator$ class. The simulators all interact with the coordination platform by sending REST requests to initialise the coordination platform service and to create, update or delete prosumer twins. As these processes are 'clients' of the coordination platform, the simulators are programmed in an independent Java project and import certain classes defined in the platform via the coordination_plarform.jar library.
Classes that model test simulators:
5.4.1) The simulator general template:
The $TestSimulator$ class provides a common template for the different types of simulators. It contains the following common attributes:
-  $allDevices$ (list of $Device$ instances): list of electrical devices that will be used in the scenario.
-  $nodeContent$ (of class $NodeContent$): the node's current structured content, which includes
-  the coordination platform configuration of the local node.
-  the lists of the different consumer and producer twins.
-  the node total (of class $NodeTotal$).
-  the errors (and warnings) returned by the coordination platform.
-  the table listing the various neighbouring nodes in the network (linked directly or indirectly to the local node). This table is dynamically updated by the coordination platform after each LSA from a remote node is received.
-  the table listing the node distances at the current time.
-  $datetimeShifts$ (mapping table containing Integer instances as key and as value): time difference between the real date-time and the fictitious date-time in the scenario. This time difference is broken down in this table for each time unit of the Java Calendar class (milliseconds, second, hour, day, month, and year.).
-  $dbConfig$ (of class $DBConfig$): configuration of the simulator database.
-  $mapIsServiceInitialized$ (mapping table containing $java.lang.String$ instances as key and $Boolean$ instances as value): table that stores the initialisation state of the coordination platform attached to each node (in the form of a Boolean array per URI of each platform).
The $TestSimulator$ class contains the methods used to carry out the various actions required for the different scenarios. The following methods initialise objects by loading content from the simulator database:
-  the devices used in the corresponding scenario.
-  the history of device consumptions and productions (for simulators based on real data, such as the $LivingLabSimulator$ class).
-  the general statistics of household consumption and production (for simulators based on household statistics, such as the $HomeSimulator$ class).
The following methods send a request to the coordination platform and then retrieve the result in JSON format from the coordination platform response. The various actions are carried out by the coordination platform service.
-  $initEnergyService$: initialises and configures the coordination platform service.
-  $stopEnergyService$: deactivates the coordination platform service.
-  $initNodeHistory$: initialises the consumption and production history to train the learning model (the history is loaded from the coordination platform service).
-  $getNodeContent$: retrieves the complete node content (consumers, prosumers, node total).
-  $addAgent$: adds a new prosumer provided in argument.
-  $modifyAgent$: updates a prosumer provided in argument.
-  $restartAgent$: restarts certain prosumers which names are provided in argument.
-  $stopAgent$, $stopListAgents$: stops certain prosumers which names are provided in argument.
All these methods receive at least the REST URL of the coordination platform as an argument, bearing in mind that one URL is specific to a node.
5.4.2) The different simulators:
The various simulators can handle different types of scenarios. For the sake of simplicity, we won't go into detail about the implementation of each of them.
-  $RandomTestSimulator$: This scenario creates a hundred of producers and consumers on a purely random basis. This is the scenario for testing the scalability of Digital Twins when there are several dozens of electricity requests to process at the same time. This scenario can be easily adjusted to increase the difficulty while decreasing the production.
-  $HomeSimulator$: This scenario creates producers and consumers based on electrical appliance data stored in the database. The level of production and consumption is determined both as a function of statistical averages of household consumption by type of appliance, and partly in an aleatory manner, following a Gaussian distribution with respect to the statistical averages.
-  $LivingLabSimulator$: This scenario creates producers and consumers based on real data recorded in the database over a given period. The data most used are those from the 'Les Vergers' living laboratory located in Meyrin, which is collected since May 2022.
-  $AwardsSimulator$: This fictitious scenario, which has been modelled in the context of integrating social acceptance criteria, initialises a microgrid that allocates rewards and creates some prosumers belonging to this microgrid. One of the prosumers applies a 'Fee-riding' policy, which consists of not contributing while receiving energy from fellow prosumer (who have an 'altruistic' prosumer policy). With the aim of alternating the prosumers that need energy, the scenario regularly switches consumer to producer and vice versa. To do this, it allocates an overall power output to each prosumer: a producer becomes a consumer as soon as this power becomes negative and vice versa.
-  $StorageSimulator$: This fictitious scenario has also been modelled as part of the integration of social acceptance: it initialises a microgrid that allocates 3 prosumers and an external supplier with a planned cut-off in order to test the ability to cope with a general shortage. This scenario has two different variants: the 'private storage' variant, in which each consumer is configured to store its own energy for its own needs, and the 'common storage' variant, in which the coordination platform is configured to operate a digital 'storage' twin that manages energy storage for the entire microgrid.
5.5) The web application:
A web application has been implemented to display the power variables at a node, at the present time and in the past, from the time the coordination platform service was launched. As represented on figure 5.55, data exchanges between client processes and the coordination platform follow the REST protocol and are carried out using JSON objects encapsulated in HTTP requests. This application uses Angular 9, JavaScript, Node.js and the D3JS graphics JavaScript library (D3JS displays numerical data graphically and dynamically: it is used in the node history web page to display changes in power variables over time).
Each web page follows the MVC (model-view-controller) design pattern, which has the advantage of defining a weak coupling between presentation, data, and business components. The "view" part is declared in an extended version of traditional HTML, with new tags and attributes. This extended HTML language is used to declare a bidirectional data link between models and views so that data is automatically synchronised. Services are provided to the component via the dependency injection system. Each view corresponding to a web page (%page_name) is coded in 3 different files:
-  %page_name.component.html, which is the web page template
-  %page_name.component.ts, which is the assorted controller: it describes the interaction between the web page and the REST server. The controller also defines the structure of the data that is displayed on the web page and exchanged with the coordination platform's REST server via HTTP forms. Each structured data item is translated into a JSON object before being encapsulated in a REST request or response.
-  %page_name.component.css, which defines the different CSS classes used in the web template.
5.5.1) Node configuration:
Figure 5.56 displays the configuration screen, showing the node's current configuration. The various elements of the node's location appear at the top: the node name, its host address, the LSA server and REST server ports, as well as a list of direct neighbours (identified by their node name). These configuration parameters can be updated at any time. For example, we can enter a new neighbour node or delete an existing neighbour. These changes are taken into account dynamically by the coordination platform.
Node configuration:
5.5.2) Node snapshot view management of the current node state:
This node snapshot view (see figure 5.57) tracks all consumer and producer devices attached to the node, as well as the node total (wattage requested, produced, supplied, consumed, missing and available). This view also displays the links between producers and consumers defined in the supply contracts:
-  For each consumer, all its suppliers are displayed in the column "Supplier(s)" with the exact wattage for each supplier. There are as many values as there are contracts in which this consumer appears as a recipient.
-  Similarly, for each producer, all its supplied consumers are displayed in the column "Client(s)" with the exact wattage for each consumer. There are as many values as there are contracts in which this producer appears as a supplier.
The filter at the top left displays producers or consumers belonging to a specific device category. A "multi-node" option lets us include prosumers from neighbouring nodes.

Manual modification operations:
-  add a new producer or consumer twin.
-  modify an existing prosumer twin (via the button "modify").
-  stop an existing prosumer twin (via the button "stop").
-  restart an existing prosumer twin that has been stopped (via the button "Restart").
Node current snapshot:
5.5.3) Display of the node history:
The node history (see figure 5.58) displays in table form the chronology of the node's state and of all the events that have occurred on the node since the coordination platform was started. Table 5.59 displays the taxonomy of the different event types.
It should be noted that a history line corresponds to the state of the node at a given moment: at that moment, there may be a single event, several events, or no events at all: in the latter case, the line corresponds to a simple refresh performed by the learning twin (hence the "Refresh" mentioned in grey, in the "Event type" column). As the coordination laws are executed every second, the data is time-stamped to the nearest second, meaning that several events can occur at the same time.
The node status contains the following variables: total wattage requested, produced, supplied, consumed, missing and available, as well as the list of unsatisfied requests, the list of requests "in warning" (i.e. unsatisfied whereas they can be supplied in terms of available power). The list of "warning" requests can be used to identify problems in the generation of supply contracts, and the history of events and offers also helps to analyse the cause of an unsupplied request.
Table of node history.:
This table can be used to investigate unsatisfied demands that have been put on "alert", as it allows to visualise in detail everything that has happened. As shown in figure 5.60, we can display the offers of energy that have been issued between different historical refresh times.
Display of offers on the right column.:
A filter in the top left-hand corner allows to display only events issued by a particular prosumer.
As represented in figure 5.61, a graphical display shows the evolution of each variable of the node's status over time. It is generated using the D3js JavaScript library.
Graph of node history.:
At the top of the graph, the cumulative and maximum duration of requests "on alert" is displayed, as well as the total KWH produced and the ratio of KWH "on alert" (KWH requested and not served when availability was sufficient at node level).
5.5.4) Display of the learning model weights:
A dedicated page displays the instant content of all the weight matrices in the training model. Depending on the model being run, these may be Markov chain transition matrices or LSTM neural network matrices. The web application sends a REST request to the coordination platform service to retrieve the content of the training model: depending on the type of learning model used by the platform, the web page will display the weight matrices of the model organised with the 'Markov Chains' or 'LSTM' structure.
-  In the case of Markov Chains, there is one matrix per time slot and per component of the node state (see figure 5.62). Each matrix contains the probabilities of each possible transition from a start state to an end state.
-  In the case of LSTM, the model structure is composed with different types of layers:  'LSTM', 'Dense', and 'Dropout' layers. Each layer contains a set of 0 to 3 weight matrices, one matrix (or nothing) being associated with each of the 3 parameter types:
-  $w$: Weight matrix applied to input signals.
-  $u$: Weight matrix applied to signals from the previous hidden layer (as shown in figure 5.63).
-  $b$: Bias vector.
An 'LSTM' layer contains a matrix for each of the three parameter types, while a 'Dense' layer contains a matrix only for the $w$ and $b$ parameter types and a 'Dropout' layer contains no matrix at all.
Display of Markov Chains transition matrices.:
Display of LSTM matrices:
5.5.5) Display of prediction accuracy statistics.:
The statistics page provides evaluations of the prediction model used, either at node level or at cluster level, depending on whether the latter two prediction perimeters are enabled in the node configuration parameters. It displays the means of the accuracies obtained on all the predictions generated by the learning twin, through its learning model (see figure 5.64). To do this, the learning twin compares the predicted states with the observed states on the horizon: for each prediction recorded in the database, it updates the observed state on the horizon on the record as soon as possible, which then allows the difference between the predicted and observed states to be deduced immediately. For each of the 6 electrical power variables, these results are aggregated by time slot of each day to obtain more global results. The top filter also allows to merge results by horizon and time slot.
The total line displays the result obtained by aggregating all filtered predictions.
In addition, Shannon entropy and Gini index are evaluated over the same period to determine the level of volatility of the variables to be predicted: the results are displayed in the 2 corresponding columns. This makes it possible to verify whether (or not) there is a strong correlation between the entropy of the variable to be predicted and the drop in accuracy of the prediction model, during the same time slot. For example, the entropy of the power produced by photovoltaic panels is at its highest during the middle of the day: this means that volatility is particularly high during these hours, making it more difficult to predict the electrical state.
We should note that the difference is calculated in two different ways:
-  either as a single scalar, by comparing the predicted and observed states per prediction
-  or as a vector which corresponds, by comparing the actual distribution of the different states over the corresponding period, with the average of the probabilities obtained for each state, at the same period. This evaluation is more relevant when the learning model returns probabilistic vectors, such as Markov Chains.
Display of predictions statistics:
5.5.6) Functionality to generate real-time predictions from a previous moment:
A simulation interface has been implemented to replay predictions, either individually, starting from a single instant (see figure 5.65), or serially (see figure 5.66), starting from different instants of an entire time slot. The learning twin then generates these predictions on demand, evaluates the difference from the actual state at the horizon (unless the moment at the horizon has not passed) and returns the set of results obtained for each prediction.
This feature can be used, for example, to check the impact of variations in prediction model weights over time on the model's performance, by replaying the same prediction each time, from the same points in time and with the same horizons.
In a similar way to the display of past predictions, the result shows the predicted states as well as the accuracy obtained, for each prediction separately, and in the last line, aggregated over the whole series of predictions. The entropy of the corresponding time slot is also displayed.
Unitary prediction generation:
Generation of a prediction series over an entire time slot:
5.5.7) Real-time verification of learning model aggregation:
As shown in figure 5.67, a display feature has been implemented to visualise the result of the last aggregation that has been applied to the learning model: it shows the respective weights assigned to each node in the last weight aggregation calculation. This feature allows to check that aggregation has been applied to the training model (and with which aggregator) and to see in greater detail the different coefficients attributed to the models of the various neighbouring nodes. In this example, the weights of each node are aggregated, based on the "dist_power_hist" aggregator shown above. This aggregator is based on the "power profile" distance between nodes (which is based on the history of values taken by the power variable to be predicted). In the case where the learning twin applies an aggregation to both training models (i.e. node-level model and cluster-level model), it is possible to select each of the two perimeters (nodes or cluster). In the filter, it is also possible to select any time slot and any power variable.
Markov Chains learning model aggregation:
LSTM learning model aggregation:
5.6) Adaptations to reduce memory usage:
As a reminder, the CLEMAP device is a Raspberry edge computing unit with the functionality to interact with surrounding electrical devices using sensors and actuators. Given that, as part of the Lasagne project, we are running several services on the same Edge device (see figure 5.68), it was necessary to undertake some works to reduce the memory consumption of the coordination platform, which totalled over 300 megabytes.
Architecture on a raspberry Pi device:
5.6.1) Monitoring of used memory:
Firstly, we have monitored the memory usage by the coordination platform, to detect memory leaks or identify excess memory consumption.
For this, we used the Visual VM tool which enables real-time monitoring of memory consumption by each instance of the coordination platform. This tool makes it possible to monitor consumption for several hours at the level of each Java class of the application. Consumption is then logged and displayed on a graph. Following various simulations, several memory leaks were identified in the coordination platform (see figure 5.69, which shows a gradual increase in memory used represented in blue and memory allocated represented in orange). Thanks to these leak detections, we continued investigations and made the necessary fixes to various locations in the application to resolve these leak problems. After each patch, we re-monitored memory consumption with Visual-VM and ensured that memory leaks disappeared.
Detecting Memory Leaks using Visual VM.:
The instantaneous consumption appears in blue, and the space allocated by the VM appears in orange. In this screenshot, we can notice that the allocated space increases significantly over time and never decreases, which shows the existence of leaks.
5.6.2) Replacement of spring-boot server by a lighter server:
The coordination platform includes a REST server that receives creation, modification and deletion requests from the various consumers and producers. This server uses Spring-Boot technology, which provides many features to facilitate web application development, but its memory consumption is not suitable for an environment with limited memory space, such as a Raspberry Pi. To reduce memory consumption, we replaced spring-boot with a more basic Rest server that uses the Java library $com.sun.net.httpserver.HttpServer$.
5.6.3) Replacement of MariaDB & MongoDB by SQLite3:
The coordination platform used initially 2 different databases:
-  a MariaDB database to store the history of electricity requests and exchanges.
-  a MongoDB database to store the node configuration.
As MariaDB and MongoDB servers both consume a lot of memory and are not suitable for an environment with limited memory capacity, we have replaced them with an SQLite-type database: the latter offers fewer functions but is better suited to this type of environment as it only uses a file to store data and does not require a server. This saves disk space and memory and makes deployment easier. We undertook the migration in tows stages:
-  Merge of the two existing databases into MariaDB so that all data and queries are stored in a single database. As the MongoDB database contains far less data and queries, we transferred the data and queries to the MariaDB database.
-  Replacing MariaDB with an SQLite3 database. This part of the migration was the most time-consuming, given that the functionalities offered by SQLite are relatively limited. For example, we had to replace SQL functions and stored procedures (which are not accepted in SQLite) with processing to be carried out in the calling code. In addition, most of the queries have been revised, due to the differences in SQL syntax between MariaDB and SQLite.
5.6.4) Lightening the Digital Twins objects:
It is particularly important to examine memory consumption by Digital Twins because the data stored in memory by them can increase rapidly due to the large number of coordination law exactions (one per second and per coordination law for each Digital Twin).
In the previous version, we identified some redundant data that could potentially increase the memory used during the execution of each coordination law. A typical example of redundant data was the $tableChosenLsa$ table of the $EnergyAgent$ class, which was therefore common to all the prosumer twins. This mapping table, which stores all the LSA objects retrieved by the Bonding law, was never cleaned (which led to regular increases in the amount of memory used). In addition, this table was redundant as each digital twin already stores some of the information received from the LSAs via another mapping table adapted to its own needs with "smaller" objects that are regularly cleaned. For example, the learning twin stores the identifiers of previously received events in the $mapReceivedEventKeys$ table, so as not to process them more than once. This table is regularly cleaned up (after an event's keys have expired, which happens about 20 seconds after the event has been created).
Other examples of redundant attributes were found, such as the authentication of an agent that was stored in the $Agent$ middleware class: this same authentication object was also present in the agent's LSA (i.e. contained in the $lsa$ attribute of the same class $Agent$).
Removing these unnecessary attributes has therefore reduced the memory consumption of the digital twins and, consequently, of the coordination platform..
5.6.5) Deactivation of functionalities not used (prediction, quality of service):
In the version of the coordination platform used for the Raspberry-Pi edge device, predictions are already calculated by the forecast service developed by HES-SO Geneva and the results of the predictions are retrieved from that service: as a result, the coordination platform does not need to calculate the predictions by itself. As a learning model tends to use a significant amount of memory and processing time, we have added an option to disable learning and predictions, using a configuration parameter in the coordination platform. This enabled us to reduce the memory space used in the Raspberry-Pi version by disabling learning and predictions. Similarly, we have disabled the quality-of-service assessment functionality, which is based on reinforcement learning to help assess the usefulness of different services created on the fly. This functionality is not used in the Lasagne project either.
5.6.6) Results:
As shown in table 5.70, tests on a 4-nodes configuration have confirmed a significant reduction in the amount of memory used after applying these updates on the coordination platform. These simulations were carried out with the learning and prediction feature disabled. In addition, as shown in figure 5.71, memory observations carried out with Visual VM have made it possible to check memory usage more precisely in real time and the absence of a gradual increase in consumption.
Comparison of memory usage and heap size (in megabytes), before and after corrections, running 4 instances of the coordination platform in a 4-node chain topology on a single VM.:
Monitoring of memory leaks after corrections.:

Deployment for the 'Energy Data Hack Day 2023' event:
As part of the "Energy Data Hack Day 2023" challenge (Footnote: https://energydatahackdays.ch/english), we developed a version of the coordination platform that can run on an VM environment similar to that of a Raspberry Pi 3 and that can communicate with the forecasting service (developed by HES-SO Geneva), to retrieve the predictions of energy production and consumption. We deployed a Docker image of the coordination platform and ran it on a VM environment with characteristics similar to that of a Raspberry Pi3.
5.7) Link to source code:
We have made the sources of the implementation available in free access, in a GitHub repository. A docker image of the coordination platform is available on docker hub.
The source code includes the various components defined in the software architecture (see figure 5.72). The coordination platform service is a Java application, while the web application uses AngularJS and the machine learning server (not shown in the figure) runs in Python.
5.7.1) Java projects:
There are 3 different Java projects (one for each software component). They can be easily imported into the Eclipse Integrated Development Environment.
-  sapereMiddlewareStandalone: This project contains the source code for the middleware library derived from SAPERE. It generates the SapereV1.jar library, which defines the tuple space and coordination mechanisms. This library is not directly executable.
-  sapereapi: This project contains the source code for the coordination platform service and the Digital Twins. It imports the SapereV1.jar library and generates the executable library coordination_platform.jar which corresponds to the light server (its main class is $LightServer$ class). This service can also run using a Spring server (in this case, we launch the $SapereAPIApplication$ class). For this reason, the sapereapi project is a 'Spring-boot' project and uses the Spring and Maven libraries. It should be noted that the Spring server is no longer regularly used, as the Spring server consumes more memory than the 'light' server.
-  saperetest: This project contains the test simulators: there is one main class per simulator. This project imports the coordiantion_plarform.jar library because the simulators use certain classes defined in the coordination platform, such as the structures of the various objects exchanged with the different REST services (input and output objects).
5.7.2) Python projects:
These are two independent python projects, both of which can be imported into the PyCharm integrated development environment:
-  download_gcp_file: This project includes scripts for importing smart-meter measurement data from the Exoscale cloud made available by the school HES-SO Geneva. This measurement data is extracted from files and stored in the database. The download_gcp_file project is independent of other projects and only imports a specific library to query the Exoscale cloud server.
-  lstm: This is the source code for the machine learning service, which currently only implements the LSTM model. This project uses the Keras and TensorFlow external libraries for machine learning and the Flask library, which defines a REST server model. The executable file (app.py) corresponds to the source of the Flask REST server.
5.7.3) Angular JS projects:
This is the sapereangular project, which can be imported into the Visual Studio Code integrated development environment. This project contains the source code of the front web server. There is one instance of the front-end web server running per platform coordination. The project is broken down into one module per web page, which is accessed as a tab, and each web page contains 3 types of source file: the HTML template, the controller that interacts with the REST server (.ts file) and the css style sheet.
Chapter 6) Gossip coordination mechanism for Decentralised Learning:
In the field of machine learning, the "gossip" mechanism consists of using the elementary aggregation and dissemination mechanisms to share the knowledge acquired by different entities located at different nodes, and to work towards a cluster-wide consensus.
In this contribution, we propose to use the coordination model to implement this gossip mechanism applied on knowledge shared by the Digital Twins involved in training learning models. In this way, the gossip mechanism will reinforce the knowledge of electrical behaviour, at the cluster level of a microgrid consisting of several nodes.
In section 6.1, we will present two ways of applying the gossip pattern to machine learning ("Gossip Federated Learning", which is based on model sharing and "Gossip Ensemble Learning", which is based on prediction sharing), while in the next section 6.2, we will focus on integrating the Gossip pattern into the coordination model, and finally in sections 6.3 and 6.4, we will focus on implementing the two presented approaches using the Gossip pattern. In this chapter, we won't go into the details of the learning models themselves (described in section 6.5), but we will instead focus on the distribution framework that allows learning models (or predictions) to be exchanged between different nodes to improve knowledge on the scale of a cluster of nodes.
6.1) Two different ways of using the Gossip mechanism.:
Decentralised knowledge sharing between different nodes in a network can be achieved in different ways, depending on whether the learning models have the same structure or not. Either the different entities manage learning models with the same structure, in which case it is possible to exchange model weight parameters to make each node's model "more efficient" in predicting electrical behaviour at a local level or cluster level. In this case, we can try to adopt a Federated Learning strategy based on the gossip mechanism.
Either this is not the case: the entities have heterogeneous structural models, and exchanging model parameters makes no sense. In this case, it is possible to benefit from the learning experience of other nodes by exchanging the prediction data generated by the different nodes. It is always possible to aggregate prediction results, whatever the learning model used by the nodes. In this situation, we can adopt an "ensemble" learning strategy, based on a gossip mechanism.
In both cases, we are talking about decentralised learning using the gossip mechanism, but in the first case, we are talking about Federated Learning and applying aggregation to learning models, while in the second case, we are talking about Ensemble Learning and applying aggregation to the predictions themselves.
6.1.1) The Gossip Federated Learning approach:
First, let's define the key concepts. In machine learning, Federated Learning is a learning paradigm in which several machines collaboratively train an artificial intelligence model while keeping their data local. Gossip Federated Learning corresponds to a paradigm in which agents communicate directly with each other and disseminate their local models peer-to-peer. We then propose to adapt this definition to the use of the bio-inspired gossip pattern that we are using in this research.
In the context of this contribution, we define Gossip Federated Learning as a purely decentralised approach to share and optimise learning across a cluster of nodes by using the gossip coordination mechanism implemented in each node. The gossip mechanism consists of spreading learning models from one node to another and merging models by aggregating them. This approach assumes that all nodes try to predict the same type of behaviours, using machine learning models with similar structure. The different nodes are also supposed not to exchange their training data samples with each other, which remain private.
This latter definition is based on the bio-inspired pattern of gossip [116]. Indeed, if we apply the gossip pattern to machine learning model weights, we can implement a purely Decentralised Federated Learning approach where each node plays a full role in learning and knowledge distribution. Firstly, it contributes to improving knowledge of a behaviour (by training its model with its own local data), secondly, it benefits from the knowledge acquired by its neighbours (by receiving their learning models) and finally, it participates in the distribution of models (by sending its model content to all its direct neighbours at each gossip cycle).
This Gossip Federated Learning approach contrasts with the Centralised Federated Learning approach, where a central server manages all aggregation and distribution to the "client" entity (which trains the model with its own local data).
As shown in figure 6.6, the principle is that each node manages the aggregation and spreading of models at its own level. The upper figure shows phase 1, which consists of training the learning model from local data, while the bottom figure shows the next 3 phases, which is to apply the Gossip mechanism on learning models. Periodically, each node:
-  Trains iteratively its own learning model using its private local data updated with the latest observations (see step number 1 on the upper figure).
-  Receives model weights from surrounding nodes which are directly linked (see step number 2 on the bottom figure).
-  Aggregate the models received into one merged model. its own model is also included in the aggregation (see step number 3 on the bottom figure).
-  Spreads its updated model to the surrounding nodes which are directly linked (see step number 4 on the bottom figure).
It is worth noting that the frequency of gossip application can be adjusted so that the accuracy obtained by the model is optimal. It should be at least equal to the model update frequency (at the risk of unnecessarily broadcasting model weights that have already been sent) but can be less than the relearning frequency.
We can also note that the physical constraints of the electrical network (represented in red in Figure 6.7) which have an impact on the transmission of energy are not directly dealt with in the Gossip Federated Learning approach. In fact, these constraints impact the values of the power variables rather than their transmission between the node computing units since this is not a latency problem on the data network. The power values we retrieve from smart meters in the living lab already take this loss into account. If these transmission problems have a recurring impact on the values of power variables at particular time slots, the learning models will be able to integrate these changes in behaviour into the weight matrices and therefore into the generation of predictions.
On the other hand, data transmission constraints have a direct impact on the way the Gossip Federated Learning approach works. As explained in more detail in subsection 6.8, given the high volume of data exchanged between the nodes, we had to reduce the gossip frequency on the learning models and use a mechanism for compressing learning model contents when broadcasting them to other nodes. In this way, we were able to achieve fluidity in exchanges between nodes. However, given the varying distance between neighbouring nodes, the update dates of the models injected into the gossip mechanism will always be a few seconds apart. However, this difference is very small compared to the frequency of Gossip application or model retraining (which can be counted in minutes, or even tens of minutes depending on the type of model).
Using coordination mechanisms to implement the Gossip Federated Learning approach.:
6.1.2) The Gossip Ensemble Learning approach:
As mentioned in section 6.9, the Ensemble Learning approaches offer an alternative to Federated Learning for sharing knowledge acquired by different independent entities. Ensemble Learning is defined as a common group-wide learning paradigm, using different machine learning models and combining them, with the aim of improving the reliability of predictions made by the cluster of nodes.
However, there are many Ensemble Learning approaches with different ways of combining models. In our approach, we propose to combine only the predictions generated by each of the models: this seems to us to be the simplest and most natural way, as it does not involve sending model samples (which remains private for each node) and limits the number of bytes to be exchanged.
Unlike Federated Learning, different nodes can use different types of learning models, but similar to Federated Learning, the different models must predict the same type of behaviour and are assumed to keep their local dataset private. In the same way, we propose to define a purely decentralised Ensemble Learning approach based on the use of the bio-inspired gossip pattern.
In the remainder of this manuscript, we define Gossip Ensemble Learning as a purely decentralised approach to sharing and optimising predictions of common behaviours across a cluster of nodes using the gossip coordination mechanism, by spreading prediction results from one node to another and merging prediction results, by aggregating them.
This approach has the advantage over "Gossip Federated Learning" of being able to integrate nodes with different models, and of requiring less bandwidth to spread to neighbouring nodes, as the prediction data is far less voluminous than the weight data of a learning model. However, as this approach only shares the results of predictions (and not the content of the models themselves), it cannot apply an aggregator that evaluates and compares the performance of models, such as the 'power_loss' aggregator.
It should be noted that despite this difference, the general mechanism remains the same. Indeed, the general stages (1,2,3,4) which involve local updates, reception, aggregation, and spreading are similar to those of Gossip Federated Learning. The difference is that these operations are applied to predictions rather than learning models.
Using coordination mechanisms to implement a Gossip Ensemble Learning approach. This figure illustrates the use of different types of learning models depending on the node. In this approach, each node manages distribution and aggregation of predictions.:
6.1.3) Overview of implemented approaches:
Table 6.10 situates the two approaches implemented in our contribution (displayed in bold) in relation to the main existing approaches to distributed learning. The type of distribution is either centralised or decentralised, while the data exchanged can be training datasets, model weights or model predictions. In our contributions, we deal exclusively with decentralised distributions, with exchanges of model weights and predictions. It should be noted that training dataset exchanges are not addressed, as we consider these data to be private and should not be disseminated to other nodes.
Synthesis of distributed learning approaches (centralised versus decentralised and the 3 types of data exchanged). The two approaches we are implementing are highlighted in bold.:
Table 6.11 highlights the similarities while table 6.12 highlights the differences between the two approaches Gossip Federated Learning and Gossip Ensemble Learning, based on various criteria. The result is that the Gossip Ensemble Learning approach is less restrictive, so it is preferable to use it if we don't have a lot of resources, bandwidth and time for integration. On the other hand, the Gossip Federated Learning approach can offer more possibilities in terms of accuracy optimisation by playing on the different aggregation operators. We will see in section 6.13 that it is possible to reduce bandwidth by using some of the adaptations implemented.
Similarities between GFDL and GEL.:
Differences between GFDL and GEL.:
6.2) Integration of the Gossip pattern into the coordination middleware:
Our approach is to use the bio-inspired mechanisms provided by the platform to implement decentralised learning, enabling multiple nodes to share knowledge. As shown in figure 6.14 and explained in definition 6.15, the gossip pattern uses the elementary patterns of aggregation and spreading: each of them appears in the "Basic Patterns" layer and is materialised in the coordination model by the two coordination laws of aggregation and spreading, and the combination of these two laws makes it possible to implement a gossip mechanism, which is applied to learning models, within the framework of Gossip Federated Learning.

Gossip is a mechanism for obtaining shared agreement on information among a set of digital twins in a decentralised manner. All the digital twins work together to gradually reach this agreement by aggregating their own knowledge with that of their neighbours. The Gossip mechanism consists of two elementary mechanisms:
Aggregation, which consists of enriching information by merging its values received from surrounding Digital Twins, using a specific operator (e.g. sum or average) and Spreading, which consists of sending information from one Digital Twin to its surrounding neighbours.
We now describe how the Gossip mechanism gradually achieved consensus. Let's consider a specific piece of information on which a cluster of nodes applies gossip. At start-up, each node contains a different value of the same information but at each gossip application cycle, this same information is broadcast to neighbouring nodes and each node applies an aggregation operator receiving as input its own value as well as that received from its neighbours. A received value may already have been aggregated previously by indirect neighbours. Regardless of the operator used, in each node, the aggregation will end up directly or indirectly integrating the version of all the other nodes: as a result, the gossip makes it possible to arrive progressively at a convergent result, which corresponds to a consensus. The speed of convergence and the obtained consensus value can vary depending on the operator used (for example, min or max or average or other type of operator). In some cases, convergence is delayed if a node modifies its local version before the information has had time to converge. Indeed, in this context of dynamic adaptation, the digital twins attached to the nodes regularly modify their properties and, as a result, new values regularly arrive in each aggregator.
Subsections 6.16 and 6.17 describe the implementation of these two elementary mechanisms within the "SAPERE derived" middleware.
Gossip pattern: combination of aggregation and spreading patterns, inspired from bio-inspired design patterns [117]. The bottom layer, called "basic patterns", contains the four elementary patterns currently implemented in the current version of the "SAPERE derived" middleware, in the form of coordination mechanisms.:
Algorithm 6.18 represents the Gossip process loop which invokes the aggregation and dissemination mechanism at regular intervals. Gossip is applied to the variable $nodeObject$, which represents the object to be aggregated and disseminated: this is a learning model (in the Gossip Federated Learning approach) or a prediction (in the Gossip Ensemble Learning approach). The processing loop involves the following main steps represented in algorithm 6.19:
-  local update of $nodeObject$: see step 6.20.
-  aggregation of $nodeObject$ and received objects: see step 6.21.
-  dissemination $nodeObject$ to neighbouring nodes: see step 6.22.
It should be noted that the local updates frequency and aggregations frequency are lower than the coordination laws frequency: for this reason, local update and aggregation is not systematically applied at each iteration (see the IF condition in step 6.23 and 6.24).
Gossip processing loop applied on an object called nodeObject (learning model or prediction). The two constants UPDATE_PERIOD and GOSSIP_PERIOD correspond to the inverse of the update and gossip frequencies.:
Comment of algorithm: first local update: model training for GFDL or prediction calculation for GEL.
True Iterative processing of the coordination laws.
Comment of algorithm: wait for 1 second. (Time elapsed between 2 coordination law cycles).
Comment of algorithm: reception of the LSA from neighbouring nodes.
$ (currentTime() >= nodeObject.lastUpdateTime() + UPDATE_PERIOD) $ check whether it's time to apply a new local update.
Comment of algorithm: iterative local update
$ (currentTime() >= nodeObject.lastAggregationTime()) + GOSSIP_PERIOD) $ check whether it's time to apply a new aggregation.
Comment of algorithm: call for aggregation
$ (nodeObject.lastUpdateTime() >= lsa.lastSpreadingTime()) $ check whether the node object is updated.
Comment of algorithm: activate the diffusion to neighbouring nodes.

6.2.1) Implementation of a generic aggregation mechanism:
The aggregation mechanism implemented draws inspiration from a previous implementation of the SAPERE middleware, which applied an aggregation on an LSA directly and not on a particular property of the LSA. This version could not be suitable as all the LSAs to be aggregated were deleted and replaced by the LSA resulting from the aggregation, which had the result of deleting all prosumer agents concerned. Furthermore, it was not possible to define the aggregator outside the middleware library and the aggregation functions only applied to simple objects like numbers, strings, or dates. These are "standard" aggregators, like the min/max or average function.
In addition to this, the need arose to execute aggregations on several different properties of the same LSA (i.e. several different aggregators attached to the LSA).
The aggregation mechanism has therefore been completely overhauled, so that it can be applied to any LSA properties and provide a degree of flexibility.
6.2.1.1) General algorithm for aggregation:
Algorithm 6.25 represents the general aggregation process, which comprises 3 stages:
-  Retrieval of the objects to be aggregated: see step 6.26 and 6.27.
-  Execution of the aggregation operator defined in the object class. It should be noted that the aggregation operator is determined on the fly by the digital twin requesting aggregation: see step 6.28.
-  Update of "aggregatedValue" attribute in the corresponding LSA property: see step 6.29.
This process is also represented in figure 6.30.
Aggregation on an object called nodeObject (learning model or prediction).:
Comment of algorithm: collect all values to be aggregated received from neighbours.
Comment of algorithm: add the value of the current node.
Comment of algorithm: application of aggregation and saves the result in the value of the current node.
\State ($lsa.property[nodeObject.property.name]).setAggregatedValue(result) $ update of the $aggregatedValue$ attribute in the LSA property containing the object.
6.2.1.2) Using polymorphism to make aggregation generic:
The new aggregation mechanism is capable on the one hand of aggregating any class of objects (e.g. apples, pears, or walnuts) and, on the other hand, of aggregating a class of objects in a different way (for example, by summing the weights, applying the maximum of the weights, or calculating an arithmetic average).
We thus use the polymorphism principle to define the aggregation behaviour for each "aggregatable" object: the aggregation method must be defined in the upper-level class which implements the $IAggregatable$ interface. The idea is to make the aggregation coordination law (defined in the coordination model middleware) independent of the $aggregate$ method applied to each object. This latter method is in the specific class of the objects to aggregate, with the possibility of defining different aggregation variants (one variant per operator value, to be defined in aggregate method). For example, an "aggregatable" class that aggregates a power value can define different aggregation operators: one that sums the power values, another that applies the maximum on power values, and another that applies the arithmetic means on power values.
Figure 6.31 illustrates the use of $IAggregatable$ interface with 4 specific classes that implement the aggregate method.
$NodeTotal$ class models the state of a node, containing the 6 power variables. $PredictionData$ class models predictions made at different times, with different horizons: it contains the predicted and actual states at the different horizons, as well as at each regular time between the initial date and the last horizon.
$MarkovChainsModel$ and $LstmModel$ classes model the contents of Markov Chains and LSTM learning models with all parameters. For Markov Chains, these are the transition matrices, while for LSTM, these are the different layers of the recurrent neural network, each layer containing 3 different weight matrices ($w$, $u$ and $b$).
These 4 classes are used in this contribution to integrate Federated Learning and Ensemble Learning. The two classes $MarkovChainsModel$ and $LstmModel$ model the structure of the two base learning models we have integrated: Markov Chains and LSTM.
The interface "IAggregatable" defined in the coordination middleware:
Figure 6.32 shows an example of aggregation applied independently to 3 properties of the same LSA belonging to the learning Digital Twin:
-  The "TOTAL" property, of class $NodeTotal$, includes aggregated variables at node level. The "SUM" aggregation operator defined in the NodeTotal class consists of summing each power variable by adding together all the values of the variable belonging to the nodes to be aggregated. This aggregation operator is used to calculate power variables at cluster level.
-  The "MODEL" property, of class $LstmModel$, contains the learning model used to predict a node variable. Aggregation is performed by applying a weighted average of the various LSTM models, using a weighting proportional to the number of samples in each LSTM model.
-  The "CL_MODEL" property, of class $MarkovChainsModel$, contains the learning model used to predict a variable at cluster level. Aggregation uses the "power LOSS" operator defined in the $MarkovChainsModel$ class: aggregation is performed by applying a weighted average of the different Markov-Chains models, using a weighting proportional to the model's performance evaluated with local data.
Figure 6.33 illustrates the aggregation mechanism applied on 3 property objects and shows that the 3 object aggregations are independent of each other: they do not apply to the same property and the same class, and they use aggregation operators that are specific to them. In this example, the objects are of different classes, but we could very well use two independent aggregations which apply to the same object class (for example $LstmModel$), but which don't use the same operator.
LSA properties used in the aggregators shown in figure 6.34.:
Aggregation of 3 different properties: TOTAL, MODEL (node model) and CL_MODEL (cluster model).:
6.2.2) Implementation of spreading mechanism:
In the previous version of the derivative SAPERE middleware, we have identified a regression in the spreading coordination law mechanism. The latter does not manage the sending of data to indirect neighbour nodes as a spreading execution ends at each coordination cycle.
The mechanism has been corrected to ensure indirect spreading by memorising LSA route in its properties: a node having received a message in the previous cycle repeats the sending of this same message to all the nodes which have not already received or sent this same LSA. The section 6.35 explains in detail how the spreading mechanism is implemented to date.
[DC1] It is worth noting that the objects aggregated and broadcasted are time-stamped, making it possible to assess the time taken by the Gossip mechanism to aggregate and distribute each object: this can highlight problems of network slowdown. We can find out the exact network distance of each object (from its originating node) and therefore compare its distance and propagation time. Section 6.36 describes the aggregation verification functionality. More generally, the available data can be used to detect that no objects from a certain node have been received for a certain period of time, which may be due to a network slowdown or the node being disconnected from the network. This detection is not automatic and would require a little additional development.
6.3) Using Gossip pattern for Gossip Federated Learning:
The generic aggregation mechanism therefore allows an aggregation to be applied to any class of objects, and to different properties of an LSA at the same time. In the context of Gossip Federated Learning, this will involve aggregating objects containing learning models (used for Federated Learning aggregation) and node state instances (used to aggregate the 6 power variables at the microgrid level).
6.3.1) Template of a generic learning model that can be aggregated:
We have modelled a common template (in the form of an abstract class and a generic interface) to define the common properties and services that must be included in any type of learning model implementation used by the learning Digital Twin. To date, we have implemented 2 types of models which are Markov Chains [118] and LSTM [119], but this architecture will allow tomorrow to integrate other types of models, by implementing the methods required in the common template. A concrete model will notably have to implement the train process and prediction of each power variable (including produced, requested, consumed, provided, missing, available). A model is structured into several sub-models, each of which is associated with one of the 6 power variables to predict. In the following, we use the term "sub-model" to designate the sub-part of the model dedicated to the prediction of a single variable. In each model implementation, the parameters of each sub-model are well separated.
Table 6.37 and table 6.38 list the main properties and services implemented in a 'concrete' learning model:
Main properties of a learning model instance.:
Main services implemented by a learning model instance.:
6.3.2) Definition of several operators for learning model aggregation:
Figure 6.39 shows a view of the aggregation mechanism applied to one property. The aggregation method follows the common parameter signature shown: the learning model's instances to aggregate corresponds to the $obj_1$, $obj_2$, $obj_n$ objects in this diagram and the aggregation method is executed in $obj_1$ instance (the local model). The result of the aggregation, $obj_aggr$, is then stored in $LSA_1$, which is the LSA containing the local model.
A learning model class is defined in the service layer and extends the abstract learning model class ($AbstractLearningModel$, which is also defined in the service layer). The result of the aggregation is then stored in $LSA1$, which is the LSA of the local node.
As represented in figure 6.40, a model aggregation takes place in two stages:
-  First, for each power variable, we extract the associated sub-model and assign it coefficients (or otherwise called weights) according to the aggregation operator. A coefficient assigned to a model from one node defines the pertinence of the model in relation to models from other nodes. Each operator corresponds to a different approach and therefore to a different way of assigning weighted coefficients. The obtained coefficients are then stored in the attribute $aggregationWeights$ of an abstract learning model, defined previously in sub-section 6.41.
-  Secondly, for each sub-model, we apply the linear combination based on the coefficients previously assigned to the entire model structure. This combination is applied to each sub-model, and each sub-model then applies this combination recursively to the data clusters: layer by layer, matrix by matrix or vector by vector, depending on how layers are structured.
The first step (i.e. assigning sub-model weights) is implemented in the abstract learning model class, as this latter class contains enough common information and services to handle the various weight calculations within this class. This has the advantage, on the one hand of preserving a certain level of generalisation in the aggregation code and, on the other, of saving aggregation programming when implementing a new learning model.
aggregation of a learning model in two steps:
The second step, which consists of applying a linear combination, is specific to each type of learning model. This is because each sub-part of the data structure of a learning model is specific to each type of model and requires adaptation when calculating a linear combination. It should be noted that, from an algorithmic point of view, this second step is relatively straightforward, as it simply applies linear combinations to objects formed from matrices, vectors of decimal numbers.
In what follows, we specifically describe each coefficient evaluation of each aggregation operator. Each of them is therefore treated in a "sub-block" following one of the 4 different approaches represented in figure 6.42. Each sub-block calls a sub-method which implements the corresponding aggregation operator in the abstract class of learning models. When the time comes to implement a new aggregation approach, a new operator will be added to this class.
For all the aggregation operators described in this section, we consider the common variables used for the calculation, which are listed in table 6.43:
Common variables used in aggregation operators.:
6.3.2.1) Quantitative approach ("sampling_nb"):
The principle is to assign a model a weight proportional to the number of samples it contains in the training data set. The underlying idea is that a model containing more samples in the training data should be more accurate. Compared to other aggregation operators, this one is relatively simple as it requires very little calculation, nor evaluation to be done in real time. This approach which is purely quantitative may be considered as a "raw foundry" aggregation because it does not take into account the fact that a neighbouring node can have (or not) similar behaviours. As a result, this approach does not consider the relevance of the model in the aggregation. Equation 6.44 shows the calculation of this coefficient based on the dataset size.

6.3.2.2) Approach based on model loss ("power_loss"):
The principle is to evaluate in real time the degree of similarity between the prediction of a node learning model and the actual values contained in a validation dataset.
To apply this approach, we evaluate each model received from neighbouring nodes separately (as well as the local model). First, the local node generates predictions using each of them and using the local test dataset (found in the model instance as described above).
The results of each prediction are then compared with the states observed, which are contained in this dataset. The cross-entropy distance called "loss" is then calculated between the predicted states and the observed states. This "loss" calculation is performed for each model, and the model coefficient assignment applies a decreasing exponential to this calculated loss, as shown in equation 6.45. In this way, the better a model performs, the smaller the loss and the greater its weight.
Equation 6.46 shows the loss computation which applies a cross-entropy calculation taking the following two vectors as inputs. The first input, represented by mathpredictions_imath, corresponds to the classes predicted by mathmodel_imath and the second input, represented by mathtestdataset_N.true_classes()math, corresponds to the true class extracted from the local node's test dataset.
The cross-entropy of two vectors p and q of the same size is calculated as follows:
center
math
cross\sumx\in p.indexes
 p(x) * log(q(x))
math
center
Equation 6.47 shows the prediction calculations performed by the evaluated model (mathmodel_imath), using the local node's test dataset (mathtestdataset_Nmath). This results in the output vector mathpredictions_imath.
Equation 6.48 shows the calculation of the index that minimises the cross-entropy between the predictions computed by mathmodel_imath and the true classes extracted from the test dataset. The cross-entropy resulting from each instance of mathmodel_imath is calculated in the same way as for the 'power_loss' variant (see equation 6.49).
6.3.2.3) Approach based on the power profile similarities:
We define "power profile" as the history of power values contained in the data set for the considered variable. This approach focuses on the similarity of the different states taken by the variable to be predicted. It assumes that a model from a node which contains a more similar power profile should provide a more accurate model irrespective of the actual performance that this model could bring to local node data. From an algorithmic point of view, this approach requires less computation and time, because it only requires comparing recent state histories (contained in the learning model) and does not require evaluating models in real time.
This distance calculation is performed for each node profile, and the model coefficient assignment applies a decreasing exponential to this calculated distance, as shown in equation 6.50. Thus, the more similar the profile of a neighbour node, the smaller the distance and the greater its weight.
Equation 6.51 shows the calculation of the profile distance (mathDIST_i,jmath) between two nodes (i and j): this is the average of the differences in power values between mathnode_imath and mathnode_jmath obtained for each instant with a corresponding power value in the dataset of mathnode_imath and mathnode_jmath.
In equation 6.52, we can see that the set of time indexes mathtimei,jmath corresponds to the intersection of the indexes of mathdataset_imath and mathdataset_jmath. It contains all the indexes for which the power values are present in both datasets. This set is used in equation 6.53 to collect power values in the calculation of the profile distance mathDIST_i,jmath between mathnode_imath and mathnode_jmath.
6.3.2.4) Possible improvements for aggregators:
We have already implemented and tested 4 different aggregation operators applied to learning models, but it is always possible to develop a new operator that is better adapted to the situation and therefore improves the accuracy obtained: the implementation of the generic aggregation mechanism makes it easy to integrate a new operator, which is an advantage. However, the current implementation assigns the same aggregator to all 6 variables and does not allow a different aggregator to be assigned depending on the variable. For example, a given aggregation operator may be effective for consumption but much less so for production, and the ability to choose the most appropriate aggregator for each variable would further improve overall accuracy.
6.3.3) Adaptations made to reduce the bandwidth used:
During our experiments, we observed that spreading of learning model objects between nodes uses up a lot of bandwidth.
On the one hand, each object separately uses a lot of memory (such as a learning model object, which has a complex structure and a large volume of data) and, on the other hand, the aggregation and spreading mechanisms that work together tend to multiply the number of objects sent between nodes, even if not all nodes directly receive data from all their neighbours. This number tends to grow polynomially as the number of nodes and links increases.
As a result, this large flow of data can quickly lead to bandwidth overload, and in some cases, we have observed delays in data reception due to spreading, which are detrimental to energy exchange, among other things.
For example, when an energy offer is received by a consumer after the deadline, the offer expires before it can be used. To solve this issue, we tried both to reduce the frequency of model exchange and to compact the model data before spreading. The following two subsections explain these two adaptations in detail. To overcome this problem, we have made the following adaptations: some affect the spreading frequency while others reduce the size of sent objects.
6.3.3.1) Adapting the spreading frequency of learning models:
To reduce the volume of data exchanged, we first tried to reduce the spreading frequency of learning models, by ceasing to submit its content to the LSA (for spreading) when this is not necessary.
The idea is to set the frequency of gossip in the launch parameters of the coordination platform: this parameter is added to the aggregation configuration for each of the learning models (the one applied to the node state prediction and the one applied to the cluster state prediction). This parameter indicates the minimum number of minutes between two aggregations. After each aggregation, a node will block the dissemination of its learning model by simply removing the property concerned from its LSA. It will wait until the last model update date is later than the last aggregation date + $N$ minutes ($N$ being the value of the minimum waiting time parameter between 2 aggregations). It should be noted that not only is it not necessary to apply spreading when the model is not updated, but the optimum prediction accuracy is not necessarily obtained when the aggregation frequency is at its maximum. We could go even further in this direction, by preventing aggregation as long as there is no significant cumulative change in the local model since the last aggregation, compared to the modifications caused by this last aggregation.
6.3.3.2) Synchronisation of spreading start-ups:
At this point, a node will not submit its model immediately, as the other nodes may not yet be ready to send their model: the idea is to ensure that all the other nodes are also ready to activate aggregation. This synchronisation of spreading avoids sending unnecessary voluminous data. At this stage, the node will indicate to the others that it is ready, by submitting the indicator in its "MODEL_READY" LSA property. Aggregation with the sum operator is applied to this property, so that all nodes can know the exact number of nodes ready to propagate their model. One node can then send its model as soon as all neighbouring nodes are ready (e.g. when the number of ready nodes is equal to the nodes number). This confirmation will reach all the nodes at approximately the same time, to within a few seconds, depending on the distance between the nodes in terms of minimal number of links.
6.3.3.3) Using a compression mechanism to reduce the size of objects exchanged:
Another focus we are working on to reduce bandwidth is the use of a more "compact" class to exchange learning model weights between nodes. This latter class uses a much simpler and more elementary structure, to use less memory in the spreading process once the object is serialised.
This compacted class of a model contains the entire hierarchy of weight matrices in "flattened" form: it includes a hash table whose keys identify each matrix, and each value contains the compressed contents of the matrix in the form of a buffer. The compacted class is used only for data exchange between nodes and cannot be directly aggregated. The principle is to be able to compact or de-compact the contents of such an object at any time.
Figure 6.54 shows the aggregation mechanism applied to a set of compacted models: in a first step, each model received is decompressed (as the compressed form cannot be directly aggregated) and in a second step, the aggregation is performed on the "complete" models. Conversely, before the learning Digital Twin submits its learning model to its LSA, it calls on the compression operator (converting the complete form to the compressed form).
Aggregation of compacted learning models. This operation is carried out in three stages: 1: unpacking the compacted models received, 2: aggregating the "complete" models, 3: compacting the aggregated model.:
6.3.3.4) Synthesis:
Table 6.55 summarises the different adaptations achieved to reduce bandwidth. The 'Usages' column shows that 2 of these adaptations (synchronisation of spreading and object compression) are only applied on learning models: in fact, learning model objects tend to use more bandwidth than prediction objects.
Adaptations used to reduce bandwidth. The 'Usages' column indicates the types of objects to which these adaptations apply.:
During the experiments, we found that these three adaptations enabled us to overcome the difficulties associated with the physical limitations of the data network. To achieve this, we had to find a good compromise between the sending frequency and the stability of the communication between the nodes.
The compression mechanism requires more processing as it requires two object conversions: compression when sending to the tuple space and decompression when recovering from tuple space. For this reason, we only use it, when necessary, i.e. for learning models.
We could reduce further frequency of aggregation, by checking that there is significant cumulative change in the local model since the last aggregation, compared to the modifications caused by this previous aggregation.
6.3.4) Evaluation of Gossip Federated Learning:
6.3.4.1) Prediction assessment method:
To assess the impact of the gossip mechanism on the quality of predictions, we run the coordination model with the "living-lab" scenario which corresponds to actual household production and consumption measured in the "Les Vergers" eco-district located near Geneva. The principle of this evaluation is to compare the predicted state at $t1$ with the actual state of the node at the prediction target time ($t2$ = $t1$ + prediction horizon).
The learning Digital Twin launches the prediction calculations and stores the results in the database. Each prediction record also includes the actual state at the horizon, which is completed a posteriori by the learning twin after horizon time ($t2$): this state corresponds to the state observed at the time of the horizon ($t2$).
We carried out comparative tests over the same time slot between 9 am and 1 pm on the same day, so that the different variants were tested with the same level of difficulty. At this time of day, the difficulty of prediction is medium: there is a certain amount of solar energy production, with some volatility, but this is not as great as in the afternoon. For the network configuration, we used chained network topologies with 2 and 4 nodes to limit traffic between nodes. We also compare each aggregation operator, as well as the version without aggregation, which corresponds to local learning (in this case, the aggregator is designated 'None' in the results tables).
We have integrated the Markov Chains and LSTM models, which operate very differently. The Markov Chains model was integrated first as it is relatively easy and quick to implement. This stochastic model uses transition matrices (one per hour) to define the transition probabilities of all possible states. It is suitable for time series that fluctuate over time, thanks to the use of a sliding window (set to 100 days). The LSTM model was added later: it appears to be a good alternative to the Markov Chains model. In fact, LSTM, which belongs to the family of recurrent neural networks, can memorise both short-term and longer-term behaviour: it is known to provide excellent performances for learning electrical power time series. The LSTM instances we have integrated use one epoch, with a batch size of 32 and a learning rate of $10^-3$ for the first training and $10^-4$ for subsequent training sessions - which are iterative.
6.3.4.2) Description of the experiment:
The principle of the experiment is to simulate energy exchanges between prosumer digital twins, based on a real power history that corresponds to the power values collected in the 'Les Vergers' living lab. The dataset used corresponds to the electrical power data collected by the smart meters in 'Les Vergers' since May 2022. The start date of the scenario is chosen arbitrarily as a fictitious date that must fall within the range of the data collected (between 1 May 2022 and today: for example, 15 January 2023 in the experiment).
We use a cluster of 4 nodes with a 'chained graph' topology (shown in figure 6.56), where a node corresponds to a building in the living lab's eco-district. At start-up, the dataset is initialised with the power values collected in the living lab, and then the coordination platform simulates the energy exchanges between the prosumer twins. The 6 power variables attached to each node vary according to the new energy supplies generated by prosumer twins (and the same applies to the 6 variables attached to the cluster level). These new samples of power values are added to the model datasets every minute and the learning models are re-trained (depending on the frequency chosen for the learning model type), taking these new samples into account. Table 6.57 shows the different parameters defined for each type of learning model: Markov Chains and LSTM.
Parameters set for each classifier used.:
Initial start-up training
For the first training of the learning models, each node coordination platform retrieves the data from the living lab dataset over the few days (generally 7) preceding the fictitious starting date-time and that correspond to its assigned node. Given that the values are collected every minute by the smart meters at each location, this gives 1,440 records per day, per node and per variable, or more than 60,000 records for a week and one node. This data is then transmitted to the learning models. The time taken for initial learning varies greatly depending on the learning model used: a few seconds for Markov Chains model or more than one minute for LSTM (for all 6 variables in one node). This learning process can be carried out in parallel for each node.
Incremental training
The coordination platforms then iteratively re-train their model at regular intervals to take account of new observations. LSTM models are much more computationally intensive: as a result, they are re-trained less frequently (i.e. every 20 minutes) than Markov models, which are re-trained every time new data is received (i.e. every minute). We have assigned gossip frequencies that are less than or equal to the re-training frequencies: every 5 minutes for Markov Chains and every 20 minutes for LSTM. A higher frequency would run the risk of sending the same version of a model more than once, which would use up bandwidth unnecessarily. In this study, we have not yet explored the impact of reducing drastically this frequency on the accuracies obtained by the models.
6.3.4.3) Accuracies obtained:
Table 6.58 displays the obtained averages of accuracy, using Markov Chains models and LSTM models, and broken down by aggregator and by prediction perimeter (node/cluster). In addition, we have identified the 'non-trivial' prediction periods for which the horizon falls within a period of higher volatility, and therefore an increase in the entropy of the state variables (which increases the difficulty of prediction). In the results, we have recalculated the predictions obtained by extracting only the 'non-trivial' predictions (see the 'Reliability Non-Trivial' columns).
Accuracy results, broken down by aggregator and by prediction perimeter. The 'CLUSTER' and 'NODE' lines correspond to the averages obtained for each prediction perimeter and the 'TOTAL' line corresponds to the overall averages obtained for all predictions. The left half of the table shows the accuracies obtained using the Markov Chains model, while the right half shows the predictions obtained using the LSTM model. Accuracies are also calculated based on non-trivial predictions.:
6.3.4.4) Node state predictions:
Figure 6.59 and 6.60 shows the accuracies obtained in the form of histograms, only for the prediction applied to the local node perimeter and for each model separately (Markov Chains/LSTM).
Accuracies of node predictions obtained using the Markov Chains model, for each aggregator.:
Using the Markov Chains model
With the Markov Chains model, the accuracies obtained ranged from 78 % to 88 %, with an average of 83.5 %. The 'min_loss' aggregator tends to outperform the other aggregators as well as local learning, while the 'sampling_nb' aggregator tends to underperform local learning.
Given that the difference in accuracy obtained between 'min_loss' and sampling_nb is greater than 10 %, these results highlight the importance of the choice of aggregation operator used. This also confirms the idea that the 'sampling_nb' aggregator only considers the quantitative aspect of a model (since it is based on the size of its dataset) whereas the 'min_loss' aggregator considers the real-time performance of models on a local dataset. The 'power_loss' aggregator, which is also based on model performance, outperforms local learning, but to a lesser extent. In this experiment, selecting a single high-performance model rather than combining several proved to be more efficient. It should be noted that increasing accuracy comes at a cost in terms of CPU and memory usage, as the 'min_loss' and 'power_loss' aggregators are very computationally intensive (each model received is re-evaluated at each aggregation).
For non-trivial predictions, we can observe a significant decrease in accuracy. In node-level predictions, the proportion of trivial predictions is high (close to 50 %) and, given that entropy increases considerably in these non-trivial prediction ranges, this tends to drastically reduce the accuracy obtained.
Using the LSTM model
With the LSTM model, accuracies obtained are between 93 % and 96 %, around the average of 94.78 %. In general, we observe significantly better performance, including for local prediction, which 'unanimously' confirms the effectiveness of the LSTM model compared with Markov Chains for node state predictions. This confirms the fact that LSTM is often cited as one of the most suitable models for predicting behaviour that can fluctuate significantly over time, such as electricity production. Its ability to take into account both short-term and longer-term behavioural memory may explain this efficiency.
Furthermore, we note that the relative performance rankings of each aggregator have been turned upside down: only the 'dist_power_hist' aggregator, which is based on node history similarity, outperforms local learning. It is also worth noting that the accuracies obtained are less disparate than those obtained with Markov Chains.
We also note that most aggregators reduce accuracy: this can be explained by differences in behaviour between nodes (for example, some nodes have no producers while others produce energy). When aggregating models, a model from a neighbour with quite different behaviour is of little relevance. This also explains why the 'dist_power_hist' aggregator, which is based precisely on the similarity of historical behaviours, tends to outperform the others.
Accuracies of node predictions obtained by the LSTM model, for each aggregator used. Averages obtained for each model appear as dashed lines.:
6.3.4.5) Cluster state predictions:
Figure 6.61 displays the histograms of accuracy obtained with predictions applied to the cluster perimeter. It should be noted that all cluster predictions are non-trivial. This can be explained by the fact that the cluster state, which aggregates all the node's states, tends to be more volatile than the most stable node's states (these are generally nodes with zero production since they have no attached producers).
We observe a significant difference between the two models (on average, LSTM outperforms Markov Chains by +13 % in accuracy). We can see that local learning has the lowest accuracy: all aggregators thus tend to increase the accuracy performance. This can easily be explained by the similarity of the behaviour to be predicted between each node: in fact, as each node tries to predict the state of the cluster which is common to all nodes (each belonging to the same cluster). All the nodes therefore predict the same behaviour, even though each node has a different sample of data. For both models (Markov Chains and LSTM), the aggregators show very little difference between them. The aggregator 'min_loss' slightly exceeds "dist_power_hist" with the LSTM model and vice versa with the Markov Chains model. Given that they provide equivalent accuracy, we tend to prefer the "dist_power_hist" aggregator, which requires much less calculation than "min_loss".
Accuracies of cluster predictions obtained by the two models (Markov Chains and LSTM) and for each aggregator used. Averages obtained for each model appear as dashed lines.:
6.3.4.6) The lessons to be learned:
First, we observed a significant difference in accuracy between the Markov Chains and LSTM classifiers, independent of the use of the gossip mechanism. Figure 6.62 shows this very clearly. However, this very significant accuracy gain brought by LSTM is not free, in the sense that LSTM consumes much more memory and computing time and requires more effort in terms of integration to be able to be called by the digital learning twins running in the coordination platform (see table 6.63).
Comparison of Markov chains and LSTM. (*): The last column shows the possibilities of reducing consumption in terms of resources and computation by adjusting the training frequency.:
In other respects, these results show that the relative performance of an aggregator fluctuates greatly depending on the learning model used, the model hyper-parameters, the prediction perimeter and other parameters linked to the experiment context. This confirms the need to carefully test and compare the impact of each aggregator on accuracy when implementing a new model or modifying the perimeter or certain hyper-parameters. Depending on the situation and the model used, gossip does not bring systematic gains, but the choice of an appropriate aggregator is decisive in improving accuracy. For example, changing the learning model or extending the prediction perimeter to the entire cluster rather than just the local node tends to upset the relative performance of each aggregator. In all the test cases, at least one of the aggregators implemented outperformed local learning and depending on the situation, the benefits of the most appropriate aggregator may be considerable.
In more general terms, we have observed that the gain from gossip is more systemic when the nodes are trying to predict similar behaviour (i.e. behaviour at cluster level in the context of this study). This confirms the added value of the gossip mechanism in such a case. Furthermore, the relative gains linked to gossip are greater overall for LSTM than for Markov Chains: the gossip mechanism barely compensates for the difficulties encountered by the Markov Chains model and further accentuates the relative performance of LSTM. Choosing the right model and the right aggregator is therefore doubly beneficial.
6.4) Using Gossip pattern for Decentralised Ensemble Learning:
In section 6.64, we presented the use of the gossip mechanism provided by the coordination model to implement the Gossip Federated Learning approach. In a similar way, this section describes the use of the gossip mechanism to implement the Gossip Ensemble Learning approach.
6.4.1) Implementation of aggregation on prediction data:
The Ensemble learning approach, as defined in 6.65 consists in aggregating the predictions received from a set of nodes. Given the uniqueness of the class modelling predictions (as opposed to the classes modelling learning models) and the relatively basic structure of a prediction result, the aggregation implementation is simplified. In addition, a prediction object is much smaller than that of a learning model, so there's no need to implement a data compression (and decompression) mechanism to send it to the tuple space.
6.4.1.1) Structure of predictions:
The structure is defined in $PredictionData$ class, which includes a mapping table containing one prediction result (modelled by the $PredictionResult$ class) for each horizon instant and for each variable name (these are the 6 variables which characterise the power state). Each prediction result contains the starting state and the list of transition probabilities to the different possible states (in the form of a list of real numbers). The aggregation of a prediction then amounts to applying this aggregation to each prediction result contained (in a $PredictionResult$ instance) for each horizon date and each variable. Like the instances of the learning models, a prediction instance also contains the recent history of the node's state: this data is used by the aggregator based on similarities in power profiles.
6.4.1.2) Definition of several operators for prediction aggregation:
In the same way as for a learning model aggregation, the aggregation method of a prediction follows the parameter signature shown in figure 6.66.
As represented in figure 6.67, a prediction aggregation also takes place in two stages:
-  First, for each power variable, we extract the associated prediction results and assign a coefficient (or otherwise called weights) to each variable according to the aggregation operator. A coefficient assigned to a prediction result from one node defines the pertinence of the prediction result in relation to the prediction results from other nodes.
-  Secondly, for each prediction result, we apply the linear combination based on the coefficients previously assigned to the entire prediction structure. This combination is applied to each prediction result, which amounts to applying this linear combination to the probability vectors (which are stored in the form of an array of real numbers).
aggregation of a prediction: 

In what follows, we specifically describe each coefficient evaluation of each aggregation operator. Each of them is therefore treated in a "sub-block" following one of the 3 different approaches represented in figure 6.68. The quantitative and 'power profile' approaches are already used in Gossip Federated Learning: they are explained in section 6.69. Regarding the quantitative approach, we should note that the dataset size comes from the model that generated the prediction: this information is simply copied into the prediction result when generated. The 'last power' approach is quite close to the 'power profile' approach: the underlying idea is that a prediction from a node which contains a more similar power value should be more accurate. This approach assumes that the last power value is more relevant to represent a node profile, which implies that it is not necessary to go through the history of the node's states. Unlike the approach based on the power profile, the distance between two nodes only considers the most recent power state (i.e. the last recorded).
6.4.2) Evaluation of Gossip Ensemble Learning:
In the same way as for the evaluation of Gossip Federated Learning, we used the "living-lab" scenario, in the same time slot between 9 a.m. and 1 p.m. and using a chain network topology with 2 and 4 nodes. The cluster of nodes uses different types of learning models to reproduce a relevant case study of Ensemble Learning: half of the nodes use the Markov Chains model, while the other half use the LSTM model.
Accuracy results, broken down by aggregator and by prediction perimeter obtained, using the Ensemble Learning approach. The 'CLUSTER' and 'NODE' lines correspond to the averages obtained for each prediction perimeter and the 'TOTAL' line corresponds to the overall averages obtained for all predictions. Accuracies are also calculated based on non-trivial predictions.:
6.4.2.1) Comparison with the Gossip Federated Learning approach:
Figure 6.70 depicts the different results obtained with the Ensemble Learning approach for cluster predictions (in orange), which is compared to the Gossip Federated Learning's approach (GFDL) applied with the Markov Chains model and with the LSTM model. The Ensemble Learning approach did not allow us to implement as many aggregators, so there are 2 of them: 'sampling_nb' and 'dist_power_hist', which are compared with the "local learning" version, which uses no aggregator.
The average obtained for Ensemble Learning is 86.26 %, which is significantly higher than that obtained for GFDL with the Markov Chains model, but slightly lower than that obtained for GFDL with LSTM. The same cannot be said for the predictions of the node perimeter (see figure 6.71), for which the average obtained (around 85 %) barely exceeds that of GFDL with Markov Chains and is far below that of GFDL with LSTM.
Comparison of accuracies obtained on cluster's level predictions for (1): each approach (GEL, GFDL with Markov Chains model, and GFDL with LSTM model) and (2): each aggregator used in both approaches GEL and GFDL ('sampling_nb', 'dist_power_hist', and no aggregator). Averages obtained for each approach appear as dashed lines.:
Same comparisons obtained on node's level predictions: by approach (GEL, GFDL with MC, GFDL with LSTM) and by aggregator. Averages obtained for each approach appear as dashed lines.:
The accuracies of node level predictions displayed on figure 6.72 confirm that the Ensemble Learning approach performs less well when each node tries to predict more heterogeneous behaviours, which is the case for node perimeter predictions. This drop is mainly due to the poor results (around 65 %) obtained by the 'sampling_nb' aggregator, which is based on the size of the training data sets. This is because some variables, such as the power produced, are hugely different from one node to another: it therefore makes no sense to aggregate their predictions according to the dataset sizes. The negative impact of this aggregator is even more direct and significant than for the GFDL approach, which consists of aggregating the model weights instead of aggregating the prediction results. Aggregating a prediction result has a more direct impact on accuracy. We can see that the impact is so great that even non-trivial predictions, which are less affected by these differences in behaviour between nodes, obtain better results.
6.4.2.2) Comparing the performance of each aggregator:
Figure 6.73 depicts the comparison of each aggregator used in Ensemble Learning's approach.
Accuracies obtained on cluster's level predictions with Ensemble Learning (Markov Chains and LSTM) and for each aggregator used.
We observed that for cluster perimeter predictions, the 3 aggregators clearly tend to improve the accuracy obtained, which is not the case for node perimeter predictions where only the 'dist_power_last' aggregator performs slightly better than local learning. In a similar way to Federated Learning, this can be explained by the increased relevance of knowledge sharing when the different nodes are led to predict the same behaviour. The two aggregators 'dist_power_hist' and 'dist_power_last' are based on electrical states similarities, but the first calculates this difference by averaging over the recent history, whereas the second is based solely on the last recorded state. We might expect the first one to perform better, but the results confirm that the one based on the latest state performs slightly better. This may reflect an important level of volatility in the state variables, making recent states more relevant than others. As we have just seen in section 6.74, the 'sampling_nb' aggregator, which is based on the size of the training dataset, is less effective than the other two. However, this difference is lower for the 'cluster' perimeter, as it involves predicting identical behaviour, which is less the case for the 'node' perimeter.
In more general terms, these results confirm that the Gossip Ensemble Learning approach is a good alternative to Gossip Federated Learning in that it provides comparable (or almost comparable) accuracy while offering greater integration flexibility and reducing the use of computing resources and bandwidth. Using this approach brings more gains for cluster-level predictions, which all relate to identical behaviour.
Chapter 7) Social acceptance by design:
In this chapter, we discuss how social acceptance is taken into account in the modelling and implementation of digital twins interacting via the coordination platform. In general, consideration of the social acceptance criteria defined by potential users is essential to give a project based on AI and digital technologies a serious chance of success. Studies have shown that the absence of this social dimension has led to many project abandonments. In addition to this, microgrid applications are based on the Customer-to-Customer (C2C) model, which means that users have a role to play as producers as well as consumers (and therefore that of prosumer). Moreover, a microgrid organisation requires to share and distribute resources within the same community which means that several rules need to be put in place to ensure that the community runs smoothly and that there is mutual respect among stockholders. Given the importance of the social dimension, we have integrated a number of these aspects into the algorithms that are integrated into a Digital Twin's behaviours. This integration is based on the work carried out by the university of HES-SO Valais, which defines user-centred approaches to design a microgrid community combining social aspects and AI technology. The analysis is based on theories, mathematical models, and social surveys of potential microgrid users [120].
7.1) Context of the contribution: study to improve the social acceptability of microgrids:
As part of the Lasagne project, the HES-SO Valais conducted qualitative surveys using focus groups and semi-structured interviews with potential users of microgrids and partners involved in microgrid projects: the results of the interviews highlighted the various characteristics of microgrids that emerge from the perceptions of the people interviewed, whether in technical, economic, logistical, organisational or relational terms.
This study drew attention to the fact that the successful operation of a microgrid is not simply a question of deploying infrastructure and technologies but depends above all on considering the social and economic context and the perception of potential users, their wishes but also their constraints and fears. The negative perceptions are the restraining forces that considerably slow down a microgrid project. Indeed, it is essential to take better account of these restraining forces if the project is to have a chance of succeeding, even if all the technical conditions are in place and some of the participants are already actively involved in the project.
This study has also highlighted the salient attributes of microgrids, which was subsequently used to build profile maps that can be allocated to a community of microgrids [121].
We define the salient attributes as the main characteristics perceived by the users (or potential users) of a microgrid as a sold and installed product with technical features, but also as an organisation which requires the implementation of logistics and good cooperation between the members who share the microgrid. Krech and Crutchfield [122] used the term of salience in the field of social psychology to describe a person's beliefs and attitudes: a salient belief or attitude is distinguished by its importance in the cognitive field and enters more easily into thought.
With regard to the study of microgrid communities, Fragnière et al. [123] have identified salient technical attributes, such as the robustness of the infrastructure, the presence of emergency plans, energy storage, help for new arrivals, but also salient mental attributes, such as team spirit, shared values and the involvement of participants (such as energy sobriety or the development of renewable energies), and the identification of participants with these values. Several profile maps have been drawn up from a combination of dozens of attributes, grouped around 4 main categories: the energy network (e.g. the choice of whether to be connected to the power grid, whether to mix with non-renewable energy), infrastructure management (internal or external), data management (e.g. data sharing, anonymous comparison of consumption) and organisation (e.g. frequency of meetings, self-regulation).
Meetings with HES-SO Valais enabled us to orientate the adaptations that could be implemented in terms of the behaviour of digital twins to integrate some of these identified characteristics that emerge from this study. In this contribution, we thus propose to integrate some of them, by adapting the behaviour of the digital twins accordingly. The aim of the contribution is not to fix a particular behaviour for a particular microgrid instance but to show that we can adapt some Digital Twins' behaviours according to a chosen context of a microgrid. Characteristic requirements vary from one microgrid' profile to another: the main idea is to be able to adapt these behaviours according to the choice made by a microgrid community. We test how well a feature is taken into account by the digital twins using a fictitious simulation scenario.
In the following paragraphs, we describe the aspects of the social dimension that we include in the Digital Twins' algorithms, such as protection of personal data, prevention of energy shortages, prevention of abusive behaviour, and integration of salient attributes specific to a microgrid community. In designing these algorithms, we also consider a certain flexibility in the Digital Twins' parameters, so that a prosumer or a community can customise its own preferences.
7.2) Protection of personal data:
To meet social acceptance criteria, we apply confidentiality rules to the data exchanged in the tuple space: personal information about a Digital Twin cannot be visible to its peers. For example, the different supplies made by a producer number A are not visible from another producer number B.
These confidentiality rules apply to the various data exchanged such as requests, offers, contracts or producer confirmations: they consist in protecting each data submitted through a LSA individually. Access to "personal" properties is only permitted for the concerned Digital Twins.
We use the notion of "wrapper" to protect access to sensitive objects (see figure 7.1). We therefore declare the sensitive object as a private attribute in a wrapper class which contains it, and which only manages access. More precisely, access is managed in a method of type "accessor" from the wrapper class, which requires the authentication of the requesting Digital Twin as a parameter.
In this way, the access method checks whether the Digital Twin has correctly authenticated to the microgrid and, if so, it determines the extent of visibility the Digital Twin has on the requested data.
The method restricts the data to return, according to the obtained visibility and it sends a security exception if the Digital Twin has no access rights to the data.
Protection of a "sensitive" object located in a LSA property:
As an example of application, figure 7.2 shows the visibility of an electricity supply contract between consumer number 1 and providers number 2 and 3 (which supply consumer 1).
We can see that:
-  all prosumers not included in the contract stakeholders have no access to the contract data (this is the case for consumers number 2 and 3, as well as producer number 1)
-  consumer number 1, as the contract owner, has full access (it has full visibility of the 2 supplies it receives)
-  the two suppliers (number 2 and 3) have partial access: they only see the partial supply that concerns them. Each producer does not have access to the supply data of the other producers involved in the same contract.
visibility of prosumer Digital Twins on an electricity supply contract (approximation of consumer 1 by producer 2 and producer 3):
7.3) Tragedy of the common:
The "tragedy of the commons" scenario corresponds to the case where the best individual decision for a given Digital Twin turns out to be the worst-case scenario for them as a group [124]. This is a classic scenario which causes a shortage of electricity on a microgrid scale. We therefore propose to study this scenario with the aim of highlighting such a risk and providing a solution through an alternative scenario. As an example, let's consider the charging of electric vehicles (EV) at night when energy prices are less expensive, for instance between 11 pm and 5 am. Individually, it is a good policy to start charging the EV from 11 pm onward. However, if everybody in a neighbourhood takes this same decision, this leads to a peak of energy consumption at 11 pm.
7.3.1) Situation scenario:
To experiment with such a scenario, we have defined a policy that encourages all Digital Twins to request electricity at the same time slot. In this way, we test the resilience of the Digital Twins by straining the available electricity resources. As an example, we have defined a pricing table with a minimum price set at the current time plus 1 minute, which encourages all Digital Twins to request a supply during the time window corresponding to the cheapest price (see the red box in figure 7.3). In our simulation, there are 10 consumers and a single producer, which can supply only 3 Digital Twins at the same time. As a result, 7 demands for electricity will remain unmet (see figure 7.4).
Rates of electricity in kWh set by a producer. This staggered tariff is non-dynamic and identical for all consumers. It therefore encourages consumers to choose the same moment (t = 1 minute) when the energy rate is most attractive. The simulation of this tariff grid has made it possible to reproduce the scenario of the tragedy of the commons.:
10 demands at the same time (10 x 10 Watts): the producer can meet only 3/10 of them.:
7.3.2) Alternative scenario based on dynamic pricing:
To address this supply gap, a first alternative is to modify the pricing policy to consider the real-time demand. To do so, we have defined a price escalation factor that is a function of the remaining availability of the producer in watts (see figure 7.5). If the producer's availability decreases, the price increases in real time and the unserved consumers will then review their demand time slot. In this way, we can spread the demand of different consumers over time.
Increase factor depending on the producer's remaining capacity. This factor makes pricing dynamic, considering the current increase in demand. The resulting rating encourages unserved consumers to defer their energy requests.:
Figure 7.6 shows the process used to iteratively distribute energy demands over time using a dynamic pricing which favours the least popular periods. A new iteration is carried out when there are unfulfilled requests at the current time. At each iteration, the Digital Twins perform the following operations:
-  Each producer supplies requests according to its capacity. This reduces its available capacity to zero if the overall capacity is not sufficient to meet all requests.
-  Each producer applies dynamic pricing by recalculating all slot tariffs based on updated availability.
-  Each dissatisfied consumer updates the tariff table and revises the time slot of its request according to the new tariffs (it must target the period corresponding to the lowest price).
Using dynamic pricing to spread energy demand over time.:
7.3.3) Results:
As shown in figure 7.7, when applying this indexed pricing policy to the previous example, the 7 unsatisfied Digital Twins then defer their requests to the next time slot. Of the remaining 7 requests, only 3 will become satisfied in the second slot, and similarly the 4 remaining unfulfilled Digital Twins will defer their requests to the next slot. Thus, the next 3 requests will become satisfied in the third time slot, and the last one will become satisfied in the fourth time slot.
Historical view of the alternative scenario: staggered requests over time.:
We should note that, at present, Digital Twins are not yet able to reduce the power demand when the overall supply is insufficient at time $t$. This last solution would be preferable to cater for all Digital Twins in a more equitable manner.
7.4) Tracking of "free riding" behaviours:
For a microgrid community to function, the various prosumers are supposed to share energy resources and therefore contribute to supplying their neighbours when they are short of energy, in the fairest possible way. Indeed, a failure to respect this principle of equality of supply leads to frustration and demotivation, and therefore to a reduction in the general well-being of the community. We call "free riding" behaviour this type of behaviour consisting of taking advantage of the services offered by the community while ceasing to contribute.
To tackle these failures of fairness principles, the adopted strategy consists in discriminating or disadvantaging prosumers through penalties in the decision-making process. This strategy can be integrated into the logarithms executed by the Digital Twins: they can interact in a way to penalise any "free riding" type behaviour:
-  on the one hand by detecting it on the surrounding prosumers
-  on the other hand, by adapting its own supply strategy if this behaviour is detected on a peer.
We propose two variants of strategy that can be adopted by a prosumer in response to the free riding behaviour of another prosumer:
-  one consisting of no longer sending an offer to the "free riding" prosumer.
-  another consisting of applying a penalty in the energy price per KWH the offers sent to 'free riding' prosumers.
For data privacy reasons, we propose that the regulatory agent evaluates the behaviour of the prosumer twins attached to the same node and assigns them reward credits (or penalties) according to the obtained evaluation. Each prosumer twin will then emit its current reward credit in the energy requests, which will allow the producers to adapt their supply strategy according to the reward credit. Only the final score shown in the energy requests will be visible to the other peers.
7.4.1) Modelling criteria for assessing prosumer behaviours:
We have identified the different criteria that allow us to identify the relevant behaviours at the scale of a microgrid. To do this, we have defined different metrics to evaluate the degree of contribution of participants in a smart grid community: all prosumers shall consider this degree in the decision-making process to accept or prioritise energy distribution. We have aligned our algorithms on sociological studies made in the framework of the LASAGNE project and on existing works to handle free riding behaviours. For example, if a prosumer Digital Twin has an individualistic behaviour, such as profiting from other Digital Twins without contributing to the community, all other Digital Twins of the microgrid will rate that Digital Twin with a low score. As a result, each peer prosumer twin will penalise the "profiting" twin according to its policy applied: the "free rider" will be either excluded as a requester of energy, or it will face an important rise in price per KWH, or it will become less of a priority as a potential consumer.
This modelling draws inspiration from work on the detection and treatment of "free riding" behaviours in peer-to-peer file exchange networks [125].
The regulator twin evaluates each prosumer according to the 3 following criteria of evaluation:
-  Level of altruism: distribution of energy surplus to prosumers in the community when the surplus exceeds a certain threshold.
-  Ability to save energy: avoid excessive consumption in relation to current availability at the node level.
-  Equity in distribution (for the same level of award):
disparity in requests responding by "client" prosumers ratio of served request response time.
-  Ratio of "green energy" consumption.
7.4.2) Awards computation by the regulator twin:
The regulator twin progressively builds the evaluation data at regular intervals. It calculates and accumulates the evaluation data using an instance of the $AwardsComputingData$ class. This class is shown in simplified form in figure 7.8. The following subsections describe the different processing blocks of the computing process, which are invoked at different frequencies.
7.4.2.1) Retrieving data useful for assessing prosumers:
Every second, the regulator twin retrieves the following basic data, which will then be used to construct the various evaluation data:
-  The current consumptions and supplies.
-  The demanded power (energy needs not yet satisfied: we distinguish between requests from consumers that already have penalties, because we consider that a prosumer is not obliged to supply a consumer which has penalties, i.e. a negative reward score).
-  The power offered to meet demand (in new offers established to meet consumers demands).
-  The response time of new supplies.
7.4.2.2) Construction of historical data on the evaluation of prosumers:
The regulator twin calculates historical data which is used to evaluate the various criteria assessed for each prosumer. The regulator stores this historical data in its $AwardsComputingData$ instance. The principle is to establish different evaluation data for each consumer at regular intervals, then add them together over time to generate bonus or malus scores corresponding to the time elapsed since the last addition.
The various evaluation criteria are stored using the same table structure: each table contains an access key by consumer name and by date (time of the evaluation criterion). These tables are used to record the value of each of the criteria variables, each time the criteria value is computed, and for each consumer concerned. Here are the tables used:
-  $historyProvidedPower$: power provided by each prosumer and at each evaluation timestamp.
-  $historyConsumedPower$: power consumed by each prosumer and at each evaluation timestamp.
-  $historyProposedPower$: power proposed (in the form of energy offers) by each consumer and at each evaluation timestamp.
-  $historyIdealSupplyPower$: the ideal supply (power that a producer should provide given its production capacity and current needs) at each evaluation timestamp.
-  $historyIdealConsumtionPower$: ideal consumption (power that a consumer should use regards the cumulated production capacity and the maximal consumption threshold).
-  $historyMalusNotGivenPower$: energy not supplied and not offered by the producer who has sufficient availability, while there are requests for energy from non-penalised consumers at the same time. This power result will contribute to increasing the penalty acquired by a prosumer. We should note that this calculation also takes into account offers sent by the producer, even if they are not accepted by the consumer concerned (the power of the offer is deducted from the $malusNotGieven$ history for the same period).
-  $historyBonusProvidedPower$: power range above the bonus threshold (80 % of the ideal power contained in $historyIdealSupplyPower$), supplied by each prosumer at each moment. This range will help to increase the bonus acquired by the consumer.
7.4.2.3) Generation of award items:
Aggregation of results per consumer:
This historical data in WH (energy in Watt-Hour) is then aggregated by summing the energy in WH obtained at the different evaluation timestamps (power multiplied by the time differential). The regulator twin obtains the following aggregated tables (with access key by prosumer name):
-  $mapProvidedWH$: provided energy for each prosumer.
(results from $historyProvidedPower$)
-  $mapConsumedWH$: consumed energy for each prosumer.
(results from $historyConsumedPower$)
-  $mapIdealSupplyWH$: ideal energy supply for each prosumer.
(results from $historyIdealSupplyPower$)
-  $mapBonusProvidedWH$: bonus of provided energy for each prosumer.
(results from $historyBonusProvidedPower$)
-  $mapMalusNotGivenWH$: malus resulting from energy not supplied.
(results from $historyMalusNotGieven$)
7.4.2.4) Building a reward table by prosumer:
The $AwardsComputingData$ class has a method for generating a response table by prosumer name using the various previous tables obtained. For each prosumer, a new $AwardItem$ instance is created, corresponding to an award attribution, whose scores are interpreted as real rewards or penalties, depending on whether they are positive or negative.
The $AwardItem$ instance attributes are initialized as follows:
-  $scoreSupplies$: score that characterises the prosumer involvement in the supply of peer prosumers. It is calculated in the $AwardsComputingData$ instance as follow:
-  $scoreConsumptions$: score that reflects the efforts made by the prosumer to limit their consumption. It is calculated in the $AwardsComputingData$ instance as follow:
-  $scoreEquity$: score which reflects the efforts made by the prosumer not to always supply the same consumers. The calculation of this score has not yet been implemented.
The $getTotal$ method returns the total score obtained: this is simply the sum of the 3 scores $scoreSupplies$, $scoreConsumptions$, and $scoreEquity$.
7.4.2.5) Reception of the awards by prosumers:
After each reward calculation, the regulator twin submits the computed reward table in its lsa property 'AWARD', the contents of which is then retrieved by the prosumer twins. Each prosumer concerned then retrieves the reward assigned to it and adds it to its cumulative internal reward, which is stored in the 'award' attribute. The score of each reward retrieved is simply added to the internal reward.
7.4.2.6) Use of the awards by prosumers:
Every second, the consumer updates the award credit for its energy request if it is still activated. The value allocated corresponds to the award balance, which is equal to the total award score minus the various uses of credit.
A consumer can use an award credit during a supply: the amount used depends on the discount (or penalty) applied in the supply, and the time elapsed during that supply. Depending on the credit used, the award balance may be reset to zero.
If this is not the case, the prosumer could possibly cancel its credit balance at the next supply, unless it accumulates new penalties or rewards in the meantime. It should be noted that rewards and penalties are modelled by the same attributes, whose value becomes negative in the case of penalties. A prosumer can, for example, absorb part of its penalty in a supply that will give it an increase in the rate per KWH. So, by paying more for electricity for a certain period of time, a prosumer can pay off all its penalties.
7.4.2.7) Taking reward credits into account in prosumer decision-making:
In processing energy requests, the prosumers that are still able to supply take decisions on the construction of energy offers. We propose two different alternatives, one consisting of excluding a penalised prosumer (i.e. ignoring its request), the other consisting of increasing the price per KWH in the offer intended for the demanding prosumer.
Exclusion of energy demand with negative credit
When a producer selects the requests to be processed, it applies a decision-making algorithm that confirms whether each request has been selected before generating an offer in response to that request. This decision is defined in the producer policy adapted by the prosumer. At the implementation level, this is a class that customises the producer policy by implementing the common producer policy interface. The policy must return a binary decision on whether (or not) to take the demand into account, based on the energy demand and the requesting agent received as input. The producer's default policy rejects the demand if its credit counter is negative, below a certain threshold. In this way, a prosumer refuses to trade energy with any prosumer partner that has received penalties for behaviour considered harmful to the community.
Adjustment of the credit in the price per KWH
A producer's policy can override this default behaviour and agree to select any request with a negative credit as done in this alternative strategy. This latter strategy consists of generating a supply whose unit price per KWH takes account of the demand credit, whether positive or negative. The pricing of an offer is also implemented in the producer policy. The latter evaluates the unit price as follows: The total discount, which is proportional to the award credit, is spread over the supply period requested: the greater the number of KWH to be supplied, the lower the discount per KWH, and vice versa. The discount rate per KWH is calculated and then incorporated into the resulting unit price which is the offer price. Thus, if the demand credit is negative, the discount rate per KWH will be negative and this will result in a unit price increase which will be proportional to the credit and inversely proportional to the total energy required over the period. In this way, a prosumer can reward or penalise its partners based on the credits contained in the energy requests.
7.4.3) Scenario including a "free rider" prosumer:
Reward scenario with 2 altruistic prosumers and 1 'free rider' prosumer:
To experiment with free riding behaviour and the reward-based solution, we implemented a microgrid scenario with 3 prosumers as depicted in figure 7.9:
-  1 of the 3 prosumers applies a 'free riding' policy, which consists of requesting energy while refusing to supply energy to its partners. This consists of asking for energy while refusing to supply energy to its partners.
-  The other two prosumers apply an 'altruistic' type policy: they agree to supply their partners, unless they have a negative credit when the variant that excludes "free riding" behaviour is applied.
Figure 7.10 shows the output of each prosumer, which is positive when it produces energy and negative when it needs energy. The 3 prosumers have equivalent needs and production, but not at the same time. Each of them switches from consumer to producer and vice versa at different times, which makes it possible to test the fact that each of the 3 prosumers will be asked by the others to supply energy.
power produced by each prosumer during the 'credits' scenario:
7.4.4) Results:
We have tested each variant separately. In reality, it is the same scenario class ($AwardsSimulator$): the variants are distinguished by a configuration parameter that can be assigned at runtime.
7.4.4.1) Variant based on the exclusion of "free riding" prosumers:
Initially, we applied the first variant, which consisted of no longer supplying a prosumer with a negative credit balance. The first tests very quickly confirmed the exclusion of the 'free rider' prosumer as a consumer. Figure 7.11 displays the consumption history of the "free rider" in the first hour of the scenario: rectangles filled in blue correspond to actual supplies and those filled in red correspond to unsupplied energy demands. History confirms that the "free rider" was only supplied during the first cycle of the scenario. The first supply can be explained by the fact that the "free rider" credit starts with a null value and falls below the tolerance threshold (which is slightly negative) only after the "free rider" has received its first penalties. We can see that the narrow red vertical stripes that appear in the first supply block are solely due to the time taken to generate a supply contract. The following red blocks confirm that all subsequent requests for supplies are refused by the other prosumers (including during the entire period of the scenario). This result confirms that a prosumer twin can exclude as a potential consumer any prosumer penalised for bad behaviour. This could encourage a "free riding" prosumer to cooperate further by supplying energy to the other prosumers requesting energy.
Consumption history of the 'free rider' prosumer.:
7.4.4.2) Variant based on price adjustment:
Figure 7.12 shows the unit price paid by each of the 3 prosumers during an experiment lasting several hours. These are averages taken over 5-minute periods. We can easily see that the 'free rider' prosumer is very quickly penalised and pays 1.5 to 2 times the default price, whereas the 'altruistic' prosumer is very quickly rewarded and pays prices varying between 0 and 0.7 times the default price. The more attractive discount rates obtained by 'altruist 2' compared to 'altruist 1' can be explained by a more in-depth analysis of the credit utilisation data: during the scenario, both collect roughly equivalent amounts of credit but altruist 2 is supplied over shorter periods (because its supply contracts are interrupted earlier on average), which means that it has more credit left over for each new contract and therefore a better discount.
Overall, these results confirm that the use of reward credits has a considerable impact on energy prices. This could be an effective way of penalising "free riding" behaviour and encouraging prosumers to improve their involvement in the smooth running of the microgrid community.
Rate per KWH applied to energy supplies. This is the energy Rate per KWH paid by each of the 3 prosumers mentioned. The default Rate is set to one unit per KWH (represented by the curve in black).:
7.5) Use of energy storage during a blackout:
In a microgrid, the prevention of energy shortages is one of the main concerns and responds to a large number of sources of worry, particularly when certain supplies are critical. To meet this challenge, we propose to model energy storage at the level of a microgrid and to integrate storage management into the behaviour of digital twins. We consider local energy storage as a way of coping with a general shortage that may be caused by the temporary shutdown of an external supplier. More concretely, we propose two quite different solutions in terms of organisation and implementation: either each prosumer manages its own storage exclusively for its own needs, or all the prosumers in the microgrid share a common storage that can be used by all the prosumer members of the microgrid. The following section describes these two approaches.
7.5.1) Private and common storage approaches:
In both approaches (private storage or shared storage), we propose to integrate energy storage management into the prosumer digital twin. The main difference is whether to manage storage in each twin for its own needs or in a single dedicated twin for everyone's needs. We describe how each approach works as follows:
-  Private storage: At each execution cycle, each prosumer transfers its power surplus in its own storage in the limit of its storage capacity. A prosumer can use its own stored energy later if they need it, when it cannot be met from external supplies (i.e. from external suppliers or from other prosumers located in the microgrid).
-  Common storage: At start-up, the coordination platform launches an additional prosumer twin which manages the common storage for the whole micro-network: we call it a 'storage twin', even though at implementation level it is also a prosumer twin. This prosumer does not consume energy and can produce energy to supply other prosumers if its battery is charged (i.e. if the energy balance of its battery is sufficient). Its storage battery is discharged at start-up, but it can receive surplus energy from all the prosumers on the microgrid. At each execution cycle or coordination laws, each consumer transfers its surplus energy to the storage twin in the form of an 'energy donation' via its LSA via the 'DONATION' property: in this way, the storage twin gradually builds up a stock of energy. When certain prosumers need energy that cannot be supplied either by their peers or by an external supplier, the storage twin will produce energy to meet these needs using its storage battery. The storage twin will act as the other producers: the only difference is that it produces energy using its battery.
Figures 7.13 and 7.14 show an example of an application of these two approaches in a microgrid with 3 prosumers:
-  'Prosumer 1', which produces 3 KW, 1 KW of which is used to supply 'Prosumer 2'. In the case of private storage, the 2 KW surplus is used to charge its own battery, while in the case of common storage, this surplus is transferred to the 'storage twin' in the form of a donation.
-  'Prosumer 2', which consumes 1 KW (received from 'Prosumer 1'). Prosumer 2', which consumes 1 KW (received from "Prosumer 1"). In the case of private storage, it cannot use its battery, which is discharged.
-  'Prosumer 3', which consumes 1.5 kW. In the case of private storage, 'consumer 3' is supplied by its own battery, and in the case of shared storage, by the 'storage twin'.
The 'storage twin' is specific to the common storage approach and therefore only appears in figure 7.15.
Private energy storage: each prosumer manages its own battery for its own needs.:
Common energy storage: The 'storage twin' manages energy storage for the whole microgrid and uses the stored energy to meet the energy demands of surrounding prosumers.:
Comparison of private and common storage:
7.5.2) Implementation:
7.5.2.1) Energy storage:
The $EnergyStorage$ class models energy storage: there is one instance of this class in each prosumer twin: it can be used either for private or shared storage. In the case of common storage, only the storage twin (which is also an instance of $ProsumerAgent$ class) will have a non-null instance of $EnergyStorage$ class because it is effectively the only Digital Twin to manage a battery.
-  setting (of class $EnergyStorageSetting$): storage configuration parameter: indicates the type of storage (private or shared), whether it is active, its energy capacity, the energy at scenario start-up, etc.
-  $agentName$ (of class $String$): name of the digital twin which owns the battery.
-  $receivedDonations$: (double mapping table containing String and Date as key and $EnergyWithdrawal$ instances as value): Contains a history of donations from each prosumer. These donations regularly add to the total stored energy ($totalSavedWH$). The 'double key' identifies the prosumer (String instance) and the time of donation (Date instance). In this way, the digital twin cannot receive a duplicate donation from the same issuer at the same time.
-  $totalSavedWH$ (double): total stored energy in WH: cannot exceed the battery capacity in WH.
-  $withdrawalsForNeeds$ (mapping table containing Date as key and double as value): Includes withdrawals at different times used to compensate for the prosumer's energy needs.
-  $withdrawalsForProduction$ (mapping table containing Date as key and double as value): includes withdrawals at different times used to boost the prosumer's energy production.
-  $lastReservations$: (mapping table containing String as key and $StorageSupply$ instances as value): includes reservations of energy to respond to prosumer energy requests. The key identifies the prosumer to be supplied. Allows the storage twin to memorise the energy reservations already made to supply the same requester, so as not to draw energy from the battery several times for the same requester. These reservations expire after about fifteen seconds, the time it takes for an energy offer to result in a supply.
The main actions are carried out using the following methods:
-  $canSaveEnergy$ (returns a boolean): confirms whether energy saving is enabled in the storage configuration parameters. No energy credit or debit is applied if storage is not activated.
-  $computeBalanceSavedWH$ (returns a double): Calculates the remaining energy balance: corresponds to the saved total ($totalSavedWH$), from which the various withdrawals contained in $withdrawalsForNeeds$ and $withdrawalsForProduction$ are deducted. Before making a debit, this method is used to check the initial balance, to prevent a negative balance being obtained after the debit.
-  $addSavedWH$: Allows energy to be stored in the battery (in WH), up to its capacity.
-  $addDonation$: Receives an energy withdrawal from a prosumer. Converts this donation in WH and then calls $addSavedWH$.
-  $withdrawWH$: Draws energy either to boost production or to compensate for the prosumer's energy requirements.
7.5.2.2) Storage supply:
Modelling of energy supply received from storage: $StorageSupply$: corresponds to a power to provide during a time slot. It can be attached either:
-  to $ProsumerEnergyRequest$ instance: in that case, it "compensates" the need by deducting its power to the requested power.
-  to a $ProsumerEnergySupply$ instance: in that case it "reinforces" the supply 
 by adding its power to the produced power.
Figure 7.16 shows the class diagram covering the classes that manage energy storage. The $ProsumerEnergyRequest$ and $ProsumerEnergySupply$ classes implement $IEnergyReqyest$ and $IProsumerRequest$, and both include an instance of the $StorageSupply$ class (contained in the $AbstractEnergyFlow$ parent class): this instance corresponds to the battery's energy input. In the case of the $ProsumerEnergyRequest$ class, this energy offsets the energy demand, and in the case of the $ProsumerEnergySupply$ class, this energy boosts production. The power calculation implemented in each of the two classes includes the battery supply: $ProsumerEnergySupply$ adds it to its internal power, while $ProsumerEnergyRequest$ subtracts it to its internal power (because it reduces the power demanded).
:
7.5.3) Actions carried out by the prosumer:
7.5.3.1) Transfer of unused energy to the local battery or to the digital storage twin.:
The algorithm 7.17 describes the actions carried out regularly by the prosumer twin to process a surplus of energy which will feed the local storage or the common battery. The principle is to calculate this energy surplus in WH (it corresponds to the energy produced which has not yet been used for any supply). If local storage is active, this surplus energy is added directly to the battery. If common storage at microgrid level is active, the policy of the prosumer twin will check whether it authorises the 'donation' of energy for shared storage and will generate a new donation if necessary.
Processing carried out by the prosumers to use or release energy from the battery according to internal or external needs (of other prosumers). Transfers unused energy either to the local battery (if active) or to a donation for the digital storage twin.:
\State withdrawFromStorage($storage$, $globalNeed$, $globalProduction$) withdraw for production and consumption
$ globalProduction != null $ check whether the prosumer is a producer.
Comment of algorithm: compute power not used in Watts.
Comment of algorithm:  convert in WH.
$ (storage.canSaveEnergy()) $ check whether the battery can store energy. check whether the battery can still store energy.
Comment of algorithm: store energy not used in battery.
$ (donation != null ) $  check whether the energy donation is activated.
$ (producerPolicy.confirmDonation(this, unusedWH) $ the agent checks whether it agrees to give the unused energy to the 'storage' digital twin.
Comment of algorithm: Sending unused energy as a donation.
withdrawals from storage:
$ globalNeed != null $ check whether the prosumer is a consumer.
Comment of algorithm: Deletes (if necessary) supplies from storage that have expired.).
Comment of algorithm: energy used to cover consumption:
$ globalProduction != null $ check whether the prosumer is a producer.
Comment of algorithm: Deletes (if necessary) supplies from storage that have expired.).
Comment of algorithm: energy used to boost production:
comment
7.5.3.2) Using the battery for local needs:
Algorithm 7.18 describes the actions carried out regularly by the prosumer twin to use the energy from its own battery to meet its own needs. The principle is that before initiating a new supply from its battery, the prosumer twin checks that a supply has not already been initiated recently from its storage. If this is not the case, it initiates a new supply from its energy storage. If its needs increase at the current time, it becomes unsatisfied, and the prosumer will initiate a new supply from its battery (provided that the remaining energy balance of the battery is sufficient to meet this new supply).
Processing carried out by the prosumers to use energy from the battery according to internal needs.:
$ (storage.isActivated() \And globalNeed != null  \And !this.isSatisfied()) $ the prosumer checks whether its energy need is still not being met.
$ (existingStorageSupply = null \OR !existingStorageSupply.isRcent()) $ the prosumer checks whether storage provisioning has already been initiated recently.
Comment of algorithm: number of seconds since the need was active.
$ missingDurationSec >= 3 $ check if the need has not been met for more than 3 seconds.
Comment of algorithm: creating a battery supply to meet demand.
Comment of algorithm: Integration of this new supply into the energy need.
$ hasChange $ Check that the change is effective.
Comment of algorithm: modification of energy demand (can be set to zero if battery supply is sufficient)
Comment of algorithm: Processing carried out for any change in energy requirements.
7.5.3.3) Using the battery for local production:
Algorithm 7.19 describes the actions carried out by the twin to use the energy in its battery to meet the needs of other prosumers. This algorithm is only applied in the case of a common storage battery. We can note that the storage twin is also a prosumer, which is why this treatment is also implemented in $ProsumerAgent$ class, which models all prosumer twins. If there is no longer any demand and there is a power surplus, the prosumer will try to reduce the supply to the battery by limiting it to what is necessary, hence the surplus check carried out in step 7.20. If there are unprocessed requests that are still unmet, the storage twin will initiate new supplies to meet the new needs, within the limits of the remaining energy balance. If the remaining balance is not sufficient to fully meet a request, the duration is reduced in proportion to the remaining balance (see step 7.21). The supplies added to meet each request are added to a list, which is then merged into a single supply (see step 7.22): this then updates the new energy flow produced by the digital storage twin.
Processing carried out by the 'storage' digital twin to use battery energy according to the needs of other prosumers.:
$ (storage.isActivated() \And storage.getSetting().isCommon() \And globalProduction != null $ the prosumer checks whether common storage is activated.
Comment of algorithm: retrieve unmet requests.
$ (listWaitingRequests.size = 0 \And globalProduction.getAdditionalPower() > 0) $ no demands: the prosumer checks whether all power from storage is used or not.
Comment of algorithm: compute power not used in Watts.
$ (listWaitingRequestss.size() > 0 \And storage.getTotalSavedWH() > 0) $ the prosumer checks whether it can increase storage supply to respond to the waiting demands.
Comment of algorithm: power of existing storage supply
Comment of algorithm: duration of existing storage supply
$request in listWaitingRequests$ iteration on waiting demands for energy.
$ (request.getBeginDate() < getTimeStamp() -5) \And !storage.hasReservation(request.getIssuer() $  Check that the request has not already been processed.
Comment of algorithm: creating a new supply to meet this demand using storage energy.
$ (availableWH < nextStorageSupply.getRemainWH() $  the prosumer checks whether the stock of energy still available in the battery is sufficient to meet this demand throughout its duration.
Comment of algorithm: reduce the duration of the supply (insufficient energy for the entire period requested).
Comment of algorithm: deducts the energy of the new supply from the available energy.
Comment of algorithm:  merge storage supplies
7.5.4) Scenario-based assessment:
We have implemented a scenario with 3 prosumer digital twins belonging to the same microgrid node, whose production fluctuates cyclically in the same way as for the awards scenario but whose average production gradually decreases in stages, until they demand more energy than they produce. Figure 7.23 shows the production of each of the 3 local prosumers. An external supplier producing 1000 watts continuously is added: its production stops after 30 minutes, for 20 minutes. The shutdown period is shown in red in figure 7.24 (the width of the graph is not sufficient to represent this outage period in its entirety). The principle of the scenario is that the prosumers start from favourable conditions, enabling them to store energy easily, and that this stored energy is then used when they need energy: from a given moment, not only does the external supplier no longer produce, but the prosumers no longer produce enough to meet their needs. The two storage variants (private and common storage) are tested with this same scenario. In assessing the energy shortages, we have allowed a tolerance of 5 seconds when drawing up an energy contract. This time is effectively required for a prosumer to be supplied by the storage twin or another prosumer twin which plays the role of producer in the supply contract.
power produced by each prosumer during the 'storage' scenario.:
7.5.4.1) Assessment of private storage:
In this variant, each prosumer manages its own battery: we have deliberately given them very different capacities: 10, 20, 70 WH for each of the three. This allows to test the impact of inequality of storage between the 3 prosumers.
Figure 7.25 shows the history of the power produced and missing for each prosumer. The graph clearly indicates that the first two prosumers have energy missing (shown by the staircase steps in the red curve during the last third of the scenario, which corresponds to the period of the external supplier's outage). The third prosumer, which has a much higher storage capacity (70 WH), has no energy losses: this absence of energy shortfall is a direct consequence of the battery capacity. This also indicates that the battery can avoid or reduce shortages during a shortage, within the limits of its storage capacity. The second prosumer, which has a higher capacity than the first one, has relatively less energy missing than the first.
Table 7.26 shows the cumulative stored and missing energy scores for each consumer: this confirms that the amount of storage energy used depends on private storage capacity, and that not all prosumer twins are in the same boat when it comes to avoiding energy shortages.
Table 7.27 shows the cumulative missing energy scores for each consumer when storage is deactivated: the total missing is equal to 84.07 WH compared with 57.7 WH when storage is activated.
This confirms the overall reduction in missing energy, but it is surprising to see that the cumulative missing energy of the first consumer decreases when storage is deactivated.
Actually, when storage is deactivated, prosumers cannot use their energy surplus for their own storage: in this case, they use it to supply other prosumers when they need energy, which tends to even out the scores for missing energy among consumers. The third prosumer, which managed not to run out of energy in the private storage scenario, increases its shortage, while the first prosumer, which experienced the greatest shortage in the private storage scenario, tends to reduce it.
Private storage: history of the wattage produced and missing during the scenario, for each prosumer.:
Private storage: evaluation of stored and missing energy per prosumer:
No storage: evaluation of missing energy per prosumer.:
7.5.4.2) Assessment of common storage:
We have run the common storage scenario under the same conditions, with the same 3 local prosumers and the same external supplier. The storage twin has a 200 WH battery: this twin is automatically initialised when the coordination platform is started up (only if common storage is activated). In this variant, we consider that the shared storage can be equipped with a battery of much greater capacity thanks to the shared investment in the microgrid.
Figure 7.28 shows the history of the power produced and missing for each prosumer in the same way as for the private storage scenario. We can see here that the energy shortages are almost non-existent (we can only see red peaks appearing in places in the zone where the external supplier's outage is located). These energy shortages can be explained by the start-up time of a supply, which can sometimes exceed 5 seconds (this is the time it takes for an energy contract to be made with the storage twin).
Table 7.29 shows the cumulated missing energy for each prosumer. The scores are all below 1 WH and the ratios are all between 1 % and 2 %: they confirm that the missing energy is only due to the time needed to start a new supply and that common storage is the most appropriate solution to avoid shortages for all prosumers. In addition, the total energy used from common storage is 126.16 WH, which is much higher than the total energy used from private storage (which is 57.64 WH).
However, the private storage solution allows the energy shortage to be reduced strictly to zero (provided that the battery capacity of each prosumer is sufficient), which is not the case for shared storage, because there will always be slight shortages due to the time needed to start up new contracts with the storage twin.
Common storage: history of the wattage produced and missing during the scenario, for each prosumer.:
Common storage: evaluation of missing energy per prosumer. The storage twin is also listed, as it indicates the total storage energy used to supply the 3 prosumers.:
7.5.4.3) Assessment of supply from storage for critical requests:
This is a more critical variant of the common storage scenario in which the total energy is not sufficient to supply all consumers, but for which certain needs are a priority and must therefore be supplied whatever the cost. We have used the same conditions as in the previous scenario, but with the following modifications: we have set the priority level for requests from the first prosumer to the highest level and we have reduced the capacity of the common battery to 70 MH, so that it can no longer store enough energy to meet all needs.
Table 7.30 shows the accumulated missing energy obtained for each prosumer ("Local-1", which has a high priority level, is shown in red). The results confirm that 'local-1' is always served with a shortfall of almost zero, while the other prosumers, which have a lower priority, have energy shortfalls, which can be explained by the limits of the battery's capacity, which was deliberately reduced for this test. More generally, these results show that the digital twins are able to use the available storage energy in such a way as to best serve the most important demands.
Common storage with reduced capacity and critical requests from 'Local-1' prosumer: evaluation of missing energy per prosumer.:
7.6) Integration of salient attributes in the decision making of Digital Twins:
[GDM2] In this section, we propose to study the integration of some of the salient attributes that Fragnière et al. have defined and used for the design of profile maps [126]. More specifically, these are the attributes for which adaptations need to be made to the software components included in the coordination platform running on a microgrid node.
In fact, there are two types of software component involved: either the digital twins or, further downstream, the web application that distributes the report data.
Behavioural modifications involve the algorithms applied by the digital twins, while modifications to data visibility involve the web application used to distribute data to the various users of a microgrid. It should be noted that the digital twins also intervene on the visibility of the objects exchanged, but this management does not allow visibility to be managed at the level of the web application.
To date, we have not translated these attributes at implementation level, but we have identified the adaptations to be made in the software components for each attribute concerned.
The following three tables show how implementation should proceed in order to integrate each of the salient attributes selected. For ease of reading, salient attributes are separated by category: table 7.31 concerns the 'network' category, while table 7.32 concerns the 'Community life' category
and table 7.33 the 'Information data' category.
Integration of salient attributes attached to the textbf'network' category:
Integration of salient attributes attached to the textbf'Community life' category:
Integration of salient attributes attached to the textbf'Information data' category. (*): The REST server is the web server attached to the coordination platform. It provides reports on electricity consumption and production at the level of a prosumer or the microgrid.:
It should be noted that in addition to the implementations indicated in each table, all of these attributes will also need to be integrated into the platform's configuration so that they can be easily modified from the platform's web administration.
7.7) Management of two levels of flexibility:
The principle is that the regulator uses two different levels of flexibility in assessing consumer consumption: a normal level and a more flexible level for holidays or periods of shortage when urgent supplies are needed. In fact, the lack of flexibility can block supply for critical needs or reduce the motivation of members, especially if they have made prolonged efforts over a long time to limit their consumption.
Today, the level of flexibility is not yet implemented, but we have also identified the component to be updated. As with the integration of the 'regulation' salient attribute, the integration of flexibility will have to be considered in the calculation of the consumption limit applied in the allocation of rewards and penalties (mentioned in the table 7.34).
The flexibility can be simply integrated as another input sent to the function that calculates the acceptable consumption limit (in addition to the two prosumers' home characteristics mentioned: the number of people and the apartment surface). By this way, it will be possible to raise the consumption quotas according to the flexibility level.
Chapter 8) Conclusion:
Our research work concerns the design and development of an intelligent distributed system specifically tailored for smart grids. We summarise here our main contributions and future perspectives.
8.1) Contributions:
We discuss here our main contributions in light of the research questions listed in section 8.1:
-  (Q1) Can we design a coordination model and mechanisms that allows Grid
Edge Devices to collectively achieve various objectives? 
 To address research question Q1, we have modelled and implemented a coordination model that allows different grid devices to interact with each other to respond to objects in a collective manner.
Contribution: A coordination model adapted for smart grids; equipped with the concept of digital twins and novel coordination laws.
-  (Q2) How can we model the notion of Digital Twins to represent microgrid
entities which exchange and regulate energy at a local level?
To address research question Q2, we have designed and developed a series of intelligent Digital Twins that represent the entities of the microgrid. These Digital Twins interact and coordinate their activities to exchange energy and ensure the microgrid stability. To the best of our knowledge, this implementation is an innovative proposal for managing energy in a smart grid. Indeed, on the one hand it uses Multi-Agents Systems powering the behaviour of the intelligent Digital Twins. On the other hand, bio-inspired and self-organising principles present in the coordination model provide self-adaptability to the ongoing events in the grid. The test results confirmed the self-adaptation capabilities, as it obtains acceptable response times, even in difficult situations, with many requests at the same time and with insufficient produced power. It can also regulate the use of energy, at the present time or a priori using the prediction in the hour. The learning model now achieves a decent level of reliability, but it could be improved by incorporating other characteristic variables such as solar radiation or humidity levels.

Contribution: Design and implementation of digital twins as autonomous agents and a series of coordination algorithms for negotiating energy, avoiding energy peaks.
-  (Q3) How can we integrate a gossip mechanism into a coordination model that can be used for decentralised learning, with an aggregator that the client layer can define on the fly?
To address research question Q3, we have implemented the gossip bio-inspired pattern [127] as a 'complete' generic coordination mechanism that can be applied to any class of object and any aggregation operator defined in the aggregated object class. We have applied this new gossip mechanism on the learning models weights to integrate the Gossip Federated Learning approach in which each node of a microgrid participates not only in learning, but also in the distribution of model weights with the surrounding nodes. We have also integrated the Gossip Ensemble Learning approach by applying this same mechanism to the prediction results generated by the microgrid nodes. Our tests with a multi-node cluster confirmed the resilience of gossip approaches and the improved accuracy of predictions when nodes try to predict similar behaviours and when an appropriate aggregator is chosen.
Contribution: design and implementation of a novel coordination law, the gossip, which serves to aggregate machine learning models or predictions on an aggregator function provided on-the-fly.
-  (Q4) To what extent can we integrate criteria of social acceptability into Digital Twins behaviours, in the decision-making process for electricity transaction and electricity regulation?
To address research question Q4, we have incorporated into the behaviour of Digital Twins the criteria of social acceptance through design, which are the result of studies and surveys carried out by a research unit that took part in the Lasagne project. After incorporating the notion of the prosumer (represented by the prosumer Digital Twin, who can switch from producer to consumer at any time, and vice versa), we set up new scenarios and algorithms to meet defined social requirements. We have implemented critical situation scenarios such as the tragedy of the commons, with a solution based on an alternative scenario using dynamic pricing that considers demand in real time. We also integrated the use of reward credit to reduce free-riding behaviour and increase the involvement of microgrid users. In addition, we have integrated energy storage by prosumers to improve resilience in the event of a general shortage. We have implemented two variants: one using private storage (each prosumer manages its own battery) and shared storage (a digital twin centralises storage management for the whole microgrid). The results show that shared storage can guarantee optimum distribution of the energy remaining in the battery, depending on the need priority.
In the same context, we have studied the possibility of integrating salient attributes (used to define microgrid profile maps) into the digital twin algorithms and the web application that generates reports.
Contribution: design and implementation of several social acceptance algorithms: avoiding tragedy of the commons; reducing free-riding behaviour through reward credits; integrating energy storage at individual and microgrid levels; investigating the integration of salient attributes that can be handled by the digital layers of a microgrid (e.g. energy mix, pricing, regulation, and data sharing).
-  (Q5) Can we implement a light version of the coordination model that can run
on a Grid Edge Device with a small amount of disk space and memory?
To address research question Q5, we have lightened the various components and software layers involved in the coordination platform, so that it can run on edge devices with few memory resources. Tests have confirmed a significant reduction in the amount of memory used and the resolution of leakage problems.
Contribution: Light version of the coordination model adapted for smart meters.
8.2) Current limitations:
To date, although this work has addressed some aspects of the Digital Twin of microgrids, we have identified some limitations and aspects that have not yet been considered or that can be developed further to make this contribution usable in the real world. Some future work could focus on the following improvements to integrate them into this research:
8.2.1) Improving the flexibility of prosumer digital twins:
Simultaneous consumption and supply flows: Regarding the prosumer implementation, flexibility would be improved by managing energy supply and consumption in parallel and at the same time. This would require little additional implementation effort.

Holonic entities: Regarding the prosumer modelling, it would be useful to make the prosumer Digital Twin more generic by also representing higher-level entities, taking inspiration from holonic structures (a prosumer twin could represent an entire microgrid or a group of microgrids). This would make it possible to manage larger smart grids.

Energy distribution: Regarding the management of energy distribution, implementing staggering of supply over time when energy availability is not sufficient would allow to fully meet all demand at a given time. This would prevent some consumers from not being served at all. Implementing the generation of contracts for future needs would make it possible to avoid certain temporary shortages due to a lack of anticipation.
8.2.2) Integrating digital twins into the real world:
[DC2] In the current version, the prosumer digital twins can interact with each other at a local level, but do not interact with external entities in the real world that participate in the distribution of electricity at a higher level. First, we need to model another Digital Twin to represent a Distributed System Operator (DSO) entity. The DSO, which operates, manages, and sometimes owns the local and regional energy distribution networks, is an avoidable partner that is linked to a microgrid structure. The DSO can appear as an external entity that exchanges energy with the microgrid as the microgrid can both supply and receive energy depending on the moment. The DSO can also act as a representative of the microgrid in a larger-scale multi-lateral market: in this case, the DSO transmits buy or sell orders requested by the microgrid.\Integrating price negotiation with external entities:
{[DC2] In this context of energy trading, a microgrid needs to negotiate the price of energy either with a single entity (DSO, TSO or other) or with several entities through an organised market on which a microgrid sends orders of purchase or sale basis. We thus need to integrate bilateral or multilateral negotiation and be able to aggregate purchase or sale offers from all the prosumers connected to the microgrid. The commercial aggregator could be modelled by a higher-level prosumer that represents the whole microgrid and aggregate the offers to buy or sell from the linked lower level (some of which contain Distributed Energy Resources).

Moreover, different types of Energy market exist (refer to [128]) and some of these fix a price for the next day. In this type of market, it is necessary to know the total KWH needed and available for all the following day: this can be done by predicting the future needs and available power for all the following day.
In addition to knowing the quantity of energy to be traded, knowledge of current and forecast energy prices is also an important element to consider when trading energy: this would also involve predicting the energy price in different types of market: predicting the current or future KWH price could help to choose the most appropriate market to minimise the price of purchase orders and maximise the price of sales orders.}
8.2.4) Deploying the solution on real-life infrastructures:
[DC2] In the current simulations, we have limited ourselves to a small number of nodes (4) located on the same local virtual machine, which does not reflect the real conditions for deploying smart-grid data networks. Running several platforms on the same machine (with different port numbers) on the one hand reduces the amount of memory available for each instance of the platform, and on the other hand underestimates the actual communication time between the different nodes because the actual time is mainly the result of the time taken to execute the coordination laws.

To better reflect real-life situations, we could use a network topology comprising at least several dozen nodes, in which the nodes are distributed across different virtual machines. This requires a certain investment in terms of machine and network infrastructure.
Another limitation is linked to the current experimental conditions: the prosumer digital twins indirectly receive information from the smart-meter (which is the electrical power data from the associated electrical appliance) but, on the other hand, the decisions taken by the prosumer twins are not yet taken into account by the smart-meter, since they do not have an actuator that receives the decisions taken by the prosumer twins. As a result, prosumer twins do not interact fully with the physical device to which they are linked.
8.2.5) Improving the learning model:
Regarding the learning model implementation, it is possible to enhance the model's characteristics by integrating meteorological variables that have a major impact on photovoltaic electricity production.
Another way of improving the learning model's implementation is to define the classification intervals for each variable independently. This would allow the classifiers to better adapt to the distribution of each variable and therefore improve the accuracies obtained.
8.2.6) Improving the decentralised learning framework:
With regard to the application of gossip, it would be more appropriate to allow a different aggregator to be assigned to each of the 6 variables to be predicted. This would maximise the accuracy obtained for a specific variable. For example, energy produced could have a different aggregator from energy consumed, which is not the case at present.

Regarding the experiment of Gossip Federated/Ensemble Learning, the results would be more exhaustive if comparative tests were carried out by modifying the gossip frequency applied to the learning models and checking whether certain values can improve the performance already obtained.
Another area for improvement along these lines is to implement and test a variant that further reduces the frequency of gossip by only applying it when the latest changes in model weights (or prediction results) since the last application of gossip become significant.
It would also be interesting to test the gossip mechanism with other types of learning models commonly used for microgrids.
Furthermore, testing Gossip Federated/Ensemble Learning with other case studies, by highlighting the influence of each aggregator on the accuracies obtained, would help to produce more meaningful results.
8.2.7) Improving the web application:
In real use, the application would be used to monitor the status of a node or the entire microgrid. Firstly, to display the topology of the microgrid with all the nodes and the location of the local node to which the web application is connected. In addition, to make it easier to use, it would be necessary to switch from one local node to another. In addition, the rendering can be improved by using more intuitive visualisation composed of graphical elements to represent devices and energy flows. The width of the flows could be proportional to the electrical power exchanged.
8.2.8) Addition of social acceptance criteria in prosumer twins:
Salient attribute: Regarding the social acceptance, the salient attributes still need to be integrated into the behaviour of the digital twins and into the web application for distributing the report. Once the attributes have been integrated, it would be pertinent to carry out evaluations based on profile cards selected from the participants in the different surveys.

{
Algorithms of decision-making:
[EF1] Furthermore, the current implementation of a behaviour is simplistic in the sense that it is not differentiated between being either an altruistic contributor or a free-rider who refuses any request for supply. In reality, behaviour with regard to supply requests is more nuanced and each decision should take into account factors such as available energy, market price, the expected gain in credit score, etc.
An improvement could consist of integrating the decision making into a Markov Chains process or a reinforcement learning type algorithm in which the score acquired by the prosumer is used as a reward and can influence the prosumer's future decision making. This could help a prosumer twin to find an optimal long-term policy.
}
8.3) Future perspectives:
This thesis research offers the opportunity to adapt the paradigms of Digital Twins and coordination models to microgrid environments.
If we consider the PESTEL analysis framework, we can show that this work can have a greater or lesser impact on different types of domain. We can first mention the economic impact: on the one hand, this work will facilitate local transactions of electricity between devices in a microgrid infrastructure, and on the other hand, it will help to reduce communication overhead with the implementation of decentralised learning.
We can then mention the technological impacts resulting from the improvement in prediction performance (thanks to the use of gossip) and the avoidance of energy peaks (thanks to the regulation operated by the regulator twin and the interoperability of the coordination platform with different types of device (thanks to the generic nature of the prosumer digital twin).
We could also mention the social impacts resulting from the integration of social acceptance criteria and the ecological impacts resulting from the possibility of integrating renewable energy (thanks to the prosumer twin, which makes it possible to represent a Distributed Energy Resource).
{
[JHM1] Finally, there are the political and legal impacts, which are less direct than the previous ones but which could result from a wider communication campaign about this work (and the resulting improvements) in order to raise awareness among the political and legislative partners who make the decisions.
For example, the 'Energy Communities - sharing and steering of all energy resources' conference was organised to disseminate the work carried out as part of the Lasagne project to the various industrial and decision-making partners working with the ElectriCITY microgrid (located in Stockholm).
}
8.3.1) Towards decentralized energy distribution:
[DC3] In the near future, market operators will have to adapt to a new model of decentralized energy distribution, in which many prosumers are emerging who exchange energy in a decentralized way. According to Guibentif et al. [129], operators such as DSOs are having to make major changes to the way they manage energy distribution as a result of the gradual decentralisation of exchanges: they will gradually sell less KWH, but in return they will be able to sell services to interconnect microgrids and act as aggregators to bring together the buy and sell orders issued by the linked microgrids and execute them to the wholesale market.

[DC3] In terms of energy distribution, the decentralised approach offers several advantages. Not only Customer-to-Customer transactions reduce cost of energy (as it does not require an intermediary business entity) but it also reduces energy loss due to the transportation. In addition to this, using a local electricity network increases resilience in case of general shortage of the general grid operator (e.g. Iberian blackout in April 2025) as it can operate in 'island' mode. Finally, a local microgrid will make individuals more involved in energy management since each of them participates in energy production and distribution. As a result, microgrid members will be more concerned with the need to monitor and limit consumption.
On the other hand, decentralized management requires more effort on the part of users, especially in the short term. It requires not only investment in equipment and software, but also adaptation to the complexity of technical aspects and legislation. In addition, it requires cooperation between all the members of a microgrid community, and on top of that, it leads to fluctuations in local production, which requires monitoring. However, thanks to the advantages of decentralised distribution, good management of a microgrid can amply reward these efforts, particularly in the medium and long term.

[DC3] In this context of decentralised energy exchange, we will propose distributed information systems using solutions such as digital twins and coordination models that allow dynamic adaptation. Distributed information systems will allow each microgrid or prosumer to manage its energy exchanges and regulations at the local level, whereas a centralised information system that operates in traditional business-to-customer distribution management would not be able to cope with the complexity generated by local exchanges within and between different microgrids.
8.3.2) A roadmap for adapting this work to future needs:
[DC4] Taking into account the emerging needs and the improvements we have previously identified, we propose a roadmap for approaching the market and for integrating this solution into real microgrids. It can be presented as follows:

  -  Make the prosumer twin more generic by allowing a prosumer to be represented at different levels, in a holonic microgrid structure.
-  Make the prosumer twin more flexible by allowing consumption and production at the same time.
-  Integrate price negotiation within the framework of peer-to-peer trading and within the framework of an organised market.
-  Implement and test the transmission of instructions from a digital twin to the actuator of a smart meter.
-  Deploy and test the solution on a larger-scale infrastructure.
-  Integrate meteorological variables in learning models.
-  Make learning models more flexible by assigning classification intervals an aggregation operator specific to each variable to be predicted.
-  Integrate some of the identified salient attribute  into the prosumer twin behaviours.
-  Integrate stochastic processes into the decision-making and behaviour of prosumer twins.
In more general terms, this work could be the first step towards establishing digital services for the autonomous management of smart grids, in a context where smart grids will be developed more and more, but where regulation may prove necessary for their use, whether to ensure electrical stability or to guarantee good cohesion among prosumers. This work is part of a wider project to deploy the coordination platform and Digital Twins in a living laboratory (i.e. a real microgrid).